{"cells":[{"cell_type":"code","source":["#@title check GPU type\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRc61dK9pUNa","outputId":"d9f51632-06c2-45cd-c87a-227948cf7f55","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Mar 14 01:11:13 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["#@title Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuD0Fd14k1B7","outputId":"e1f8b318-4d87-483a-f330-09edb0f111a6","cellView":"form","executionInfo":{"status":"ok","timestamp":1647570142039,"user_tz":420,"elapsed":1482,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fwC17Oyis-e","outputId":"e9ece094-674d-4017-b26c-c548a51c47ec","executionInfo":{"status":"ok","timestamp":1647570145565,"user_tz":420,"elapsed":3230,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Proj4_DPI/scripts/model3_TransDTI\n"]}],"source":["#@title import libraries\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","from torch.utils import data\n","from torch import nn \n","import copy\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, roc_curve, confusion_matrix, precision_score, recall_score, auc\n","from sklearn.model_selection import KFold, train_test_split\n","torch.manual_seed(1)    # reproducible torch:2 np:3\n","np.random.seed(1)\n","\n","%cd /content/drive/MyDrive/Proj4_DPI/scripts/model3_TransDTI/\n","from config import BIN_config_DBPE\n","from models import BIN_Interaction_Flat\n","from stream import BIN_Data_Encoder\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CDy2SpNhis-i","executionInfo":{"status":"ok","timestamp":1647570145851,"user_tz":420,"elapsed":289,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}}},"outputs":[],"source":["#@title define functions\n","def test(data_generator, model, use_cuda):\n","    y_pred = []\n","    y_label = []\n","    model.eval()\n","    loss_accumulate = 0.0\n","    count = 0.0\n","    for i, (d, p, label) in enumerate(data_generator):\n","\n","        label = Variable(torch.from_numpy(np.array(label)).float())\n","        if use_cuda:\n","            d = d.cuda()\n","            p = p.cuda()\n","            label = label.cuda()\n","        \n","        score = model(d, p)\n","        \n","        m = torch.nn.Sigmoid()\n","        logits = torch.squeeze(m(score))\n","        loss_fct = torch.nn.BCELoss()           \n","\n","        loss = loss_fct(logits, label)\n","        \n","        loss_accumulate += loss\n","        count += 1\n","        \n","        logits = logits.detach().cpu().numpy()\n","        \n","        label_ids = label.to('cpu').numpy()\n","        y_label = y_label + label_ids.flatten().tolist()\n","        y_pred = y_pred + logits.flatten().tolist()\n","        \n","    loss = loss_accumulate/count\n","    \n","    fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n","\n","    precision = tpr / (tpr + fpr)\n","\n","    f1 = 2 * precision * tpr / (tpr + precision + 0.00001)\n","\n","    # thred_optim = thresholds[5:][np.argmax(f1[5:])]\n","    thred_optim = 0.5\n","\n","    print(\"optimal threshold: \" + str(thred_optim))\n","\n","    # y_pred_s = [1 if i else 0 for i in (y_pred >= thred_optim)]\n","    y_pred_s = [1 if i>=thred_optim else 0 for i in y_pred]\n","    \n","\n","    auc_k = metrics.auc(fpr, tpr)\n","    print(\"AUROC:\" + str(auc_k))\n","    print(\"AUPRC: \"+ str(average_precision_score(y_label, y_pred)))\n","\n","    cm1 = confusion_matrix(y_label, y_pred_s)\n","    print('Confusion Matrix : \\n', cm1)\n","    print('Recall : ', recall_score(y_label, y_pred_s))\n","    print('Precision : ', precision_score(y_label, y_pred_s))\n","\n","    total1=sum(sum(cm1))\n","    #####from confusion matrix calculate accuracy\n","    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n","    print ('Accuracy : ', accuracy1)\n","\n","    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n","    print('Sensitivity : ', sensitivity1 )\n","\n","    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n","    print('Specificity : ', specificity1)\n","\n","    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n","    return accuracy1, roc_auc_score(y_label, y_pred), average_precision_score(y_label, y_pred), f1_score(y_label, outputs), y_pred, loss.item()\n","\n","def main(use_cuda):\n","    config = BIN_config_DBPE()\n","    \n","    lr = config['learning_rate']\n","    BATCH_SIZE = config['batch_size']\n","    # BATCH_SIZE = 128\n","    train_epoch = config['train_epoch']\n","    accumulation_steps = config['accumulation_steps']\n","\n","    print(\"learning rate:\",lr)\n","    print(\"batch size:\",BATCH_SIZE)\n","    print(\"training epoch:\",train_epoch)\n","    print(\"accumulation steps:\", accumulation_steps)\n","\n","    \n","    loss_history = []\n","    loss_history_val = []\n","    acc_train = []\n","    acc_val = []\n","    \n","    model = BIN_Interaction_Flat(**config)\n","    \n","    if use_cuda:\n","        model = model.cuda()\n","\n","    if torch.cuda.device_count() > 1:\n","        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","        model = nn.DataParallel(model, dim = 0)\n","    elif torch.cuda.device_count() < 1:\n","        print(\"Let's use cpu!\")\n","            \n","    opt = torch.optim.AdamW(model.parameters(), lr = lr)\n","    # opt = torch.optim.Adam(model.parameters(), lr = lr)\n","    #opt = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n","    \n","    print('--- Data Preparation ---')\n","    \n","    params = {'batch_size': BATCH_SIZE,\n","              'shuffle': True,\n","              'num_workers': 6, \n","              'drop_last': True}\n","\n","    dataFolder = '/content/drive/MyDrive/Proj4_DPI/data/data_with_embedding/'\n","    # df_train = pd.read_pickle(dataFolder + '/train_loc0.pkl')\n","    # df_train = df_train[1:1000]\n","    # df_val = pd.read_pickle(dataFolder + '/val_loc0.pkl')\n","    # df_val = df_val[1:500]\n","    # df_test = pd.read_pickle(dataFolder + '/test_loc0.pkl')\n","    # df_test = df_test[1:500]\n","    # df = pd.read_pickle(dataFolder + '/JUNB_test.pkl')\n","    df = pd.read_pickle(dataFolder + '/AP2A_train.pkl')\n","    \n","    df_train, df_val = train_test_split(df, test_size=0.2)\n","    print(\"training size: \", df_train.shape[0])\n","    print(\"validation size: \", df_val.shape[0])\n","  \n","\n","    training_set = BIN_Data_Encoder(np.array([i for i in range(df_train.shape[0])]), df_train.label.values, df_train)\n","    training_generator = data.DataLoader(training_set, **params)\n","\n","    validation_set = BIN_Data_Encoder(np.array([i for i in range(df_val.shape[0])]), df_val.label.values, df_val)\n","    validation_generator = data.DataLoader(validation_set, **params)\n","    # testing_set = BIN_Data_Encoder(np.array([i for i in range(df_test.shape[0])]), df_test.label.values, df_test)\n","    # testing_generator = data.DataLoader(testing_set, **params)\n","    \n","    # early stopping\n","    max_auc = 0\n","    model_max = copy.deepcopy(model)\n","    \n","    print('--- Go for Training ---')\n","    torch.backends.cudnn.benchmark = True\n","    for epo in range(train_epoch):\n","        model.train()\n","        for i, (d, p, label) in enumerate(training_generator):\n","            \n","            label = Variable(torch.from_numpy(np.array(label)).float())\n","            if use_cuda:\n","                d = d.cuda()\n","                p = p.cuda()\n","                label = label.cuda()\n","\n","            \n","            score = model(d, p)\n","            loss_fct = torch.nn.BCELoss()\n","            m = torch.nn.Sigmoid()\n","            n = torch.squeeze(m(score))\n","            # print(d.isnan().any())\n","            # print(p.isnan().any())\n","            # print(p)\n","            \n","            loss = loss_fct(n, label)\n","            loss_history.append(loss)\n","            loss.backward()\n","            \n","\n","            # only updates weights after gradients are accumulated\n","            if ((i+1) % accumulation_steps == 0):\n","                opt.step()\n","                opt.zero_grad()\n","            \n","            if ((i+1) % 100 == 0):\n","                print('Training at Epoch ' + str(epo + 1) + ' iteration ' + str(i+1) + ' with loss ' + str(loss.cpu().detach().numpy()))\n","            \n","        # every epoch test\n","        with torch.set_grad_enabled(False):\n","            accuracy, auc, auprc, f1, logits, loss = test(validation_generator, model, use_cuda)\n","            loss_history_val.append(loss)\n","            acc_val.append(accuracy)\n","            if auc > max_auc:\n","                model_max = copy.deepcopy(model)\n","                max_auc = auc\n","                # # save the model\n","                # save_path = './epoch' + str(epo+1) + '.pt'\n","                # torch.save(model.state_dict(), save_path)\n","                # print('Saving model to',save_path)\n","\n","            print('Validation at Epoch '+ str(epo + 1) + ' , AUROC: '+ str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Val loss: '+str(loss)+ ' , Accuracy: '+str(accuracy))\n","            \n","            accuracy, auc, auprc, f1, logits, loss = test(training_generator, model, use_cuda)\n","            print('Training at Epoch '+ str(epo + 1) + ' , AUROC: '+ str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Train loss: '+str(loss)+ ' , Accuracy: '+str(accuracy))\n","            acc_train.append(accuracy)\n","\n","    print(\"max validation accuracy \"+ str(max_auc))\n","    # print('--- Go for Testing ---')\n","    # try:\n","    #     with torch.set_grad_enabled(False):\n","    #         auc, auprc, f1, logits, loss = test(testing_generator, model_max, use_cuda)\n","    #         print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Test loss: '+str(loss))\n","    # except:\n","    #     print('testing failed')\n","    return model_max, model, loss_history, loss_history_val, acc_train, acc_val\n"]},{"cell_type":"code","source":["#@title run the model\n","s = time()\n","model_max, model_last, loss_history, loss_val, acc_train, acc_val = main(use_cuda)\n","e = time()\n","print(e-s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xknXEkqiYSDY","executionInfo":{"status":"ok","timestamp":1647573523063,"user_tz":420,"elapsed":3098401,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"85dc7ae6-3bd2-423a-b85e-a9a5fdfd28e6"},"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["learning rate: 0.001\n","batch size: 64\n","training epoch: 100\n","accumulation steps: 1\n","--- Data Preparation ---\n","training size:  23660\n","validation size:  5916\n","--- Go for Training ---\n","Training at Epoch 1 iteration 100 with loss 0.702685\n","Training at Epoch 1 iteration 200 with loss 0.682441\n","Training at Epoch 1 iteration 300 with loss 0.67854583\n","optimal threshold: 0.5\n","AUROC:0.5779963988579269\n","AUPRC: 0.5661722717568693\n","Confusion Matrix : \n"," [[1727 1238]\n"," [1373 1550]]\n","Recall :  0.5302771125555936\n","Precision :  0.5559540889526542\n","Accuracy :  0.5565557065217391\n","Sensitivity :  0.5824620573355818\n","Specificity :  0.5302771125555936\n","Validation at Epoch 1 , AUROC: 0.5779963988579269 , AUPRC: 0.5661722717568693 , F1: 0.5428121169672562 , Val loss: 0.6837907433509827 , Accuracy: 0.5565557065217391\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["optimal threshold: 0.5\n","AUROC:0.6013117805909598\n","AUPRC: 0.5925178754880669\n","Confusion Matrix : \n"," [[6898 4825]\n"," [5246 6647]]\n","Recall :  0.5589001933910703\n","Precision :  0.5794107391910739\n","Accuracy :  0.5735518292682927\n","Sensitivity :  0.5884159344877591\n","Specificity :  0.5589001933910703\n","Training at Epoch 1 , AUROC: 0.6013117805909598 , AUPRC: 0.5925178754880669 , F1: 0.5689706826449819 , Train loss: 0.6779308319091797 , Accuracy: 0.5735518292682927\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training at Epoch 2 iteration 100 with loss 0.69159234\n","Training at Epoch 2 iteration 200 with loss 0.6931017\n","Training at Epoch 2 iteration 300 with loss 0.70079726\n","optimal threshold: 0.5\n","AUROC:0.5939828278264256\n","AUPRC: 0.5749033119089637\n","Confusion Matrix : \n"," [[1774 1188]\n"," [1372 1554]]\n","Recall :  0.5311004784688995\n","Precision :  0.5667396061269147\n","Accuracy :  0.5652173913043478\n","Sensitivity :  0.5989196488858879\n","Specificity :  0.5311004784688995\n","Validation at Epoch 2 , AUROC: 0.5939828278264256 , AUPRC: 0.5749033119089637 , F1: 0.5483415666901906 , Val loss: 0.6805067658424377 , Accuracy: 0.5652173913043478\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["optimal threshold: 0.5\n","AUROC:0.619189194562733\n","AUPRC: 0.6076557146387489\n","Confusion Matrix : \n"," [[7175 4549]\n"," [5281 6611]]\n","Recall :  0.5559199461823074\n","Precision :  0.5923835125448028\n","Accuracy :  0.5837567750677507\n","Sensitivity :  0.6119924940293415\n","Specificity :  0.5559199461823074\n","Training at Epoch 2 , AUROC: 0.619189194562733 , AUPRC: 0.6076557146387489 , F1: 0.5735727919486378 , Train loss: 0.6746813058853149 , Accuracy: 0.5837567750677507\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training at Epoch 3 iteration 100 with loss 0.68774545\n","Training at Epoch 3 iteration 200 with loss 0.6776068\n","Training at Epoch 3 iteration 300 with loss 0.67422533\n","optimal threshold: 0.5\n","AUROC:0.5945015306666396\n","AUPRC: 0.5792573940616179\n","Confusion Matrix : \n"," [[1527 1435]\n"," [1078 1848]]\n","Recall :  0.631578947368421\n","Precision :  0.5628997867803838\n","Accuracy :  0.5731997282608695\n","Sensitivity :  0.5155300472653612\n","Specificity :  0.631578947368421\n","Validation at Epoch 3 , AUROC: 0.5945015306666396 , AUPRC: 0.5792573940616179 , F1: 0.5952649379932357 , Val loss: 0.6799311637878418 , Accuracy: 0.5731997282608695\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["optimal threshold: 0.5\n","AUROC:0.6320904750156651\n","AUPRC: 0.624682923023395\n","Confusion Matrix : \n"," [[6220 5509]\n"," [4101 7786]]\n","Recall :  0.655001261882729\n","Precision :  0.5856336968785257\n","Accuracy :  0.5930724932249323\n","Sensitivity :  0.5303094893000255\n","Specificity :  0.655001261882729\n","Training at Epoch 3 , AUROC: 0.6320904750156651 , AUPRC: 0.624682923023395 , F1: 0.6183782066555475 , Train loss: 0.6680349111557007 , Accuracy: 0.5930724932249323\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training at Epoch 4 iteration 100 with loss 0.6620066\n","Training at Epoch 4 iteration 200 with loss 0.68542314\n","Training at Epoch 4 iteration 300 with loss 0.68755436\n","optimal threshold: 0.5\n","AUROC:0.5955890429609527\n","AUPRC: 0.5812419700927062\n","Confusion Matrix : \n"," [[1515 1443]\n"," [1097 1833]]\n","Recall :  0.6255972696245734\n","Precision :  0.5595238095238095\n","Accuracy :  0.5686141304347826\n","Sensitivity :  0.5121703853955375\n","Specificity :  0.6255972696245734\n","Validation at Epoch 4 , AUROC: 0.5955890429609527 , AUPRC: 0.5812419700927062 , F1: 0.5907186593619078 , Val loss: 0.6800546050071716 , Accuracy: 0.5686141304347826\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["optimal threshold: 0.5\n","AUROC:0.6484157753847686\n","AUPRC: 0.6396455628247661\n","Confusion Matrix : \n"," [[6316 5414]\n"," [3968 7918]]\n","Recall :  0.6661618711088676\n","Precision :  0.5939093909390939\n","Accuracy :  0.6027269647696477\n","Sensitivity :  0.5384484228473998\n","Specificity :  0.6661618711088676\n","Training at Epoch 4 , AUROC: 0.6484157753847686 , AUPRC: 0.6396455628247661 , F1: 0.6279641525894203 , Train loss: 0.6639013886451721 , Accuracy: 0.6027269647696477\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training at Epoch 5 iteration 100 with loss 0.64714503\n","Training at Epoch 5 iteration 200 with loss 0.6909393\n","Training at Epoch 5 iteration 300 with loss 0.6412692\n","optimal threshold: 0.5\n","AUROC:0.5920366942159441\n","AUPRC: 0.5745594135981721\n","Confusion Matrix : \n"," [[1496 1470]\n"," [1094 1828]]\n","Recall :  0.6255989048596852\n","Precision :  0.5542753183747726\n","Accuracy :  0.5645380434782609\n","Sensitivity :  0.5043830074173972\n","Specificity :  0.6255989048596852\n","Validation at Epoch 5 , AUROC: 0.5920366942159441 , AUPRC: 0.5745594135981721 , F1: 0.5877813504823151 , Val loss: 0.6803505420684814 , Accuracy: 0.5645380434782609\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["optimal threshold: 0.5\n","AUROC:0.6482106268340593\n","AUPRC: 0.6414120137210058\n","Confusion Matrix : \n"," [[6422 5295]\n"," [4053 7846]]\n","Recall :  0.6593831414404572\n","Precision :  0.5970626284148847\n","Accuracy :  0.6041666666666666\n","Sensitivity :  0.5480925151489289\n","Specificity :  0.6593831414404572\n","Training at Epoch 5 , AUROC: 0.6482106268340593 , AUPRC: 0.6414120137210058 , F1: 0.6266773162939296 , Train loss: 0.6623469591140747 , Accuracy: 0.6041666666666666\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training at Epoch 6 iteration 100 with loss 0.6861084\n","Training at Epoch 6 iteration 200 with loss 0.6905242\n","Training at Epoch 6 iteration 300 with loss 0.64105964\n","optimal threshold: 0.5\n","AUROC:0.5948972355694343\n","AUPRC: 0.5761253854087911\n","Confusion Matrix : \n"," [[1420 1542]\n"," [ 993 1933]]\n","Recall :  0.6606288448393711\n","Precision :  0.5562589928057554\n","Accuracy :  0.5694633152173914\n","Sensitivity :  0.47940580688723833\n","Specificity :  0.6606288448393711\n","Validation at Epoch 6 , AUROC: 0.5948972355694343 , AUPRC: 0.5761253854087911 , F1: 0.6039681299796907 , Val loss: 0.6824377179145813 , Accuracy: 0.5694633152173914\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.6587811111543929\n","AUPRC: 0.6501679689695224\n","Confusion Matrix : \n"," [[6063 5666]\n"," [3518 8369]]\n","Recall :  0.7040464372844284\n","Precision :  0.5962949768436052\n","Accuracy :  0.6111111111111112\n","Sensitivity :  0.5169238639270185\n","Specificity :  0.7040464372844284\n","Training at Epoch 6 , AUROC: 0.6587811111543929 , AUPRC: 0.6501679689695224 , F1: 0.6457063498186868 , Train loss: 0.6571359038352966 , Accuracy: 0.6111111111111112\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 7 iteration 100 with loss 0.6442652\n","Training at Epoch 7 iteration 200 with loss 0.6686665\n","Training at Epoch 7 iteration 300 with loss 0.6617632\n","optimal threshold: 0.5\n","AUROC:0.5942756677079998\n","AUPRC: 0.5793864986346571\n","Confusion Matrix : \n"," [[1593 1370]\n"," [1165 1760]]\n","Recall :  0.6017094017094017\n","Precision :  0.5623003194888179\n","Accuracy :  0.5694633152173914\n","Sensitivity :  0.5376307796152549\n","Specificity :  0.6017094017094017\n","Validation at Epoch 7 , AUROC: 0.5942756677079998 , AUPRC: 0.5793864986346571 , F1: 0.5813377374071016 , Val loss: 0.6838181018829346 , Accuracy: 0.5694633152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.6713562828071786\n","AUPRC: 0.6638071224916984\n","Confusion Matrix : \n"," [[6882 4840]\n"," [4050 7844]]\n","Recall :  0.6594921809315621\n","Precision :  0.6184169031851151\n","Accuracy :  0.6235602981029811\n","Sensitivity :  0.5871011772735029\n","Specificity :  0.6594921809315621\n","Training at Epoch 7 , AUROC: 0.6713562828071786 , AUPRC: 0.6638071224916984 , F1: 0.6382944096346326 , Train loss: 0.6485931873321533 , Accuracy: 0.6235602981029811\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 8 iteration 100 with loss 0.7125484\n","Training at Epoch 8 iteration 200 with loss 0.6547164\n","Training at Epoch 8 iteration 300 with loss 0.6742514\n","optimal threshold: 0.5\n","AUROC:0.5961476599584167\n","AUPRC: 0.5795749019885177\n","Confusion Matrix : \n"," [[1448 1510]\n"," [1033 1897]]\n","Recall :  0.6474402730375427\n","Precision :  0.5567948341649545\n","Accuracy :  0.5681046195652174\n","Sensitivity :  0.48951994590939824\n","Specificity :  0.6474402730375427\n","Validation at Epoch 8 , AUROC: 0.5961476599584167 , AUPRC: 0.5795749019885177 , F1: 0.5987060123086633 , Val loss: 0.688487708568573 , Accuracy: 0.5681046195652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.6746736780231684\n","AUPRC: 0.6648814563679211\n","Confusion Matrix : \n"," [[6247 5477]\n"," [3479 8413]]\n","Recall :  0.7074503868146653\n","Precision :  0.6056875449964003\n","Accuracy :  0.6207655826558266\n","Sensitivity :  0.5328386216308427\n","Specificity :  0.7074503868146653\n","Training at Epoch 8 , AUROC: 0.6746736780231684 , AUPRC: 0.6648814563679211 , F1: 0.6526258630051974 , Train loss: 0.64772629737854 , Accuracy: 0.6207655826558266\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 9 iteration 100 with loss 0.6402329\n","Training at Epoch 9 iteration 200 with loss 0.64508873\n","Training at Epoch 9 iteration 300 with loss 0.6537123\n","optimal threshold: 0.5\n","AUROC:0.5919624477628679\n","AUPRC: 0.5805716507242737\n","Confusion Matrix : \n"," [[1760 1197]\n"," [1354 1577]]\n","Recall :  0.5380416240191062\n","Precision :  0.5684931506849316\n","Accuracy :  0.5667459239130435\n","Sensitivity :  0.595197835644234\n","Specificity :  0.5380416240191062\n","Validation at Epoch 9 , AUROC: 0.5919624477628679 , AUPRC: 0.5805716507242737 , F1: 0.5528483786152498 , Val loss: 0.6829437613487244 , Accuracy: 0.5667459239130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.6932749518144468\n","AUPRC: 0.6868696727194804\n","Confusion Matrix : \n"," [[7710 4015]\n"," [4548 7343]]\n","Recall :  0.6175258598940375\n","Precision :  0.646504666314492\n","Accuracy :  0.6374068428184282\n","Sensitivity :  0.6575692963752665\n","Specificity :  0.6175258598940375\n","Training at Epoch 9 , AUROC: 0.6932749518144468 , AUPRC: 0.6868696727194804 , F1: 0.631683083143361 , Train loss: 0.6394745707511902 , Accuracy: 0.6374068428184282\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 10 iteration 100 with loss 0.6428317\n","Training at Epoch 10 iteration 200 with loss 0.6361303\n","Training at Epoch 10 iteration 300 with loss 0.6703738\n","optimal threshold: 0.5\n","AUROC:0.5903101788150725\n","AUPRC: 0.5805937637705291\n","Confusion Matrix : \n"," [[1849 1114]\n"," [1443 1482]]\n","Recall :  0.5066666666666667\n","Precision :  0.5708782742681048\n","Accuracy :  0.5657269021739131\n","Sensitivity :  0.6240296996287547\n","Specificity :  0.5066666666666667\n","Validation at Epoch 10 , AUROC: 0.5903101788150725 , AUPRC: 0.5805937637705291 , F1: 0.5368592646259736 , Val loss: 0.6821266412734985 , Accuracy: 0.5657269021739131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7015481288720902\n","AUPRC: 0.6917282037888903\n","Confusion Matrix : \n"," [[8134 3588]\n"," [4830 7064]]\n","Recall :  0.5939128972591222\n","Precision :  0.663161847540368\n","Accuracy :  0.6435467479674797\n","Sensitivity :  0.693908889268043\n","Specificity :  0.5939128972591222\n","Training at Epoch 10 , AUROC: 0.7015481288720902 , AUPRC: 0.6917282037888903 , F1: 0.6266300008870753 , Train loss: 0.6424731612205505 , Accuracy: 0.6435467479674797\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 11 iteration 100 with loss 0.66146004\n","Training at Epoch 11 iteration 200 with loss 0.6855731\n","Training at Epoch 11 iteration 300 with loss 0.6247987\n","optimal threshold: 0.5\n","AUROC:0.5917924361650783\n","AUPRC: 0.578377860993782\n","Confusion Matrix : \n"," [[1599 1362]\n"," [1172 1755]]\n","Recall :  0.5995900239152716\n","Precision :  0.563041385948027\n","Accuracy :  0.5696331521739131\n","Sensitivity :  0.5400202634245187\n","Specificity :  0.5995900239152716\n","Validation at Epoch 11 , AUROC: 0.5917924361650783 , AUPRC: 0.578377860993782 , F1: 0.5807412309728657 , Val loss: 0.6926370859146118 , Accuracy: 0.5696331521739131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7012627170143014\n","AUPRC: 0.69391034671092\n","Confusion Matrix : \n"," [[7150 4575]\n"," [3857 8034]]\n","Recall :  0.6756370364140947\n","Precision :  0.6371639305258149\n","Accuracy :  0.6429539295392954\n","Sensitivity :  0.6098081023454158\n","Specificity :  0.6756370364140947\n","Training at Epoch 11 , AUROC: 0.7012627170143014 , AUPRC: 0.69391034671092 , F1: 0.6558367346938775 , Train loss: 0.6292780041694641 , Accuracy: 0.6429539295392954\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 12 iteration 100 with loss 0.68560946\n","Training at Epoch 12 iteration 200 with loss 0.666163\n","Training at Epoch 12 iteration 300 with loss 0.6560497\n","optimal threshold: 0.5\n","AUROC:0.5874464051654114\n","AUPRC: 0.5766849277517944\n","Confusion Matrix : \n"," [[1690 1270]\n"," [1316 1612]]\n","Recall :  0.5505464480874317\n","Precision :  0.5593337959750173\n","Accuracy :  0.5608016304347826\n","Sensitivity :  0.5709459459459459\n","Specificity :  0.5505464480874317\n","Validation at Epoch 12 , AUROC: 0.5874464051654114 , AUPRC: 0.5766849277517944 , F1: 0.5549053356282273 , Val loss: 0.6893157958984375 , Accuracy: 0.5608016304347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7231521852805769\n","AUPRC: 0.7225148294225927\n","Confusion Matrix : \n"," [[7870 3859]\n"," [4194 7693]]\n","Recall :  0.6471775889627324\n","Precision :  0.6659452908587258\n","Accuracy :  0.6590023712737128\n","Sensitivity :  0.6709864438571063\n","Specificity :  0.6471775889627324\n","Training at Epoch 12 , AUROC: 0.7231521852805769 , AUPRC: 0.7225148294225927 , F1: 0.6564273219847262 , Train loss: 0.6202419400215149 , Accuracy: 0.6590023712737128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 13 iteration 100 with loss 0.6204337\n","Training at Epoch 13 iteration 200 with loss 0.60966897\n","Training at Epoch 13 iteration 300 with loss 0.63375235\n","optimal threshold: 0.5\n","AUROC:0.5818683542007836\n","AUPRC: 0.5717370966051142\n","Confusion Matrix : \n"," [[1718 1243]\n"," [1342 1585]]\n","Recall :  0.5415100785787496\n","Precision :  0.5604667609618105\n","Accuracy :  0.5609714673913043\n","Sensitivity :  0.580209388720027\n","Specificity :  0.5415100785787496\n","Validation at Epoch 13 , AUROC: 0.5818683542007836 , AUPRC: 0.5717370966051142 , F1: 0.5508253692441355 , Val loss: 0.7065550684928894 , Accuracy: 0.5609714673913043\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7268926107289833\n","AUPRC: 0.7272578562376816\n","Confusion Matrix : \n"," [[8022 3712]\n"," [4312 7570]]\n","Recall :  0.6370981316276721\n","Precision :  0.6709803226378301\n","Accuracy :  0.660230352303523\n","Sensitivity :  0.6836543378217147\n","Specificity :  0.6370981316276721\n","Training at Epoch 13 , AUROC: 0.7268926107289833 , AUPRC: 0.7272578562376816 , F1: 0.6536004144361941 , Train loss: 0.6097911596298218 , Accuracy: 0.660230352303523\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 14 iteration 100 with loss 0.63067657\n","Training at Epoch 14 iteration 200 with loss 0.6511408\n","Training at Epoch 14 iteration 300 with loss 0.6501509\n","optimal threshold: 0.5\n","AUROC:0.5789805558632403\n","AUPRC: 0.5694774755446821\n","Confusion Matrix : \n"," [[1828 1132]\n"," [1451 1477]]\n","Recall :  0.5044398907103825\n","Precision :  0.5661172863165964\n","Accuracy :  0.5613111413043478\n","Sensitivity :  0.6175675675675676\n","Specificity :  0.5044398907103825\n","Validation at Epoch 14 , AUROC: 0.5789805558632403 , AUPRC: 0.5694774755446821 , F1: 0.5335018963337548 , Val loss: 0.6988042593002319 , Accuracy: 0.5613111413043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7412232146331309\n","AUPRC: 0.7359291724587365\n","Confusion Matrix : \n"," [[8446 3279]\n"," [4548 7343]]\n","Recall :  0.6175258598940375\n","Precision :  0.6913010732442101\n","Accuracy :  0.6685721544715447\n","Sensitivity :  0.7203411513859275\n","Specificity :  0.6175258598940375\n","Training at Epoch 14 , AUROC: 0.7412232146331309 , AUPRC: 0.7359291724587365 , F1: 0.6523342069026784 , Train loss: 0.6081971526145935 , Accuracy: 0.6685721544715447\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 15 iteration 100 with loss 0.6018953\n","Training at Epoch 15 iteration 200 with loss 0.67782557\n","Training at Epoch 15 iteration 300 with loss 0.7032397\n","optimal threshold: 0.5\n","AUROC:0.5835179428956472\n","AUPRC: 0.5775844850916261\n","Confusion Matrix : \n"," [[1482 1476]\n"," [1131 1799]]\n","Recall :  0.6139931740614335\n","Precision :  0.5493129770992367\n","Accuracy :  0.557235054347826\n","Sensitivity :  0.5010141987829615\n","Specificity :  0.6139931740614335\n","Validation at Epoch 15 , AUROC: 0.5835179428956472 , AUPRC: 0.5775844850916261 , F1: 0.5798549556809025 , Val loss: 0.6960495710372925 , Accuracy: 0.557235054347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7613538361251511\n","AUPRC: 0.7637933620405859\n","Confusion Matrix : \n"," [[7411 4311]\n"," [3103 8791]]\n","Recall :  0.7391121573902808\n","Precision :  0.6709662646924134\n","Accuracy :  0.6860602981029811\n","Sensitivity :  0.6322299948814195\n","Specificity :  0.7391121573902808\n","Training at Epoch 15 , AUROC: 0.7613538361251511 , AUPRC: 0.7637933620405859 , F1: 0.7033925428068492 , Train loss: 0.5957506895065308 , Accuracy: 0.6860602981029811\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 16 iteration 100 with loss 0.6429259\n","Training at Epoch 16 iteration 200 with loss 0.50301063\n","Training at Epoch 16 iteration 300 with loss 0.7017932\n","optimal threshold: 0.5\n","AUROC:0.5737749133113919\n","AUPRC: 0.5638071069458179\n","Confusion Matrix : \n"," [[1394 1572]\n"," [1062 1860]]\n","Recall :  0.6365503080082136\n","Precision :  0.541958041958042\n","Accuracy :  0.5526494565217391\n","Sensitivity :  0.46999325691166555\n","Specificity :  0.6365503080082136\n","Validation at Epoch 16 , AUROC: 0.5737749133113919 , AUPRC: 0.5638071069458179 , F1: 0.5854579792256847 , Val loss: 0.7071513533592224 , Accuracy: 0.5526494565217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.760257208790512\n","AUPRC: 0.7653339093843254\n","Confusion Matrix : \n"," [[7158 4568]\n"," [2925 8965]]\n","Recall :  0.7539949537426409\n","Precision :  0.6624547402645385\n","Accuracy :  0.682715108401084\n","Sensitivity :  0.6104383421456592\n","Specificity :  0.7539949537426409\n","Training at Epoch 16 , AUROC: 0.760257208790512 , AUPRC: 0.7653339093843254 , F1: 0.7052668843173505 , Train loss: 0.5927529335021973 , Accuracy: 0.682715108401084\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 17 iteration 100 with loss 0.68846446\n","Training at Epoch 17 iteration 200 with loss 0.61776906\n","Training at Epoch 17 iteration 300 with loss 0.65791035\n","optimal threshold: 0.5\n","AUROC:0.5840483917027961\n","AUPRC: 0.5753596491011312\n","Confusion Matrix : \n"," [[1583 1380]\n"," [1221 1704]]\n","Recall :  0.5825641025641025\n","Precision :  0.5525291828793775\n","Accuracy :  0.5582540760869565\n","Sensitivity :  0.5342558218022275\n","Specificity :  0.5825641025641025\n","Validation at Epoch 17 , AUROC: 0.5840483917027961 , AUPRC: 0.5753596491011312 , F1: 0.5671492760858713 , Val loss: 0.7042970657348633 , Accuracy: 0.5582540760869565\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7819516157740548\n","AUPRC: 0.785240453178903\n","Confusion Matrix : \n"," [[7966 3762]\n"," [3266 8622]]\n","Recall :  0.7252691790040376\n","Precision :  0.6962209302325582\n","Accuracy :  0.7024051490514905\n","Sensitivity :  0.6792291950886766\n","Specificity :  0.7252691790040376\n","Training at Epoch 17 , AUROC: 0.7819516157740548 , AUPRC: 0.785240453178903 , F1: 0.71044825313118 , Train loss: 0.574939489364624 , Accuracy: 0.7024051490514905\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 18 iteration 100 with loss 0.5923241\n","Training at Epoch 18 iteration 200 with loss 0.59424835\n","Training at Epoch 18 iteration 300 with loss 0.5523851\n","optimal threshold: 0.5\n","AUROC:0.5771471822811742\n","AUPRC: 0.5664836612369177\n","Confusion Matrix : \n"," [[1525 1433]\n"," [1185 1745]]\n","Recall :  0.5955631399317406\n","Precision :  0.5490874764002517\n","Accuracy :  0.5553668478260869\n","Sensitivity :  0.5155510480054091\n","Specificity :  0.5955631399317406\n","Validation at Epoch 18 , AUROC: 0.5771471822811742 , AUPRC: 0.5664836612369177 , F1: 0.5713817943680419 , Val loss: 0.7063885927200317 , Accuracy: 0.5553668478260869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7874840323064902\n","AUPRC: 0.7923505294525297\n","Confusion Matrix : \n"," [[7916 3810]\n"," [3121 8769]]\n","Recall :  0.7375105130361649\n","Precision :  0.6971142380157406\n","Accuracy :  0.7065125338753387\n","Sensitivity :  0.6750810165444312\n","Specificity :  0.7375105130361649\n","Training at Epoch 18 , AUROC: 0.7874840323064902 , AUPRC: 0.7923505294525297 , F1: 0.7167436348032205 , Train loss: 0.5730909109115601 , Accuracy: 0.7065125338753387\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 19 iteration 100 with loss 0.5749724\n","Training at Epoch 19 iteration 200 with loss 0.61613137\n","Training at Epoch 19 iteration 300 with loss 0.54348916\n","optimal threshold: 0.5\n","AUROC:0.5766234181319383\n","AUPRC: 0.5661972226894336\n","Confusion Matrix : \n"," [[1586 1380]\n"," [1223 1699]]\n","Recall :  0.58145106091718\n","Precision :  0.5518025332900293\n","Accuracy :  0.5579144021739131\n","Sensitivity :  0.5347269049224544\n","Specificity :  0.58145106091718\n","Validation at Epoch 19 , AUROC: 0.5766234181319383 , AUPRC: 0.5661972226894336 , F1: 0.5662389601733044 , Val loss: 0.7129837870597839 , Accuracy: 0.5579144021739131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.7975805513869108\n","AUPRC: 0.8031229766397552\n","Confusion Matrix : \n"," [[8162 3562]\n"," [3177 8715]]\n","Recall :  0.7328456104944501\n","Precision :  0.7098639732833755\n","Accuracy :  0.7146426151761518\n","Sensitivity :  0.6961787785738656\n","Specificity :  0.7328456104944501\n","Training at Epoch 19 , AUROC: 0.7975805513869108 , AUPRC: 0.8031229766397552 , F1: 0.7211717489345857 , Train loss: 0.5617762207984924 , Accuracy: 0.7146426151761518\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 20 iteration 100 with loss 0.5966758\n","Training at Epoch 20 iteration 200 with loss 0.6628548\n","Training at Epoch 20 iteration 300 with loss 0.7016964\n","optimal threshold: 0.5\n","AUROC:0.584252400501215\n","AUPRC: 0.5690054848191133\n","Confusion Matrix : \n"," [[1709 1249]\n"," [1326 1604]]\n","Recall :  0.5474402730375426\n","Precision :  0.5622152120574834\n","Accuracy :  0.5626698369565217\n","Sensitivity :  0.5777552400270453\n","Specificity :  0.5474402730375426\n","Validation at Epoch 20 , AUROC: 0.584252400501215 , AUPRC: 0.5690054848191133 , F1: 0.5547293792149404 , Val loss: 0.7075110673904419 , Accuracy: 0.5626698369565217\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8044017102939836\n","AUPRC: 0.8094965610980541\n","Confusion Matrix : \n"," [[8616 3103]\n"," [3499 8398]]\n","Recall :  0.7058922417416156\n","Precision :  0.730197374141379\n","Accuracy :  0.7204437669376694\n","Sensitivity :  0.7352163153852718\n","Specificity :  0.7058922417416156\n","Training at Epoch 20 , AUROC: 0.8044017102939836 , AUPRC: 0.8094965610980541 , F1: 0.7178391315497051 , Train loss: 0.5569553375244141 , Accuracy: 0.7204437669376694\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 21 iteration 100 with loss 0.6681688\n","Training at Epoch 21 iteration 200 with loss 0.5830969\n","Training at Epoch 21 iteration 300 with loss 0.56832236\n","optimal threshold: 0.5\n","AUROC:0.5731697565906071\n","AUPRC: 0.5674785285271111\n","Confusion Matrix : \n"," [[1857 1103]\n"," [1495 1433]]\n","Recall :  0.48941256830601093\n","Precision :  0.5650630914826499\n","Accuracy :  0.5587635869565217\n","Sensitivity :  0.6273648648648649\n","Specificity :  0.48941256830601093\n","Validation at Epoch 21 , AUROC: 0.5731697565906071 , AUPRC: 0.5674785285271111 , F1: 0.5245241581259151 , Val loss: 0.7142593860626221 , Accuracy: 0.5587635869565217\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8127164953858835\n","AUPRC: 0.8181986448085322\n","Confusion Matrix : \n"," [[9144 2582]\n"," [3955 7935]]\n","Recall :  0.667367535744323\n","Precision :  0.7544927260625653\n","Accuracy :  0.7231961382113821\n","Sensitivity :  0.7798055602933651\n","Specificity :  0.667367535744323\n","Training at Epoch 21 , AUROC: 0.8127164953858835 , AUPRC: 0.8181986448085322 , F1: 0.7082608113535949 , Train loss: 0.5546299815177917 , Accuracy: 0.7231961382113821\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 22 iteration 100 with loss 0.6251445\n","Training at Epoch 22 iteration 200 with loss 0.5060652\n","Training at Epoch 22 iteration 300 with loss 0.6618042\n","optimal threshold: 0.5\n","AUROC:0.5758292395199299\n","AUPRC: 0.5654722272489535\n","Confusion Matrix : \n"," [[1867 1097]\n"," [1513 1411]]\n","Recall :  0.48255813953488375\n","Precision :  0.5625996810207337\n","Accuracy :  0.5567255434782609\n","Sensitivity :  0.6298920377867746\n","Specificity :  0.48255813953488375\n","Validation at Epoch 22 , AUROC: 0.5758292395199299 , AUPRC: 0.5654722272489535 , F1: 0.5195139911634757 , Val loss: 0.7253434658050537 , Accuracy: 0.5567255434782609\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8180969849307251\n","AUPRC: 0.822254611897941\n","Confusion Matrix : \n"," [[9276 2447]\n"," [4004 7889]]\n","Recall :  0.6633313713949383\n","Precision :  0.7632546439628483\n","Accuracy :  0.7268377371273713\n","Sensitivity :  0.7912650345474708\n","Specificity :  0.6633313713949383\n","Training at Epoch 22 , AUROC: 0.8180969849307251 , AUPRC: 0.822254611897941 , F1: 0.7097935129785415 , Train loss: 0.5387367606163025 , Accuracy: 0.7268377371273713\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 23 iteration 100 with loss 0.61102784\n","Training at Epoch 23 iteration 200 with loss 0.600657\n","Training at Epoch 23 iteration 300 with loss 0.6997673\n","optimal threshold: 0.5\n","AUROC:0.5692002156290442\n","AUPRC: 0.561381554286557\n","Confusion Matrix : \n"," [[1702 1262]\n"," [1394 1530]]\n","Recall :  0.5232558139534884\n","Precision :  0.5479942693409742\n","Accuracy :  0.5489130434782609\n","Sensitivity :  0.5742240215924427\n","Specificity :  0.5232558139534884\n","Validation at Epoch 23 , AUROC: 0.5692002156290442 , AUPRC: 0.561381554286557 , F1: 0.5353393981805459 , Val loss: 0.724492609500885 , Accuracy: 0.5489130434782609\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8336064999207189\n","AUPRC: 0.8411562273662075\n","Confusion Matrix : \n"," [[8990 2733]\n"," [3336 8557]]\n","Recall :  0.7194988648785\n","Precision :  0.7579273693534101\n","Accuracy :  0.7430132113821138\n","Sensitivity :  0.766868549006227\n","Specificity :  0.7194988648785\n","Training at Epoch 23 , AUROC: 0.8336064999207189 , AUPRC: 0.8411562273662075 , F1: 0.738213345986283 , Train loss: 0.5313477516174316 , Accuracy: 0.7430132113821138\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 24 iteration 100 with loss 0.5902411\n","Training at Epoch 24 iteration 200 with loss 0.5771368\n","Training at Epoch 24 iteration 300 with loss 0.4772802\n","optimal threshold: 0.5\n","AUROC:0.5753300998823657\n","AUPRC: 0.5722293336585259\n","Confusion Matrix : \n"," [[1626 1339]\n"," [1288 1635]]\n","Recall :  0.5593568251796099\n","Precision :  0.5497646267652992\n","Accuracy :  0.5538383152173914\n","Sensitivity :  0.548397976391231\n","Specificity :  0.5593568251796099\n","Validation at Epoch 24 , AUROC: 0.5753300998823657 , AUPRC: 0.5722293336585259 , F1: 0.5545192470747837 , Val loss: 0.7161233425140381 , Accuracy: 0.5538383152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8383407567152295\n","AUPRC: 0.8453392435308562\n","Confusion Matrix : \n"," [[8699 3028]\n"," [2931 8958]]\n","Recall :  0.7534695937421145\n","Precision :  0.74737193392291\n","Accuracy :  0.7476710704607046\n","Sensitivity :  0.7417924447855376\n","Specificity :  0.7534695937421145\n","Training at Epoch 24 , AUROC: 0.8383407567152295 , AUPRC: 0.8453392435308562 , F1: 0.7504083769633507 , Train loss: 0.530040979385376 , Accuracy: 0.7476710704607046\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 25 iteration 100 with loss 0.55444986\n","Training at Epoch 25 iteration 200 with loss 0.54743314\n","Training at Epoch 25 iteration 300 with loss 0.6668267\n","optimal threshold: 0.5\n","AUROC:0.5705769447112681\n","AUPRC: 0.5614618662396516\n","Confusion Matrix : \n"," [[1479 1484]\n"," [1143 1782]]\n","Recall :  0.6092307692307692\n","Precision :  0.5456215554194733\n","Accuracy :  0.5538383152173914\n","Sensitivity :  0.49915626054674317\n","Specificity :  0.6092307692307692\n","Validation at Epoch 25 , AUROC: 0.5705769447112681 , AUPRC: 0.5614618662396516 , F1: 0.5756743660151833 , Val loss: 0.7183337807655334 , Accuracy: 0.5538383152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8423837105689798\n","AUPRC: 0.8474954245621573\n","Confusion Matrix : \n"," [[8224 3505]\n"," [2423 9464]]\n","Recall :  0.7961638765037435\n","Precision :  0.7297401495874778\n","Accuracy :  0.7489837398373984\n","Sensitivity :  0.7011680450166254\n","Specificity :  0.7961638765037435\n","Training at Epoch 25 , AUROC: 0.8423837105689798 , AUPRC: 0.8474954245621573 , F1: 0.7615062761506275 , Train loss: 0.530137300491333 , Accuracy: 0.7489837398373984\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 26 iteration 100 with loss 0.6134126\n","Training at Epoch 26 iteration 200 with loss 0.57873756\n","Training at Epoch 26 iteration 300 with loss 0.6359451\n","optimal threshold: 0.5\n","AUROC:0.5694667278197484\n","AUPRC: 0.5617629215180874\n","Confusion Matrix : \n"," [[1633 1330]\n"," [1311 1614]]\n","Recall :  0.5517948717948717\n","Precision :  0.548233695652174\n","Accuracy :  0.5514605978260869\n","Sensitivity :  0.5511306108673641\n","Specificity :  0.5517948717948717\n","Validation at Epoch 26 , AUROC: 0.5694667278197484 , AUPRC: 0.5617629215180874 , F1: 0.5500085193388993 , Val loss: 0.741432785987854 , Accuracy: 0.5514605978260869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8582655147484175\n","AUPRC: 0.8648210132391054\n","Confusion Matrix : \n"," [[9061 2661]\n"," [2882 9012]]\n","Recall :  0.7576929544308054\n","Precision :  0.7720380364944744\n","Accuracy :  0.7652862466124661\n","Sensitivity :  0.7729909571745436\n","Specificity :  0.7576929544308054\n","Training at Epoch 26 , AUROC: 0.8582655147484175 , AUPRC: 0.8648210132391054 , F1: 0.7647982348198753 , Train loss: 0.4981580078601837 , Accuracy: 0.7652862466124661\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 27 iteration 100 with loss 0.57560265\n","Training at Epoch 27 iteration 200 with loss 0.45523772\n","Training at Epoch 27 iteration 300 with loss 0.6201519\n","optimal threshold: 0.5\n","AUROC:0.5666205935117736\n","AUPRC: 0.5568942682480885\n","Confusion Matrix : \n"," [[1714 1252]\n"," [1382 1540]]\n","Recall :  0.5270362765229295\n","Precision :  0.5515759312320917\n","Accuracy :  0.5526494565217391\n","Sensitivity :  0.5778826702629805\n","Specificity :  0.5270362765229295\n","Validation at Epoch 27 , AUROC: 0.5666205935117736 , AUPRC: 0.5568942682480885 , F1: 0.5390269513475673 , Val loss: 0.7662122845649719 , Accuracy: 0.5526494565217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8651318379116129\n","AUPRC: 0.871614011425381\n","Confusion Matrix : \n"," [[9327 2397]\n"," [2983 8909]]\n","Recall :  0.7491590985536495\n","Precision :  0.7879886785777463\n","Accuracy :  0.7721883468834688\n","Sensitivity :  0.7955475946775844\n","Specificity :  0.7491590985536495\n","Training at Epoch 27 , AUROC: 0.8651318379116129 , AUPRC: 0.871614011425381 , F1: 0.7680834554702992 , Train loss: 0.48102959990501404 , Accuracy: 0.7721883468834688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 28 iteration 100 with loss 0.48958838\n","Training at Epoch 28 iteration 200 with loss 0.5647202\n","Training at Epoch 28 iteration 300 with loss 0.62044126\n","optimal threshold: 0.5\n","AUROC:0.5670050213800949\n","AUPRC: 0.5572260748747403\n","Confusion Matrix : \n"," [[1816 1142]\n"," [1469 1461]]\n","Recall :  0.49863481228668943\n","Precision :  0.5612754514022282\n","Accuracy :  0.5565557065217391\n","Sensitivity :  0.6139283299526708\n","Specificity :  0.49863481228668943\n","Validation at Epoch 28 , AUROC: 0.5670050213800949 , AUPRC: 0.5572260748747403 , F1: 0.5281041026567865 , Val loss: 0.7405056357383728 , Accuracy: 0.5565557065217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8711983508881144\n","AUPRC: 0.8775539977712302\n","Confusion Matrix : \n"," [[9612 2110]\n"," [3250 8644]]\n","Recall :  0.7267529846981672\n","Precision :  0.803793937139669\n","Accuracy :  0.7730352303523035\n","Sensitivity :  0.8199965876130353\n","Specificity :  0.7267529846981672\n","Training at Epoch 28 , AUROC: 0.8711983508881144 , AUPRC: 0.8775539977712302 , F1: 0.7633345107735783 , Train loss: 0.495688259601593 , Accuracy: 0.7730352303523035\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 29 iteration 100 with loss 0.5669471\n","Training at Epoch 29 iteration 200 with loss 0.49095333\n","Training at Epoch 29 iteration 300 with loss 0.52606165\n","optimal threshold: 0.5\n","AUROC:0.5602948223269661\n","AUPRC: 0.5505715490635513\n","Confusion Matrix : \n"," [[1767 1194]\n"," [1462 1465]]\n","Recall :  0.5005124701059105\n","Precision :  0.5509590071455435\n","Accuracy :  0.5489130434782609\n","Sensitivity :  0.596757852077001\n","Specificity :  0.5005124701059105\n","Validation at Epoch 29 , AUROC: 0.5602948223269661 , AUPRC: 0.5505715490635513 , F1: 0.5245255997135697 , Val loss: 0.7781301140785217 , Accuracy: 0.5489130434782609\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8669326211122103\n","AUPRC: 0.8737969099938583\n","Confusion Matrix : \n"," [[9475 2245]\n"," [3173 8723]]\n","Recall :  0.7332716879623403\n","Precision :  0.7953136396790663\n","Accuracy :  0.770579268292683\n","Sensitivity :  0.8084470989761092\n","Specificity :  0.7332716879623403\n","Training at Epoch 29 , AUROC: 0.8669326211122103 , AUPRC: 0.8737969099938583 , F1: 0.7630335899230231 , Train loss: 0.47623658180236816 , Accuracy: 0.770579268292683\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 30 iteration 100 with loss 0.47906363\n","Training at Epoch 30 iteration 200 with loss 0.50541025\n","Training at Epoch 30 iteration 300 with loss 0.5228173\n","optimal threshold: 0.5\n","AUROC:0.5622140475930036\n","AUPRC: 0.5565866217252696\n","Confusion Matrix : \n"," [[1756 1210]\n"," [1470 1452]]\n","Recall :  0.49691991786447637\n","Precision :  0.5454545454545454\n","Accuracy :  0.5448369565217391\n","Sensitivity :  0.5920431557653405\n","Specificity :  0.49691991786447637\n","Validation at Epoch 30 , AUROC: 0.5622140475930036 , AUPRC: 0.5565866217252696 , F1: 0.5200573065902578 , Val loss: 0.7426572442054749 , Accuracy: 0.5448369565217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8847149240429103\n","AUPRC: 0.8906617597496393\n","Confusion Matrix : \n"," [[9705 2021]\n"," [2996 8894]]\n","Recall :  0.7480235492010092\n","Precision :  0.8148419606046725\n","Accuracy :  0.7875592818428184\n","Sensitivity :  0.8276479617943032\n","Specificity :  0.7480235492010092\n","Training at Epoch 30 , AUROC: 0.8847149240429103 , AUPRC: 0.8906617597496393 , F1: 0.7800043850032888 , Train loss: 0.4783618152141571 , Accuracy: 0.7875592818428184\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 31 iteration 100 with loss 0.5062821\n","Training at Epoch 31 iteration 200 with loss 0.5844381\n","Training at Epoch 31 iteration 300 with loss 0.5179125\n","optimal threshold: 0.5\n","AUROC:0.5600068398853004\n","AUPRC: 0.5523004956012021\n","Confusion Matrix : \n"," [[1554 1408]\n"," [1252 1674]]\n","Recall :  0.5721120984278879\n","Precision :  0.5431537962362103\n","Accuracy :  0.548233695652174\n","Sensitivity :  0.5246455097906819\n","Specificity :  0.5721120984278879\n","Validation at Epoch 31 , AUROC: 0.5600068398853004 , AUPRC: 0.5523004956012021 , F1: 0.5572569906790945 , Val loss: 0.7789651155471802 , Accuracy: 0.548233695652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8866477160657554\n","AUPRC: 0.8933872893652538\n","Confusion Matrix : \n"," [[9122 2604]\n"," [2351 9539]]\n","Recall :  0.8022708158116064\n","Precision :  0.7855554640533641\n","Accuracy :  0.790184620596206\n","Sensitivity :  0.7779293876854853\n","Specificity :  0.8022708158116064\n","Training at Epoch 31 , AUROC: 0.8866477160657554 , AUPRC: 0.8933872893652538 , F1: 0.7938251570756877 , Train loss: 0.45510026812553406 , Accuracy: 0.790184620596206\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 32 iteration 100 with loss 0.46227133\n","Training at Epoch 32 iteration 200 with loss 0.6073016\n","Training at Epoch 32 iteration 300 with loss 0.56608903\n","optimal threshold: 0.5\n","AUROC:0.5596695763101819\n","AUPRC: 0.5533327450040089\n","Confusion Matrix : \n"," [[1631 1331]\n"," [1356 1570]]\n","Recall :  0.5365686944634313\n","Precision :  0.541192692175112\n","Accuracy :  0.5436480978260869\n","Sensitivity :  0.550641458474004\n","Specificity :  0.5365686944634313\n","Validation at Epoch 32 , AUROC: 0.5596695763101819 , AUPRC: 0.5533327450040089 , F1: 0.5388707739831818 , Val loss: 0.7786145806312561 , Accuracy: 0.5436480978260869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.8965710751260217\n","AUPRC: 0.9016194718724069\n","Confusion Matrix : \n"," [[9503 2226]\n"," [2376 9511]]\n","Recall :  0.8001177757213763\n","Precision :  0.8103433586095254\n","Accuracy :  0.8051321138211383\n","Sensitivity :  0.8102139994884474\n","Specificity :  0.8001177757213763\n","Training at Epoch 32 , AUROC: 0.8965710751260217 , AUPRC: 0.9016194718724069 , F1: 0.8051981036234337 , Train loss: 0.4437253475189209 , Accuracy: 0.8051321138211383\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 33 iteration 100 with loss 0.5127859\n","Training at Epoch 33 iteration 200 with loss 0.55838317\n","Training at Epoch 33 iteration 300 with loss 0.77308047\n","optimal threshold: 0.5\n","AUROC:0.5618460277394315\n","AUPRC: 0.5543864697541047\n","Confusion Matrix : \n"," [[1537 1429]\n"," [1241 1681]]\n","Recall :  0.5752908966461328\n","Precision :  0.5405144694533762\n","Accuracy :  0.5465353260869565\n","Sensitivity :  0.5182063385030344\n","Specificity :  0.5752908966461328\n","Validation at Epoch 33 , AUROC: 0.5618460277394315 , AUPRC: 0.5543864697541047 , F1: 0.5573607427055703 , Val loss: 0.7772517800331116 , Accuracy: 0.5465353260869565\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9024767113479686\n","AUPRC: 0.9079861471463482\n","Confusion Matrix : \n"," [[9214 2513]\n"," [1972 9917]]\n","Recall :  0.8341323912860628\n","Precision :  0.7978278358809332\n","Accuracy :  0.8100863821138211\n","Sensitivity :  0.7857081947642193\n","Specificity :  0.8341323912860628\n","Training at Epoch 33 , AUROC: 0.9024767113479686 , AUPRC: 0.9079861471463482 , F1: 0.8155762983675315 , Train loss: 0.4396975636482239 , Accuracy: 0.8100863821138211\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 34 iteration 100 with loss 0.4754683\n","Training at Epoch 34 iteration 200 with loss 0.47820285\n","Training at Epoch 34 iteration 300 with loss 0.6817903\n","optimal threshold: 0.5\n","AUROC:0.560729782229558\n","AUPRC: 0.5568633220777768\n","Confusion Matrix : \n"," [[1718 1247]\n"," [1408 1515]]\n","Recall :  0.5183031132398221\n","Precision :  0.5485155684286749\n","Accuracy :  0.5490828804347826\n","Sensitivity :  0.5794266441821248\n","Specificity :  0.5183031132398221\n","Validation at Epoch 34 , AUROC: 0.560729782229558 , AUPRC: 0.5568633220777768 , F1: 0.532981530343008 , Val loss: 0.7893416285514832 , Accuracy: 0.5490828804347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9038024457765715\n","AUPRC: 0.9096098644171294\n","Confusion Matrix : \n"," [[9798 1927]\n"," [2600 9291]]\n","Recall :  0.7813472374064419\n","Precision :  0.8282224995542877\n","Accuracy :  0.8083079268292683\n","Sensitivity :  0.8356503198294243\n","Specificity :  0.7813472374064419\n","Training at Epoch 34 , AUROC: 0.9038024457765715 , AUPRC: 0.9096098644171294 , F1: 0.8041022978060496 , Train loss: 0.43088772892951965 , Accuracy: 0.8083079268292683\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 35 iteration 100 with loss 0.55326957\n","Training at Epoch 35 iteration 200 with loss 0.68140817\n","Training at Epoch 35 iteration 300 with loss 0.53344065\n","optimal threshold: 0.5\n","AUROC:0.5629531169321922\n","AUPRC: 0.5523405515466947\n","Confusion Matrix : \n"," [[1626 1337]\n"," [1318 1607]]\n","Recall :  0.5494017094017094\n","Precision :  0.5458559782608695\n","Accuracy :  0.5490828804347826\n","Sensitivity :  0.5487681403982451\n","Specificity :  0.5494017094017094\n","Validation at Epoch 35 , AUROC: 0.5629531169321922 , AUPRC: 0.5523405515466947 , F1: 0.5476231044470948 , Val loss: 0.7862825393676758 , Accuracy: 0.5490828804347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9030100204791962\n","AUPRC: 0.9103601384803395\n","Confusion Matrix : \n"," [[9448 2277]\n"," [2278 9613]]\n","Recall :  0.8084265410814903\n","Precision :  0.8084945332211942\n","Accuracy :  0.8071222899728997\n","Sensitivity :  0.8057995735607676\n","Specificity :  0.8084265410814903\n","Training at Epoch 35 , AUROC: 0.9030100204791962 , AUPRC: 0.9103601384803395 , F1: 0.8084605357217947 , Train loss: 0.43347984552383423 , Accuracy: 0.8071222899728997\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 36 iteration 100 with loss 0.41362512\n","Training at Epoch 36 iteration 200 with loss 0.59825575\n","Training at Epoch 36 iteration 300 with loss 0.5107243\n","optimal threshold: 0.5\n","AUROC:0.5613681615461196\n","AUPRC: 0.5498849648055036\n","Confusion Matrix : \n"," [[1714 1252]\n"," [1423 1499]]\n","Recall :  0.5130047912388774\n","Precision :  0.544892766266812\n","Accuracy :  0.5456861413043478\n","Sensitivity :  0.5778826702629805\n","Specificity :  0.5130047912388774\n","Validation at Epoch 36 , AUROC: 0.5613681615461196 , AUPRC: 0.5498849648055036 , F1: 0.5284681826194253 , Val loss: 0.7983519434928894 , Accuracy: 0.5456861413043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9153237933311821\n","AUPRC: 0.9205203996694465\n","Confusion Matrix : \n"," [[9862 1871]\n"," [2351 9532]]\n","Recall :  0.8021543381301018\n","Precision :  0.8359203718319741\n","Accuracy :  0.8212228997289973\n","Sensitivity :  0.8405352424784795\n","Specificity :  0.8021543381301018\n","Training at Epoch 36 , AUROC: 0.9153237933311821 , AUPRC: 0.9205203996694465 , F1: 0.818689341235077 , Train loss: 0.4134114682674408 , Accuracy: 0.8212228997289973\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 37 iteration 100 with loss 0.46063495\n","Training at Epoch 37 iteration 200 with loss 0.38426957\n","Training at Epoch 37 iteration 300 with loss 0.5238361\n","optimal threshold: 0.5\n","AUROC:0.5650845947078578\n","AUPRC: 0.5590059581572944\n","Confusion Matrix : \n"," [[1644 1320]\n"," [1353 1571]]\n","Recall :  0.5372777017783857\n","Precision :  0.5434105845728122\n","Accuracy :  0.5460258152173914\n","Sensitivity :  0.5546558704453441\n","Specificity :  0.5372777017783857\n","Validation at Epoch 37 , AUROC: 0.5650845947078578 , AUPRC: 0.5590059581572944 , F1: 0.5403267411865864 , Val loss: 0.81216961145401 , Accuracy: 0.5460258152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9195392895939638\n","AUPRC: 0.9246436198719001\n","Confusion Matrix : \n"," [[9638 2090]\n"," [1992 9896]]\n","Recall :  0.8324360699865411\n","Precision :  0.8256299015518105\n","Accuracy :  0.8271510840108401\n","Sensitivity :  0.821793997271487\n","Specificity :  0.8324360699865411\n","Training at Epoch 37 , AUROC: 0.9195392895939638 , AUPRC: 0.9246436198719001 , F1: 0.829019016503309 , Train loss: 0.39651986956596375 , Accuracy: 0.8271510840108401\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 38 iteration 100 with loss 0.46030653\n","Training at Epoch 38 iteration 200 with loss 0.45682162\n","Training at Epoch 38 iteration 300 with loss 0.56674325\n","optimal threshold: 0.5\n","AUROC:0.5635585158310729\n","AUPRC: 0.5566202483541145\n","Confusion Matrix : \n"," [[1593 1366]\n"," [1292 1637]]\n","Recall :  0.5588938204165244\n","Precision :  0.5451215451215451\n","Accuracy :  0.5485733695652174\n","Sensitivity :  0.5383575532274417\n","Specificity :  0.5588938204165244\n","Validation at Epoch 38 , AUROC: 0.5635585158310729 , AUPRC: 0.5566202483541145 , F1: 0.5519217801753202 , Val loss: 0.8042152523994446 , Accuracy: 0.5485733695652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9232203795973732\n","AUPRC: 0.9278936149310308\n","Confusion Matrix : \n"," [[ 9627  2100]\n"," [ 1862 10027]]\n","Recall :  0.8433846412650349\n","Precision :  0.8268326873917704\n","Accuracy :  0.8322323848238482\n","Sensitivity :  0.8209260680480941\n","Specificity :  0.8433846412650349\n","Training at Epoch 38 , AUROC: 0.9232203795973732 , AUPRC: 0.9278936149310308 , F1: 0.8350266489007327 , Train loss: 0.39760318398475647 , Accuracy: 0.8322323848238482\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 39 iteration 100 with loss 0.52576274\n","Training at Epoch 39 iteration 200 with loss 0.55819833\n","Training at Epoch 39 iteration 300 with loss 0.5544425\n","optimal threshold: 0.5\n","AUROC:0.5532015276143677\n","AUPRC: 0.5451177661550914\n","Confusion Matrix : \n"," [[1624 1337]\n"," [1347 1580]]\n","Recall :  0.5398018448923813\n","Precision :  0.5416523825848475\n","Accuracy :  0.5441576086956522\n","Sensitivity :  0.5484633569739953\n","Specificity :  0.5398018448923813\n","Validation at Epoch 39 , AUROC: 0.5532015276143677 , AUPRC: 0.5451177661550914 , F1: 0.54072553045859 , Val loss: 0.8082175850868225 , Accuracy: 0.5441576086956522\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9194665259906123\n","AUPRC: 0.9241849111788956\n","Confusion Matrix : \n"," [[9777 1948]\n"," [2150 9741]]\n","Recall :  0.8191909847784038\n","Precision :  0.83334759175293\n","Accuracy :  0.8264735772357723\n","Sensitivity :  0.8338592750533049\n","Specificity :  0.8191909847784038\n","Training at Epoch 39 , AUROC: 0.9194665259906123 , AUPRC: 0.9241849111788956 , F1: 0.8262086513994911 , Train loss: 0.40718355774879456 , Accuracy: 0.8264735772357723\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 40 iteration 100 with loss 0.41823703\n","Training at Epoch 40 iteration 200 with loss 0.49083748\n","Training at Epoch 40 iteration 300 with loss 0.5078386\n","optimal threshold: 0.5\n","AUROC:0.5544795497748586\n","AUPRC: 0.5512546778242137\n","Confusion Matrix : \n"," [[1677 1286]\n"," [1402 1523]]\n","Recall :  0.5206837606837607\n","Precision :  0.542185831256675\n","Accuracy :  0.5434782608695652\n","Sensitivity :  0.5659804252446844\n","Specificity :  0.5206837606837607\n","Validation at Epoch 40 , AUROC: 0.5544795497748586 , AUPRC: 0.5512546778242137 , F1: 0.531217300313917 , Val loss: 0.8356121182441711 , Accuracy: 0.5434782608695652\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9333736512726903\n","AUPRC: 0.9373504275164376\n","Confusion Matrix : \n"," [[10129  1595]\n"," [ 2114  9778]]\n","Recall :  0.8222334342415069\n","Precision :  0.8597555614173921\n","Accuracy :  0.8429454607046071\n","Sensitivity :  0.8639542818150802\n","Specificity :  0.8222334342415069\n","Training at Epoch 40 , AUROC: 0.9333736512726903 , AUPRC: 0.9373504275164376 , F1: 0.840575972490866 , Train loss: 0.3774486184120178 , Accuracy: 0.8429454607046071\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 41 iteration 100 with loss 0.6346047\n","Training at Epoch 41 iteration 200 with loss 0.48977005\n","Training at Epoch 41 iteration 300 with loss 0.49255216\n","optimal threshold: 0.5\n","AUROC:0.5593337118611232\n","AUPRC: 0.5508442459837701\n","Confusion Matrix : \n"," [[1553 1406]\n"," [1280 1649]]\n","Recall :  0.5629907818368044\n","Precision :  0.5397708674304419\n","Accuracy :  0.5438179347826086\n","Sensitivity :  0.5248394727948631\n","Specificity :  0.5629907818368044\n","Validation at Epoch 41 , AUROC: 0.5593337118611232 , AUPRC: 0.5508442459837701 , F1: 0.5511363636363636 , Val loss: 0.8103209137916565 , Accuracy: 0.5438179347826086\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9338296449903867\n","AUPRC: 0.9381919596813847\n","Confusion Matrix : \n"," [[ 9788  1938]\n"," [ 1680 10210]]\n","Recall :  0.8587047939444912\n","Precision :  0.8404675666776424\n","Accuracy :  0.8467987804878049\n","Sensitivity :  0.8347262493603957\n","Specificity :  0.8587047939444912\n","Training at Epoch 41 , AUROC: 0.9338296449903867 , AUPRC: 0.9381919596813847 , F1: 0.8494883101755554 , Train loss: 0.38526374101638794 , Accuracy: 0.8467987804878049\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 42 iteration 100 with loss 0.60988456\n","Training at Epoch 42 iteration 200 with loss 0.49664843\n","Training at Epoch 42 iteration 300 with loss 0.43483782\n","optimal threshold: 0.5\n","AUROC:0.5545094379613998\n","AUPRC: 0.5473968905019104\n","Confusion Matrix : \n"," [[1593 1364]\n"," [1340 1591]]\n","Recall :  0.5428181508017741\n","Precision :  0.538409475465313\n","Accuracy :  0.5407608695652174\n","Sensitivity :  0.5387216773757186\n","Specificity :  0.5428181508017741\n","Validation at Epoch 42 , AUROC: 0.5545094379613998 , AUPRC: 0.5473968905019104 , F1: 0.5406048250084947 , Val loss: 0.8246757984161377 , Accuracy: 0.5407608695652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9422542096140367\n","AUPRC: 0.9461815932185214\n","Confusion Matrix : \n"," [[10102  1622]\n"," [ 1783 10109]]\n","Recall :  0.850067272115708\n","Precision :  0.8617338675304748\n","Accuracy :  0.8558180894308943\n","Sensitivity :  0.8616513135448652\n","Specificity :  0.850067272115708\n","Training at Epoch 42 , AUROC: 0.9422542096140367 , AUPRC: 0.9461815932185214 , F1: 0.8558608136138508 , Train loss: 0.36741873621940613 , Accuracy: 0.8558180894308943\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 43 iteration 100 with loss 0.42198402\n","Training at Epoch 43 iteration 200 with loss 0.39883244\n","Training at Epoch 43 iteration 300 with loss 0.4318012\n","optimal threshold: 0.5\n","AUROC:0.5609401088807766\n","AUPRC: 0.5521316071296749\n","Confusion Matrix : \n"," [[1592 1367]\n"," [1302 1627]]\n","Recall :  0.5554796858996245\n","Precision :  0.5434201736806947\n","Accuracy :  0.5467051630434783\n","Sensitivity :  0.5380196012166273\n","Specificity :  0.5554796858996245\n","Validation at Epoch 43 , AUROC: 0.5609401088807766 , AUPRC: 0.5521316071296749 , F1: 0.5493837582306265 , Val loss: 0.8427947759628296 , Accuracy: 0.5467051630434783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9430239538146306\n","AUPRC: 0.9466058756510648\n","Confusion Matrix : \n"," [[ 9912  1810]\n"," [ 1578 10316]]\n","Recall :  0.8673280645703716\n","Precision :  0.8507339600857661\n","Accuracy :  0.8565379403794038\n","Sensitivity :  0.8455894898481487\n","Specificity :  0.8673280645703716\n","Training at Epoch 43 , AUROC: 0.9430239538146306 , AUPRC: 0.9466058756510648 , F1: 0.8589508742714403 , Train loss: 0.35140448808670044 , Accuracy: 0.8565379403794038\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 44 iteration 100 with loss 0.47274238\n","Training at Epoch 44 iteration 200 with loss 0.39974868\n","Training at Epoch 44 iteration 300 with loss 0.5110872\n","optimal threshold: 0.5\n","AUROC:0.5560542993212585\n","AUPRC: 0.5491431899579041\n","Confusion Matrix : \n"," [[1518 1445]\n"," [1253 1672]]\n","Recall :  0.5716239316239317\n","Precision :  0.5364132178376644\n","Accuracy :  0.5417798913043478\n","Sensitivity :  0.5123185960175498\n","Specificity :  0.5716239316239317\n","Validation at Epoch 44 , AUROC: 0.5560542993212585 , AUPRC: 0.5491431899579041 , F1: 0.5534591194968554 , Val loss: 0.8411844372749329 , Accuracy: 0.5417798913043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9459544987395372\n","AUPRC: 0.948294575616162\n","Confusion Matrix : \n"," [[ 9746  1978]\n"," [ 1332 10560]]\n","Recall :  0.887991927346115\n","Precision :  0.8422395916414102\n","Accuracy :  0.8598407859078591\n","Sensitivity :  0.8312862504264756\n","Specificity :  0.887991927346115\n","Training at Epoch 44 , AUROC: 0.9459544987395372 , AUPRC: 0.948294575616162 , F1: 0.8645108473188702 , Train loss: 0.3542536795139313 , Accuracy: 0.8598407859078591\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 45 iteration 100 with loss 0.37349457\n","Training at Epoch 45 iteration 200 with loss 0.3577054\n","Training at Epoch 45 iteration 300 with loss 0.5547479\n","optimal threshold: 0.5\n","AUROC:0.5573525767029446\n","AUPRC: 0.5483394883853727\n","Confusion Matrix : \n"," [[1565 1397]\n"," [1276 1650]]\n","Recall :  0.5639097744360902\n","Precision :  0.5415162454873647\n","Accuracy :  0.5460258152173914\n","Sensitivity :  0.5283592167454423\n","Specificity :  0.5639097744360902\n","Validation at Epoch 45 , AUROC: 0.5573525767029446 , AUPRC: 0.5483394883853727 , F1: 0.5524861878453039 , Val loss: 0.8592510223388672 , Accuracy: 0.5460258152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9519211466225443\n","AUPRC: 0.9550054617335082\n","Confusion Matrix : \n"," [[10004  1717]\n"," [ 1354 10541]]\n","Recall :  0.8861706599411517\n","Precision :  0.8599282101484744\n","Accuracy :  0.8699610433604336\n","Sensitivity :  0.8535107925944885\n","Specificity :  0.8861706599411517\n","Training at Epoch 45 , AUROC: 0.9519211466225443 , AUPRC: 0.9550054617335082 , F1: 0.872852233676976 , Train loss: 0.3354521095752716 , Accuracy: 0.8699610433604336\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 46 iteration 100 with loss 0.49273077\n","Training at Epoch 46 iteration 200 with loss 0.5168359\n","Training at Epoch 46 iteration 300 with loss 0.41378212\n","optimal threshold: 0.5\n","AUROC:0.550379259895141\n","AUPRC: 0.5446137943494413\n","Confusion Matrix : \n"," [[1657 1303]\n"," [1396 1532]]\n","Recall :  0.523224043715847\n","Precision :  0.5403880070546737\n","Accuracy :  0.541610054347826\n","Sensitivity :  0.5597972972972973\n","Specificity :  0.523224043715847\n","Validation at Epoch 46 , AUROC: 0.550379259895141 , AUPRC: 0.5446137943494413 , F1: 0.5316675342703452 , Val loss: 0.8531655073165894 , Accuracy: 0.541610054347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.953993652834741\n","AUPRC: 0.9567918375329414\n","Confusion Matrix : \n"," [[10362  1359]\n"," [ 1691 10204]]\n","Recall :  0.8578394283312316\n","Precision :  0.8824699472455245\n","Accuracy :  0.8708502710027101\n","Sensitivity :  0.8840542615817762\n","Specificity :  0.8578394283312316\n","Training at Epoch 46 , AUROC: 0.953993652834741 , AUPRC: 0.9567918375329414 , F1: 0.8699803904851223 , Train loss: 0.3404915928840637 , Accuracy: 0.8708502710027101\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 47 iteration 100 with loss 0.38577908\n","Training at Epoch 47 iteration 200 with loss 0.48194742\n","Training at Epoch 47 iteration 300 with loss 0.35925102\n","optimal threshold: 0.5\n","AUROC:0.5575000343262089\n","AUPRC: 0.5502493996146713\n","Confusion Matrix : \n"," [[1623 1338]\n"," [1352 1575]]\n","Recall :  0.538093611206013\n","Precision :  0.5406797116374872\n","Accuracy :  0.5431385869565217\n","Sensitivity :  0.5481256332320162\n","Specificity :  0.538093611206013\n","Validation at Epoch 47 , AUROC: 0.5575000343262089 , AUPRC: 0.5502493996146713 , F1: 0.5393835616438356 , Val loss: 0.8714556694030762 , Accuracy: 0.5431385869565217\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9497964506671203\n","AUPRC: 0.9534274362490398\n","Confusion Matrix : \n"," [[10214  1511]\n"," [ 1602 10289]]\n","Recall :  0.8652762593558153\n","Precision :  0.8719491525423729\n","Accuracy :  0.8681825880758808\n","Sensitivity :  0.8711300639658849\n","Specificity :  0.8652762593558153\n","Training at Epoch 47 , AUROC: 0.9497964506671203 , AUPRC: 0.9534274362490398 , F1: 0.8685998902536828 , Train loss: 0.33609911799430847 , Accuracy: 0.8681825880758808\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 48 iteration 100 with loss 0.40648633\n","Training at Epoch 48 iteration 200 with loss 0.39707842\n","Training at Epoch 48 iteration 300 with loss 0.52105397\n","optimal threshold: 0.5\n","AUROC:0.5528652288753928\n","AUPRC: 0.5471299680487519\n","Confusion Matrix : \n"," [[1639 1323]\n"," [1419 1507]]\n","Recall :  0.5150375939849624\n","Precision :  0.5325088339222614\n","Accuracy :  0.5343070652173914\n","Sensitivity :  0.5533423362592843\n","Specificity :  0.5150375939849624\n","Validation at Epoch 48 , AUROC: 0.5528652288753928 , AUPRC: 0.5471299680487519 , F1: 0.5236275191104933 , Val loss: 0.870747447013855 , Accuracy: 0.5343070652173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9574565479741879\n","AUPRC: 0.9603006876491396\n","Confusion Matrix : \n"," [[10454  1270]\n"," [ 1671 10221]]\n","Recall :  0.8594853683148335\n","Precision :  0.8894787224784614\n","Accuracy :  0.8754657859078591\n","Sensitivity :  0.8916751961787786\n","Specificity :  0.8594853683148335\n","Training at Epoch 48 , AUROC: 0.9574565479741879 , AUPRC: 0.9603006876491396 , F1: 0.8742248642175939 , Train loss: 0.3231549561023712 , Accuracy: 0.8754657859078591\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 49 iteration 100 with loss 0.34534407\n","Training at Epoch 49 iteration 200 with loss 0.42845577\n","Training at Epoch 49 iteration 300 with loss 0.45705685\n","optimal threshold: 0.5\n","AUROC:0.5514965246300068\n","AUPRC: 0.5448054369263958\n","Confusion Matrix : \n"," [[1626 1335]\n"," [1396 1531]]\n","Recall :  0.523061154765972\n","Precision :  0.5341939986043266\n","Accuracy :  0.5361752717391305\n","Sensitivity :  0.5491388044579534\n","Specificity :  0.523061154765972\n","Validation at Epoch 49 , AUROC: 0.5514965246300068 , AUPRC: 0.5448054369263958 , F1: 0.5285689625409977 , Val loss: 0.8932079076766968 , Accuracy: 0.5361752717391305\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9598661136283644\n","AUPRC: 0.9619104720208115\n","Confusion Matrix : \n"," [[10236  1488]\n"," [ 1344 10548]]\n","Recall :  0.8869828456104945\n","Precision :  0.8763708873379861\n","Accuracy :  0.8800813008130082\n","Sensitivity :  0.8730808597748209\n","Specificity :  0.8869828456104945\n","Training at Epoch 49 , AUROC: 0.9598661136283644 , AUPRC: 0.9619104720208115 , F1: 0.8816449348044133 , Train loss: 0.3137679398059845 , Accuracy: 0.8800813008130082\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 50 iteration 100 with loss 0.38443393\n","Training at Epoch 50 iteration 200 with loss 0.40614083\n","Training at Epoch 50 iteration 300 with loss 0.4046994\n","optimal threshold: 0.5\n","AUROC:0.5487399175810387\n","AUPRC: 0.5398995828139157\n","Confusion Matrix : \n"," [[1485 1480]\n"," [1238 1685]]\n","Recall :  0.5764625384878549\n","Precision :  0.5323854660347551\n","Accuracy :  0.5383831521739131\n","Sensitivity :  0.5008431703204047\n","Specificity :  0.5764625384878549\n","Validation at Epoch 50 , AUROC: 0.5487399175810387 , AUPRC: 0.5398995828139157 , F1: 0.5535479632063075 , Val loss: 0.8822265267372131 , Accuracy: 0.5383831521739131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9640532510425966\n","AUPRC: 0.9665800083520613\n","Confusion Matrix : \n"," [[10071  1649]\n"," [ 1030 10866]]\n","Recall :  0.9134162743779422\n","Precision :  0.8682381142628846\n","Accuracy :  0.8865599593495935\n","Sensitivity :  0.8593003412969283\n","Specificity :  0.9134162743779422\n","Training at Epoch 50 , AUROC: 0.9640532510425966 , AUPRC: 0.9665800083520613 , F1: 0.890254393511122 , Train loss: 0.30899307131767273 , Accuracy: 0.8865599593495935\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 51 iteration 100 with loss 0.5119646\n","Training at Epoch 51 iteration 200 with loss 0.46839666\n","Training at Epoch 51 iteration 300 with loss 0.5147593\n","optimal threshold: 0.5\n","AUROC:0.5553834629825587\n","AUPRC: 0.5457385729136233\n","Confusion Matrix : \n"," [[1648 1313]\n"," [1393 1534]]\n","Recall :  0.524086094977793\n","Precision :  0.5388127853881278\n","Accuracy :  0.540421195652174\n","Sensitivity :  0.5565687267814927\n","Specificity :  0.524086094977793\n","Validation at Epoch 51 , AUROC: 0.5553834629825587 , AUPRC: 0.5457385729136233 , F1: 0.5313474194665744 , Val loss: 0.8682553172111511 , Accuracy: 0.540421195652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9602957777306245\n","AUPRC: 0.9626259518286018\n","Confusion Matrix : \n"," [[10522  1206]\n"," [ 1573 10315]]\n","Recall :  0.8676816958277255\n","Precision :  0.895321586667824\n","Accuracy :  0.88232554200542\n","Sensitivity :  0.897169167803547\n","Specificity :  0.8676816958277255\n","Training at Epoch 51 , AUROC: 0.9602957777306245 , AUPRC: 0.9626259518286018 , F1: 0.881284975863984 , Train loss: 0.3140958547592163 , Accuracy: 0.88232554200542\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 52 iteration 100 with loss 0.4639146\n","Training at Epoch 52 iteration 200 with loss 0.40650815\n","Training at Epoch 52 iteration 300 with loss 0.5354017\n","optimal threshold: 0.5\n","AUROC:0.5524215401603495\n","AUPRC: 0.5421743980277622\n","Confusion Matrix : \n"," [[1603 1362]\n"," [1367 1556]]\n","Recall :  0.532329798152583\n","Precision :  0.5332419465387251\n","Accuracy :  0.536514945652174\n","Sensitivity :  0.5406408094435076\n","Specificity :  0.532329798152583\n","Validation at Epoch 52 , AUROC: 0.5524215401603495 , AUPRC: 0.5421743980277622 , F1: 0.5327854819380243 , Val loss: 0.9004418253898621 , Accuracy: 0.536514945652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9679730553018079\n","AUPRC: 0.969862529345893\n","Confusion Matrix : \n"," [[10486  1234]\n"," [ 1214 10682]]\n","Recall :  0.8979488903833222\n","Precision :  0.8964417589795234\n","Accuracy :  0.8963414634146342\n","Sensitivity :  0.8947098976109215\n","Specificity :  0.8979488903833222\n","Training at Epoch 52 , AUROC: 0.9679730553018079 , AUPRC: 0.969862529345893 , F1: 0.8971946917520578 , Train loss: 0.2903064489364624 , Accuracy: 0.8963414634146342\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 53 iteration 100 with loss 0.34781292\n","Training at Epoch 53 iteration 200 with loss 0.4472101\n","Training at Epoch 53 iteration 300 with loss 0.34030744\n","optimal threshold: 0.5\n","AUROC:0.5595248410881339\n","AUPRC: 0.550462179995723\n","Confusion Matrix : \n"," [[1738 1221]\n"," [1454 1475]]\n","Recall :  0.5035848412427449\n","Precision :  0.547106824925816\n","Accuracy :  0.5456861413043478\n","Sensitivity :  0.587360594795539\n","Specificity :  0.5035848412427449\n","Validation at Epoch 53 , AUROC: 0.5595248410881339 , AUPRC: 0.550462179995723 , F1: 0.5244444444444444 , Val loss: 0.8863523602485657 , Accuracy: 0.5456861413043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9684310864768013\n","AUPRC: 0.9701974081121714\n","Confusion Matrix : \n"," [[10639  1085]\n"," [ 1424 10468]]\n","Recall :  0.8802556340396905\n","Precision :  0.906084999567212\n","Accuracy :  0.8937584688346883\n","Sensitivity :  0.9074547935858069\n","Specificity :  0.8802556340396905\n","Training at Epoch 53 , AUROC: 0.9684310864768013 , AUPRC: 0.9701974081121714 , F1: 0.8929835785881851 , Train loss: 0.2933722138404846 , Accuracy: 0.8937584688346883\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 54 iteration 100 with loss 0.4739903\n","Training at Epoch 54 iteration 200 with loss 0.54357296\n","Training at Epoch 54 iteration 300 with loss 0.53070927\n","optimal threshold: 0.5\n","AUROC:0.5459004855265102\n","AUPRC: 0.5402859167774241\n","Confusion Matrix : \n"," [[1605 1355]\n"," [1385 1543]]\n","Recall :  0.5269808743169399\n","Precision :  0.5324361628709455\n","Accuracy :  0.5346467391304348\n","Sensitivity :  0.5422297297297297\n","Specificity :  0.5269808743169399\n","Validation at Epoch 54 , AUROC: 0.5459004855265102 , AUPRC: 0.5402859167774241 , F1: 0.5296944730518366 , Val loss: 0.8921809792518616 , Accuracy: 0.5346467391304348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9727172802781354\n","AUPRC: 0.9741186654736786\n","Confusion Matrix : \n"," [[10510  1213]\n"," [ 1071 10822]]\n","Recall :  0.9099470276633314\n","Precision :  0.8992106356460324\n","Accuracy :  0.9032859078590786\n","Sensitivity :  0.8965281924422076\n","Specificity :  0.9099470276633314\n","Training at Epoch 54 , AUROC: 0.9727172802781354 , AUPRC: 0.9741186654736786 , F1: 0.9045469742561016 , Train loss: 0.28598102927207947 , Accuracy: 0.9032859078590786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 55 iteration 100 with loss 0.33919328\n","Training at Epoch 55 iteration 200 with loss 0.34155023\n","Training at Epoch 55 iteration 300 with loss 0.50373644\n","optimal threshold: 0.5\n","AUROC:0.5504859846727911\n","AUPRC: 0.5453044340624086\n","Confusion Matrix : \n"," [[1831 1127]\n"," [1562 1368]]\n","Recall :  0.4668941979522184\n","Precision :  0.5482965931863727\n","Accuracy :  0.5433084239130435\n","Sensitivity :  0.618999323867478\n","Specificity :  0.4668941979522184\n","Validation at Epoch 55 , AUROC: 0.5504859846727911 , AUPRC: 0.5453044340624086 , F1: 0.504331797235023 , Val loss: 0.9195172190666199 , Accuracy: 0.5433084239130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9736988848116919\n","AUPRC: 0.9752088545601082\n","Confusion Matrix : \n"," [[11038   678]\n"," [ 1695 10205]]\n","Recall :  0.857563025210084\n","Precision :  0.9377010015620693\n","Accuracy :  0.8995172764227642\n","Sensitivity :  0.9421304199385456\n","Specificity :  0.857563025210084\n","Training at Epoch 55 , AUROC: 0.9736988848116919 , AUPRC: 0.9752088545601082 , F1: 0.895843392002809 , Train loss: 0.2804071605205536 , Accuracy: 0.8995172764227642\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 56 iteration 100 with loss 0.35189116\n","Training at Epoch 56 iteration 200 with loss 0.39147443\n","Training at Epoch 56 iteration 300 with loss 0.3397035\n","optimal threshold: 0.5\n","AUROC:0.5507679015490954\n","AUPRC: 0.5463149849292646\n","Confusion Matrix : \n"," [[1650 1314]\n"," [1405 1519]]\n","Recall :  0.5194938440492476\n","Precision :  0.5361807271443699\n","Accuracy :  0.5382133152173914\n","Sensitivity :  0.5566801619433198\n","Specificity :  0.5194938440492476\n","Validation at Epoch 56 , AUROC: 0.5507679015490954 , AUPRC: 0.5463149849292646 , F1: 0.5277054021191593 , Val loss: 0.9301489591598511 , Accuracy: 0.5382133152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9741686895926641\n","AUPRC: 0.975538280794513\n","Confusion Matrix : \n"," [[10827   897]\n"," [ 1377 10515]]\n","Recall :  0.8842078708375378\n","Precision :  0.9213985278654049\n","Accuracy :  0.9037093495934959\n","Sensitivity :  0.9234902763561924\n","Specificity :  0.8842078708375378\n","Training at Epoch 56 , AUROC: 0.9741686895926641 , AUPRC: 0.975538280794513 , F1: 0.9024201853759011 , Train loss: 0.26802515983581543 , Accuracy: 0.9037093495934959\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 57 iteration 100 with loss 0.43221676\n","Training at Epoch 57 iteration 200 with loss 0.32354635\n","Training at Epoch 57 iteration 300 with loss 0.3981459\n","optimal threshold: 0.5\n","AUROC:0.5506026751588682\n","AUPRC: 0.5418996829430883\n","Confusion Matrix : \n"," [[1773 1190]\n"," [1517 1408]]\n","Recall :  0.48136752136752137\n","Precision :  0.541955350269438\n","Accuracy :  0.5402513586956522\n","Sensitivity :  0.5983800202497469\n","Specificity :  0.48136752136752137\n","Validation at Epoch 57 , AUROC: 0.5506026751588682 , AUPRC: 0.5418996829430883 , F1: 0.509867825457179 , Val loss: 0.9431266188621521 , Accuracy: 0.5402513586956522\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9773428165755984\n","AUPRC: 0.9785020171803068\n","Confusion Matrix : \n"," [[11100   630]\n"," [ 1564 10322]]\n","Recall :  0.8684166246003702\n","Precision :  0.9424762600438276\n","Accuracy :  0.9070968834688347\n","Sensitivity :  0.9462915601023018\n","Specificity :  0.8684166246003702\n","Training at Epoch 57 , AUROC: 0.9773428165755984 , AUPRC: 0.9785020171803068 , F1: 0.9039320430860845 , Train loss: 0.2582681477069855 , Accuracy: 0.9070968834688347\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 58 iteration 100 with loss 0.46574867\n","Training at Epoch 58 iteration 200 with loss 0.36390966\n","Training at Epoch 58 iteration 300 with loss 0.3620144\n","optimal threshold: 0.5\n","AUROC:0.5508726840153503\n","AUPRC: 0.5437396395217294\n","Confusion Matrix : \n"," [[1770 1188]\n"," [1538 1392]]\n","Recall :  0.4750853242320819\n","Precision :  0.5395348837209303\n","Accuracy :  0.5370244565217391\n","Sensitivity :  0.5983772819472617\n","Specificity :  0.4750853242320819\n","Validation at Epoch 58 , AUROC: 0.5508726840153503 , AUPRC: 0.5437396395217294 , F1: 0.5052631578947367 , Val loss: 0.9247311353683472 , Accuracy: 0.5370244565217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.978979579722564\n","AUPRC: 0.979915798106968\n","Confusion Matrix : \n"," [[11023   701]\n"," [ 1425 10467]]\n","Recall :  0.8801715438950555\n","Precision :  0.9372313753581661\n","Accuracy :  0.9099762872628726\n","Sensitivity :  0.9402081200955306\n","Specificity :  0.8801715438950555\n","Training at Epoch 58 , AUROC: 0.978979579722564 , AUPRC: 0.979915798106968 , F1: 0.907805724197745 , Train loss: 0.2602425515651703 , Accuracy: 0.9099762872628726\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 59 iteration 100 with loss 0.27197266\n","Training at Epoch 59 iteration 200 with loss 0.45122242\n","Training at Epoch 59 iteration 300 with loss 0.530568\n","optimal threshold: 0.5\n","AUROC:0.5503412126549141\n","AUPRC: 0.542396583809494\n","Confusion Matrix : \n"," [[1773 1191]\n"," [1502 1422]]\n","Recall :  0.48632010943912446\n","Precision :  0.5442020665901263\n","Accuracy :  0.5426290760869565\n","Sensitivity :  0.5981781376518218\n","Specificity :  0.48632010943912446\n","Validation at Epoch 59 , AUROC: 0.5503412126549141 , AUPRC: 0.542396583809494 , F1: 0.5136355427126603 , Val loss: 0.9334244132041931 , Accuracy: 0.5426290760869565\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9808844505860979\n","AUPRC: 0.981619579732637\n","Confusion Matrix : \n"," [[11017   711]\n"," [ 1283 10605]]\n","Recall :  0.8920760430686406\n","Precision :  0.9371686108165429\n","Accuracy :  0.9155657181571816\n","Sensitivity :  0.9393758526603001\n","Specificity :  0.8920760430686406\n","Training at Epoch 59 , AUROC: 0.9808844505860979 , AUPRC: 0.981619579732637 , F1: 0.9140665402516808 , Train loss: 0.2564815878868103 , Accuracy: 0.9155657181571816\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 60 iteration 100 with loss 0.3574071\n","Training at Epoch 60 iteration 200 with loss 0.36935693\n","Training at Epoch 60 iteration 300 with loss 0.41972974\n","optimal threshold: 0.5\n","AUROC:0.5559772198586176\n","AUPRC: 0.5477182775277389\n","Confusion Matrix : \n"," [[1630 1331]\n"," [1356 1571]]\n","Recall :  0.5367270242569183\n","Precision :  0.5413507925568574\n","Accuracy :  0.5436480978260869\n","Sensitivity :  0.5504896994258697\n","Specificity :  0.5367270242569183\n","Validation at Epoch 60 , AUROC: 0.5559772198586176 , AUPRC: 0.5477182775277389 , F1: 0.5390289929662034 , Val loss: 0.9152954816818237 , Accuracy: 0.5436480978260869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.980336716763851\n","AUPRC: 0.9812521146140006\n","Confusion Matrix : \n"," [[10706  1018]\n"," [  909 10983]]\n","Recall :  0.9235620585267407\n","Precision :  0.9151737355220398\n","Accuracy :  0.9184027777777778\n","Sensitivity :  0.9131695667007848\n","Specificity :  0.9235620585267407\n","Training at Epoch 60 , AUROC: 0.980336716763851 , AUPRC: 0.9812521146140006 , F1: 0.9193487632360943 , Train loss: 0.25063303112983704 , Accuracy: 0.9184027777777778\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 61 iteration 100 with loss 0.33287108\n","Training at Epoch 61 iteration 200 with loss 0.29361933\n","Training at Epoch 61 iteration 300 with loss 0.31235337\n","optimal threshold: 0.5\n","AUROC:0.5499400290422127\n","AUPRC: 0.5402125456091\n","Confusion Matrix : \n"," [[1595 1370]\n"," [1331 1592]]\n","Recall :  0.5446459117345194\n","Precision :  0.537474679270763\n","Accuracy :  0.5412703804347826\n","Sensitivity :  0.5379426644182125\n","Specificity :  0.5446459117345194\n","Validation at Epoch 61 , AUROC: 0.5499400290422127 , AUPRC: 0.5402125456091 , F1: 0.5410365335598981 , Val loss: 0.9447497725486755 , Accuracy: 0.5412703804347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9820627639461352\n","AUPRC: 0.9828724990549655\n","Confusion Matrix : \n"," [[10825   904]\n"," [  895 10992]]\n","Recall :  0.924707663834441\n","Precision :  0.9240080699394755\n","Accuracy :  0.9238228319783198\n","Sensitivity :  0.9229260806547873\n","Specificity :  0.924707663834441\n","Training at Epoch 61 , AUROC: 0.9820627639461352 , AUPRC: 0.9828724990549655 , F1: 0.924357734516251 , Train loss: 0.24123713374137878 , Accuracy: 0.9238228319783198\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 62 iteration 100 with loss 0.4210999\n","Training at Epoch 62 iteration 200 with loss 0.3910818\n","Training at Epoch 62 iteration 300 with loss 0.39671707\n","optimal threshold: 0.5\n","AUROC:0.552176645093654\n","AUPRC: 0.5447720194719028\n","Confusion Matrix : \n"," [[1558 1403]\n"," [1300 1627]]\n","Recall :  0.5558592415442433\n","Precision :  0.5369636963696369\n","Accuracy :  0.5409307065217391\n","Sensitivity :  0.5261735900033773\n","Specificity :  0.5558592415442433\n","Validation at Epoch 62 , AUROC: 0.552176645093654 , AUPRC: 0.5447720194719028 , F1: 0.5462481114655027 , Val loss: 0.9745163321495056 , Accuracy: 0.5409307065217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9820935759947454\n","AUPRC: 0.9828695614052734\n","Confusion Matrix : \n"," [[10705  1020]\n"," [  794 11097]]\n","Recall :  0.9332268101925826\n","Precision :  0.9158207477098291\n","Accuracy :  0.9231876693766937\n","Sensitivity :  0.9130063965884861\n","Specificity :  0.9332268101925826\n","Training at Epoch 62 , AUROC: 0.9820935759947454 , AUPRC: 0.9828695614052734 , F1: 0.9244418527157614 , Train loss: 0.23219110071659088 , Accuracy: 0.9231876693766937\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 63 iteration 100 with loss 0.31259042\n","Training at Epoch 63 iteration 200 with loss 0.36134157\n","Training at Epoch 63 iteration 300 with loss 0.49228793\n","optimal threshold: 0.5\n","AUROC:0.5517884126157759\n","AUPRC: 0.5421069921881203\n","Confusion Matrix : \n"," [[1721 1243]\n"," [1473 1451]]\n","Recall :  0.49623803009575923\n","Precision :  0.538604305864885\n","Accuracy :  0.5387228260869565\n","Sensitivity :  0.5806342780026991\n","Specificity :  0.49623803009575923\n","Validation at Epoch 63 , AUROC: 0.5517884126157759 , AUPRC: 0.5421069921881203 , F1: 0.5165539337842648 , Val loss: 0.9500292539596558 , Accuracy: 0.5387228260869565\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9849507937047921\n","AUPRC: 0.9855789013795445\n","Confusion Matrix : \n"," [[11029   698]\n"," [  975 10914]]\n","Recall :  0.9179914206409285\n","Precision :  0.9398897692042715\n","Accuracy :  0.9291581978319783\n","Sensitivity :  0.9404792359512236\n","Specificity :  0.9179914206409285\n","Training at Epoch 63 , AUROC: 0.9849507937047921 , AUPRC: 0.9855789013795445 , F1: 0.9288115399344709 , Train loss: 0.23023517429828644 , Accuracy: 0.9291581978319783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 64 iteration 100 with loss 0.4382867\n","Training at Epoch 64 iteration 200 with loss 0.3869355\n","Training at Epoch 64 iteration 300 with loss 0.32184792\n","optimal threshold: 0.5\n","AUROC:0.5460826815920921\n","AUPRC: 0.5368793106895089\n","Confusion Matrix : \n"," [[1646 1313]\n"," [1399 1530]]\n","Recall :  0.5223625810856948\n","Precision :  0.5381639113612381\n","Accuracy :  0.5394021739130435\n","Sensitivity :  0.5562690098006083\n","Specificity :  0.5223625810856948\n","Validation at Epoch 64 , AUROC: 0.5460826815920921 , AUPRC: 0.5368793106895089 , F1: 0.5301455301455301 , Val loss: 1.0087382793426514 , Accuracy: 0.5394021739130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9849470787238679\n","AUPRC: 0.9856835952916964\n","Confusion Matrix : \n"," [[11044   680]\n"," [ 1019 10873]]\n","Recall :  0.9143121426168853\n","Precision :  0.9411408292218472\n","Accuracy :  0.9280572493224932\n","Sensitivity :  0.941999317639031\n","Specificity :  0.9143121426168853\n","Training at Epoch 64 , AUROC: 0.9849470787238679 , AUPRC: 0.9856835952916964 , F1: 0.927532522925997 , Train loss: 0.22093643248081207 , Accuracy: 0.9280572493224932\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 65 iteration 100 with loss 0.29565698\n","Training at Epoch 65 iteration 200 with loss 0.54148555\n","Training at Epoch 65 iteration 300 with loss 0.43846476\n","optimal threshold: 0.5\n","AUROC:0.5492555394071084\n","AUPRC: 0.5433464501840679\n","Confusion Matrix : \n"," [[1603 1359]\n"," [1372 1554]]\n","Recall :  0.5311004784688995\n","Precision :  0.533470648815654\n","Accuracy :  0.5361752717391305\n","Sensitivity :  0.5411883862255233\n","Specificity :  0.5311004784688995\n","Validation at Epoch 65 , AUROC: 0.5492555394071084 , AUPRC: 0.5433464501840679 , F1: 0.5322829251584175 , Val loss: 0.9725165963172913 , Accuracy: 0.5361752717391305\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9844006542116129\n","AUPRC: 0.9852111922798663\n","Confusion Matrix : \n"," [[11076   643]\n"," [ 1071 10826]]\n","Recall :  0.9099773052029924\n","Precision :  0.9439358270119452\n","Accuracy :  0.9274220867208672\n","Sensitivity :  0.9451318371874733\n","Specificity :  0.9099773052029924\n","Training at Epoch 65 , AUROC: 0.9844006542116129 , AUPRC: 0.9852111922798663 , F1: 0.9266455533681417 , Train loss: 0.22458945214748383 , Accuracy: 0.9274220867208672\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 66 iteration 100 with loss 0.40778917\n","Training at Epoch 66 iteration 200 with loss 0.37099925\n","Training at Epoch 66 iteration 300 with loss 0.42195532\n","optimal threshold: 0.5\n","AUROC:0.5509115496806114\n","AUPRC: 0.5424049095792247\n","Confusion Matrix : \n"," [[1589 1379]\n"," [1319 1601]]\n","Recall :  0.5482876712328767\n","Precision :  0.5372483221476511\n","Accuracy :  0.5417798913043478\n","Sensitivity :  0.535377358490566\n","Specificity :  0.5482876712328767\n","Validation at Epoch 66 , AUROC: 0.5509115496806114 , AUPRC: 0.5424049095792247 , F1: 0.5427118644067797 , Val loss: 0.9775803685188293 , Accuracy: 0.5417798913043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9868839670775847\n","AUPRC: 0.9875761417609344\n","Confusion Matrix : \n"," [[10797   923]\n"," [  605 11291]]\n","Recall :  0.949142568930733\n","Precision :  0.9244309808416571\n","Accuracy :  0.9352981029810298\n","Sensitivity :  0.9212457337883959\n","Specificity :  0.949142568930733\n","Training at Epoch 66 , AUROC: 0.9868839670775847 , AUPRC: 0.9875761417609344 , F1: 0.9366238075487349 , Train loss: 0.21423254907131195 , Accuracy: 0.9352981029810298\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 67 iteration 100 with loss 0.3330076\n","Training at Epoch 67 iteration 200 with loss 0.41899544\n","Training at Epoch 67 iteration 300 with loss 0.3425479\n","optimal threshold: 0.5\n","AUROC:0.5511923408649699\n","AUPRC: 0.5435283672341842\n","Confusion Matrix : \n"," [[1624 1339]\n"," [1381 1544]]\n","Recall :  0.5278632478632479\n","Precision :  0.535553243149497\n","Accuracy :  0.5380434782608695\n","Sensitivity :  0.5480931488356395\n","Specificity :  0.5278632478632479\n","Validation at Epoch 67 , AUROC: 0.5511923408649699 , AUPRC: 0.5435283672341842 , F1: 0.5316804407713499 , Val loss: 0.9593598246574402 , Accuracy: 0.5380434782608695\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9869469205478968\n","AUPRC: 0.9874188063751121\n","Confusion Matrix : \n"," [[10951   777]\n"," [  769 11119]]\n","Recall :  0.9353129205921938\n","Precision :  0.9346839273705447\n","Accuracy :  0.9345359078590786\n","Sensitivity :  0.9337482946793997\n","Specificity :  0.9353129205921938\n","Training at Epoch 67 , AUROC: 0.9869469205478968 , AUPRC: 0.9874188063751121 , F1: 0.9349983181971072 , Train loss: 0.22193539142608643 , Accuracy: 0.9345359078590786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 68 iteration 100 with loss 0.45010203\n","Training at Epoch 68 iteration 200 with loss 0.4213633\n","Training at Epoch 68 iteration 300 with loss 0.36192763\n","optimal threshold: 0.5\n","AUROC:0.5495236694156708\n","AUPRC: 0.5387547468923365\n","Confusion Matrix : \n"," [[1701 1262]\n"," [1485 1440]]\n","Recall :  0.49230769230769234\n","Precision :  0.532938564026647\n","Accuracy :  0.5334578804347826\n","Sensitivity :  0.5740803239959501\n","Specificity :  0.49230769230769234\n","Validation at Epoch 68 , AUROC: 0.5495236694156708 , AUPRC: 0.5387547468923365 , F1: 0.5118180202594634 , Val loss: 0.9745760560035706 , Accuracy: 0.5334578804347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9882603688338165\n","AUPRC: 0.9887963295433696\n","Confusion Matrix : \n"," [[11090   636]\n"," [  868 11022]]\n","Recall :  0.9269974768713204\n","Precision :  0.9454451878538342\n","Accuracy :  0.9363143631436315\n","Sensitivity :  0.9457615555176531\n","Specificity :  0.9269974768713204\n","Training at Epoch 68 , AUROC: 0.9882603688338165 , AUPRC: 0.9887963295433696 , F1: 0.9361304569390181 , Train loss: 0.21361595392227173 , Accuracy: 0.9363143631436315\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 69 iteration 100 with loss 0.41584513\n","Training at Epoch 69 iteration 200 with loss 0.36553368\n","Training at Epoch 69 iteration 300 with loss 0.42089185\n","optimal threshold: 0.5\n","AUROC:0.5459872672904409\n","AUPRC: 0.5367978065380463\n","Confusion Matrix : \n"," [[1747 1215]\n"," [1499 1427]]\n","Recall :  0.48769651401230346\n","Precision :  0.5401211203633611\n","Accuracy :  0.5390625\n","Sensitivity :  0.5898041863605672\n","Specificity :  0.48769651401230346\n","Validation at Epoch 69 , AUROC: 0.5459872672904409 , AUPRC: 0.5367978065380463 , F1: 0.5125718390804597 , Val loss: 0.9932321906089783 , Accuracy: 0.5390625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9884829960006221\n","AUPRC: 0.9888393000799007\n","Confusion Matrix : \n"," [[11190   541]\n"," [  988 10897]]\n","Recall :  0.9168700042069836\n","Precision :  0.9527015212449729\n","Accuracy :  0.935255758807588\n","Sensitivity :  0.953882874435257\n","Specificity :  0.9168700042069836\n","Training at Epoch 69 , AUROC: 0.9884829960006221 , AUPRC: 0.9888393000799007 , F1: 0.9344423959181923 , Train loss: 0.20885327458381653 , Accuracy: 0.935255758807588\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 70 iteration 100 with loss 0.3926738\n","Training at Epoch 70 iteration 200 with loss 0.38185936\n","Training at Epoch 70 iteration 300 with loss 0.43096745\n","optimal threshold: 0.5\n","AUROC:0.548925984579039\n","AUPRC: 0.5411653106934424\n","Confusion Matrix : \n"," [[1706 1257]\n"," [1452 1473]]\n","Recall :  0.5035897435897436\n","Precision :  0.5395604395604395\n","Accuracy :  0.5399116847826086\n","Sensitivity :  0.5757678029024638\n","Specificity :  0.5035897435897436\n","Validation at Epoch 70 , AUROC: 0.548925984579039 , AUPRC: 0.5411653106934424 , F1: 0.5209549071618037 , Val loss: 0.9860576391220093 , Accuracy: 0.5399116847826086\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9912765779264954\n","AUPRC: 0.9916065324020439\n","Confusion Matrix : \n"," [[11256   472]\n"," [  844 11044]]\n","Recall :  0.9290040376850606\n","Precision :  0.9590135463702675\n","Accuracy :  0.9442750677506775\n","Sensitivity :  0.9597544338335607\n","Specificity :  0.9290040376850606\n","Training at Epoch 70 , AUROC: 0.9912765779264954 , AUPRC: 0.9916065324020439 , F1: 0.9437702956759527 , Train loss: 0.1992829293012619 , Accuracy: 0.9442750677506775\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 71 iteration 100 with loss 0.24116\n","Training at Epoch 71 iteration 200 with loss 0.27504623\n","Training at Epoch 71 iteration 300 with loss 0.39554262\n","optimal threshold: 0.5\n","AUROC:0.5465710459624601\n","AUPRC: 0.5365797982368505\n","Confusion Matrix : \n"," [[1681 1281]\n"," [1437 1489]]\n","Recall :  0.5088858509911142\n","Precision :  0.5375451263537906\n","Accuracy :  0.5383831521739131\n","Sensitivity :  0.5675219446320054\n","Specificity :  0.5088858509911142\n","Validation at Epoch 71 , AUROC: 0.5465710459624601 , AUPRC: 0.5365797982368505 , F1: 0.5228230337078651 , Val loss: 0.9803124666213989 , Accuracy: 0.5383831521739131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9908311901282412\n","AUPRC: 0.9913171383732519\n","Confusion Matrix : \n"," [[11149   574]\n"," [  714 11179]]\n","Recall :  0.9399646851088875\n","Precision :  0.9511614055985705\n","Accuracy :  0.9454607046070461\n","Sensitivity :  0.9510364241235179\n","Specificity :  0.9399646851088875\n","Training at Epoch 71 , AUROC: 0.9908311901282412 , AUPRC: 0.9913171383732519 , F1: 0.9455298993487271 , Train loss: 0.2029530256986618 , Accuracy: 0.9454607046070461\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 72 iteration 100 with loss 0.31189147\n","Training at Epoch 72 iteration 200 with loss 0.47814876\n","Training at Epoch 72 iteration 300 with loss 0.32848072\n","optimal threshold: 0.5\n","AUROC:0.5528957070547109\n","AUPRC: 0.5474293595810484\n","Confusion Matrix : \n"," [[1721 1240]\n"," [1471 1456]]\n","Recall :  0.49743764947044755\n","Precision :  0.5400593471810089\n","Accuracy :  0.5395720108695652\n","Sensitivity :  0.5812225599459642\n","Specificity :  0.49743764947044755\n","Validation at Epoch 72 , AUROC: 0.5528957070547109 , AUPRC: 0.5474293595810484 , F1: 0.5178730215187621 , Val loss: 0.9829514026641846 , Accuracy: 0.5395720108695652\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9915788676331039\n","AUPRC: 0.9919571263922744\n","Confusion Matrix : \n"," [[11319   405]\n"," [  901 10991]]\n","Recall :  0.9242347796838211\n","Precision :  0.9644612144612145\n","Accuracy :  0.9446985094850948\n","Sensitivity :  0.9654554759467758\n","Specificity :  0.9242347796838211\n","Training at Epoch 72 , AUROC: 0.9915788676331039 , AUPRC: 0.9919571263922744 , F1: 0.9439196152524906 , Train loss: 0.19677987694740295 , Accuracy: 0.9446985094850948\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 73 iteration 100 with loss 0.29825607\n","Training at Epoch 73 iteration 200 with loss 0.3673222\n","Training at Epoch 73 iteration 300 with loss 0.37142307\n","optimal threshold: 0.5\n","AUROC:0.5493212873300621\n","AUPRC: 0.545335684982363\n","Confusion Matrix : \n"," [[1718 1245]\n"," [1515 1410]]\n","Recall :  0.48205128205128206\n","Precision :  0.5310734463276836\n","Accuracy :  0.53125\n","Sensitivity :  0.5798177522780965\n","Specificity :  0.48205128205128206\n","Validation at Epoch 73 , AUROC: 0.5493212873300621 , AUPRC: 0.545335684982363 , F1: 0.5053763440860215 , Val loss: 0.99754399061203 , Accuracy: 0.53125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9920177401881112\n","AUPRC: 0.9923860319451114\n","Confusion Matrix : \n"," [[11242   479]\n"," [  736 11159]]\n","Recall :  0.9381252627154266\n","Precision :  0.9588417253823681\n","Accuracy :  0.9485518292682927\n","Sensitivity :  0.9591331797628189\n","Specificity :  0.9381252627154266\n","Training at Epoch 73 , AUROC: 0.9920177401881112 , AUPRC: 0.9923860319451114 , F1: 0.9483703735180385 , Train loss: 0.18740113079547882 , Accuracy: 0.9485518292682927\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 74 iteration 100 with loss 0.33118963\n","Training at Epoch 74 iteration 200 with loss 0.34158438\n","Training at Epoch 74 iteration 300 with loss 0.3628668\n","optimal threshold: 0.5\n","AUROC:0.5466601790831508\n","AUPRC: 0.542908594472808\n","Confusion Matrix : \n"," [[1630 1332]\n"," [1431 1495]]\n","Recall :  0.5109364319890636\n","Precision :  0.5288291475061903\n","Accuracy :  0.5307404891304348\n","Sensitivity :  0.550303848750844\n","Specificity :  0.5109364319890636\n","Validation at Epoch 74 , AUROC: 0.5466601790831508 , AUPRC: 0.542908594472808 , F1: 0.5197288371284546 , Val loss: 1.0047298669815063 , Accuracy: 0.5307404891304348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9933332539580872\n","AUPRC: 0.9936639016102793\n","Confusion Matrix : \n"," [[11303   423]\n"," [  702 11188]]\n","Recall :  0.9409587888982338\n","Precision :  0.9635690293687021\n","Accuracy :  0.9523628048780488\n","Sensitivity :  0.9639263175848541\n","Specificity :  0.9409587888982338\n","Training at Epoch 74 , AUROC: 0.9933332539580872 , AUPRC: 0.9936639016102793 , F1: 0.9521296966086551 , Train loss: 0.18022795021533966 , Accuracy: 0.9523628048780488\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 75 iteration 100 with loss 0.36889738\n","Training at Epoch 75 iteration 200 with loss 0.29308653\n","Training at Epoch 75 iteration 300 with loss 0.44512737\n","optimal threshold: 0.5\n","AUROC:0.5484708430024867\n","AUPRC: 0.5467298264931827\n","Confusion Matrix : \n"," [[1615 1349]\n"," [1391 1533]]\n","Recall :  0.524281805745554\n","Precision :  0.5319222761970853\n","Accuracy :  0.5346467391304348\n","Sensitivity :  0.5448717948717948\n","Specificity :  0.524281805745554\n","Validation at Epoch 75 , AUROC: 0.5484708430024867 , AUPRC: 0.5467298264931827 , F1: 0.5280744057871167 , Val loss: 1.0101121664047241 , Accuracy: 0.5346467391304348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9918128132176096\n","AUPRC: 0.9921642117190518\n","Confusion Matrix : \n"," [[11048   675]\n"," [  518 11375]]\n","Recall :  0.9564449676280165\n","Precision :  0.9439834024896265\n","Accuracy :  0.9494834010840109\n","Sensitivity :  0.942420882026785\n","Specificity :  0.9564449676280165\n","Training at Epoch 75 , AUROC: 0.9918128132176096 , AUPRC: 0.9921642117190518 , F1: 0.9501733283214301 , Train loss: 0.18195736408233643 , Accuracy: 0.9494834010840109\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 76 iteration 100 with loss 0.2668526\n","Training at Epoch 76 iteration 200 with loss 0.40052748\n","Training at Epoch 76 iteration 300 with loss 0.3371814\n","optimal threshold: 0.5\n","AUROC:0.5396799216332409\n","AUPRC: 0.5401657848772632\n","Confusion Matrix : \n"," [[1689 1269]\n"," [1504 1426]]\n","Recall :  0.48668941979522184\n","Precision :  0.5291280148423005\n","Accuracy :  0.5290421195652174\n","Sensitivity :  0.5709939148073022\n","Specificity :  0.48668941979522184\n","Validation at Epoch 76 , AUROC: 0.5396799216332409 , AUPRC: 0.5401657848772632 , F1: 0.5070222222222223 , Val loss: 1.0016134977340698 , Accuracy: 0.5290421195652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9933667120426384\n","AUPRC: 0.9936436626863181\n","Confusion Matrix : \n"," [[11312   412]\n"," [  723 11169]]\n","Recall :  0.9392028254288597\n","Precision :  0.9644244883861497\n","Accuracy :  0.9519393631436315\n","Sensitivity :  0.9648584100989424\n","Specificity :  0.9392028254288597\n","Training at Epoch 76 , AUROC: 0.9933667120426384 , AUPRC: 0.9936436626863181 , F1: 0.9516465726579475 , Train loss: 0.181793212890625 , Accuracy: 0.9519393631436315\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 77 iteration 100 with loss 0.33774006\n","Training at Epoch 77 iteration 200 with loss 0.26218328\n","Training at Epoch 77 iteration 300 with loss 0.27675226\n","optimal threshold: 0.5\n","AUROC:0.5392682976078184\n","AUPRC: 0.5423200193638877\n","Confusion Matrix : \n"," [[1628 1335]\n"," [1455 1470]]\n","Recall :  0.5025641025641026\n","Precision :  0.5240641711229946\n","Accuracy :  0.5261548913043478\n","Sensitivity :  0.5494431319608505\n","Specificity :  0.5025641025641026\n","Validation at Epoch 77 , AUROC: 0.5392682976078184 , AUPRC: 0.5423200193638877 , F1: 0.5130890052356022 , Val loss: 1.053386926651001 , Accuracy: 0.5261548913043478\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9924165217669657\n","AUPRC: 0.9927590644830466\n","Confusion Matrix : \n"," [[11245   482]\n"," [  678 11211]]\n","Recall :  0.9429724955841534\n","Precision :  0.9587787565209954\n","Accuracy :  0.950880758807588\n","Sensitivity :  0.9588982689519912\n","Specificity :  0.9429724955841534\n","Training at Epoch 77 , AUROC: 0.9924165217669657 , AUPRC: 0.9927590644830466 , F1: 0.9508099397845815 , Train loss: 0.17384479939937592 , Accuracy: 0.950880758807588\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 78 iteration 100 with loss 0.28302288\n","Training at Epoch 78 iteration 200 with loss 0.38788298\n","Training at Epoch 78 iteration 300 with loss 0.43939453\n","optimal threshold: 0.5\n","AUROC:0.5525806201869696\n","AUPRC: 0.548147007818599\n","Confusion Matrix : \n"," [[1785 1172]\n"," [1548 1383]]\n","Recall :  0.4718526100307062\n","Precision :  0.5412915851272015\n","Accuracy :  0.5380434782608695\n","Sensitivity :  0.6036523503550896\n","Specificity :  0.4718526100307062\n","Validation at Epoch 78 , AUROC: 0.5525806201869696 , AUPRC: 0.548147007818599 , F1: 0.5041924899744805 , Val loss: 1.0220551490783691 , Accuracy: 0.5380434782608695\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9946207413175541\n","AUPRC: 0.9947968228502057\n","Confusion Matrix : \n"," [[11436   292]\n"," [  789 11099]]\n","Recall :  0.9336305518169583\n","Precision :  0.9743657273285927\n","Accuracy :  0.9542259485094851\n","Sensitivity :  0.9751023192360164\n","Specificity :  0.9336305518169583\n","Training at Epoch 78 , AUROC: 0.9946207413175541 , AUPRC: 0.9947968228502057 , F1: 0.9535632973924998 , Train loss: 0.17004024982452393 , Accuracy: 0.9542259485094851\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 79 iteration 100 with loss 0.32486638\n","Training at Epoch 79 iteration 200 with loss 0.35788545\n","Training at Epoch 79 iteration 300 with loss 0.3362537\n","optimal threshold: 0.5\n","AUROC:0.548113539326802\n","AUPRC: 0.5395803255321998\n","Confusion Matrix : \n"," [[1646 1316]\n"," [1406 1520]]\n","Recall :  0.5194805194805194\n","Precision :  0.535966149506347\n","Accuracy :  0.537703804347826\n","Sensitivity :  0.5557056043214045\n","Specificity :  0.5194805194805194\n","Validation at Epoch 79 , AUROC: 0.548113539326802 , AUPRC: 0.5395803255321998 , F1: 0.5275945852134675 , Val loss: 1.0448795557022095 , Accuracy: 0.537703804347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9939600761849183\n","AUPRC: 0.9941635994742326\n","Confusion Matrix : \n"," [[11211   510]\n"," [  529 11366]]\n","Recall :  0.9555275325767129\n","Precision :  0.9570562478949141\n","Accuracy :  0.956004403794038\n","Sensitivity :  0.9564883542359867\n","Specificity :  0.9555275325767129\n","Training at Epoch 79 , AUROC: 0.9939600761849183 , AUPRC: 0.9941635994742326 , F1: 0.956291279289891 , Train loss: 0.1661462038755417 , Accuracy: 0.956004403794038\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 80 iteration 100 with loss 0.38655397\n","Training at Epoch 80 iteration 200 with loss 0.31957322\n","Training at Epoch 80 iteration 300 with loss 0.3354067\n","optimal threshold: 0.5\n","AUROC:0.5503779623609165\n","AUPRC: 0.5418387960442663\n","Confusion Matrix : \n"," [[1744 1220]\n"," [1499 1425]]\n","Recall :  0.48734610123119015\n","Precision :  0.5387523629489603\n","Accuracy :  0.5382133152173914\n","Sensitivity :  0.5883940620782726\n","Specificity :  0.48734610123119015\n","Validation at Epoch 80 , AUROC: 0.5503779623609165 , AUPRC: 0.5418387960442663 , F1: 0.5117615370802658 , Val loss: 1.0562163591384888 , Accuracy: 0.5382133152173914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9939732169193558\n","AUPRC: 0.9941766512122748\n","Confusion Matrix : \n"," [[11300   425]\n"," [  656 11235]]\n","Recall :  0.9448322260533176\n","Precision :  0.9635506003430532\n","Accuracy :  0.9542259485094851\n","Sensitivity :  0.9637526652452025\n","Specificity :  0.9448322260533176\n","Training at Epoch 80 , AUROC: 0.9939732169193558 , AUPRC: 0.9941766512122748 , F1: 0.9540996136045178 , Train loss: 0.16067242622375488 , Accuracy: 0.9542259485094851\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 81 iteration 100 with loss 0.23543242\n","Training at Epoch 81 iteration 200 with loss 0.3212884\n","Training at Epoch 81 iteration 300 with loss 0.36243993\n","optimal threshold: 0.5\n","AUROC:0.5448531777931029\n","AUPRC: 0.5398552943634449\n","Confusion Matrix : \n"," [[1720 1239]\n"," [1514 1415]]\n","Recall :  0.48310003414134517\n","Precision :  0.5331574981160513\n","Accuracy :  0.5324388586956522\n","Sensitivity :  0.5812774586008786\n","Specificity :  0.48310003414134517\n","Validation at Epoch 81 , AUROC: 0.5448531777931029 , AUPRC: 0.5398552943634449 , F1: 0.5068959340856171 , Val loss: 1.038575530052185 , Accuracy: 0.5324388586956522\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9940033185394811\n","AUPRC: 0.9941845092958917\n","Confusion Matrix : \n"," [[11283   447]\n"," [  604 11282]]\n","Recall :  0.9491839138482248\n","Precision :  0.9618893341290817\n","Accuracy :  0.9554962737127372\n","Sensitivity :  0.9618925831202046\n","Specificity :  0.9491839138482248\n","Training at Epoch 81 , AUROC: 0.9940033185394811 , AUPRC: 0.9941845092958917 , F1: 0.9554943891594325 , Train loss: 0.16657525300979614 , Accuracy: 0.9554962737127372\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 82 iteration 100 with loss 0.27447903\n","Training at Epoch 82 iteration 200 with loss 0.35928196\n","Training at Epoch 82 iteration 300 with loss 0.41287756\n","optimal threshold: 0.5\n","AUROC:0.5506192497005864\n","AUPRC: 0.5447827334973494\n","Confusion Matrix : \n"," [[1598 1360]\n"," [1374 1556]]\n","Recall :  0.5310580204778157\n","Precision :  0.53360768175583\n","Accuracy :  0.5356657608695652\n","Sensitivity :  0.5402298850574713\n","Specificity :  0.5310580204778157\n","Validation at Epoch 82 , AUROC: 0.5506192497005864 , AUPRC: 0.5447827334973494 , F1: 0.5323297981525831 , Val loss: 1.0334231853485107 , Accuracy: 0.5356657608695652\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9949555214114485\n","AUPRC: 0.9951468179207351\n","Confusion Matrix : \n"," [[11273   453]\n"," [  500 11390]]\n","Recall :  0.9579478553406223\n","Precision :  0.9617495567001604\n","Accuracy :  0.9596460027100271\n","Sensitivity :  0.9613679003922906\n","Specificity :  0.9579478553406223\n","Training at Epoch 82 , AUROC: 0.9949555214114485 , AUPRC: 0.9951468179207351 , F1: 0.9598449416424388 , Train loss: 0.15840627253055573 , Accuracy: 0.9596460027100271\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 83 iteration 100 with loss 0.18548802\n","Training at Epoch 83 iteration 200 with loss 0.26757386\n","Training at Epoch 83 iteration 300 with loss 0.35457164\n","optimal threshold: 0.5\n","AUROC:0.5449088144143146\n","AUPRC: 0.5382138130193779\n","Confusion Matrix : \n"," [[1631 1327]\n"," [1422 1508]]\n","Recall :  0.5146757679180888\n","Precision :  0.5319223985890652\n","Accuracy :  0.5331182065217391\n","Sensitivity :  0.5513860716700474\n","Specificity :  0.5146757679180888\n","Validation at Epoch 83 , AUROC: 0.5449088144143146 , AUPRC: 0.5382138130193779 , F1: 0.5231569817866435 , Val loss: 1.0597968101501465 , Accuracy: 0.5331182065217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9947204619008143\n","AUPRC: 0.9948740731562216\n","Confusion Matrix : \n"," [[11137   589]\n"," [  394 11496]]\n","Recall :  0.9668629100084104\n","Precision :  0.9512618949110467\n","Accuracy :  0.9583756775067751\n","Sensitivity :  0.9497697424526693\n","Specificity :  0.9668629100084104\n","Training at Epoch 83 , AUROC: 0.9947204619008143 , AUPRC: 0.9948740731562216 , F1: 0.9589989572471325 , Train loss: 0.15555700659751892 , Accuracy: 0.9583756775067751\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 84 iteration 100 with loss 0.28703493\n","Training at Epoch 84 iteration 200 with loss 0.198111\n","Training at Epoch 84 iteration 300 with loss 0.34871092\n","optimal threshold: 0.5\n","AUROC:0.5484376701909461\n","AUPRC: 0.539819467281554\n","Confusion Matrix : \n"," [[1642 1322]\n"," [1386 1538]]\n","Recall :  0.5259917920656635\n","Precision :  0.5377622377622377\n","Accuracy :  0.5400815217391305\n","Sensitivity :  0.5539811066126855\n","Specificity :  0.5259917920656635\n","Validation at Epoch 84 , AUROC: 0.5484376701909461 , AUPRC: 0.539819467281554 , F1: 0.5318118948824342 , Val loss: 1.022875428199768 , Accuracy: 0.5400815217391305\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9961283910862365\n","AUPRC: 0.9962584799785134\n","Confusion Matrix : \n"," [[11379   347]\n"," [  476 11414]]\n","Recall :  0.9599663582842725\n","Precision :  0.9704957061474364\n","Accuracy :  0.9651507452574526\n","Sensitivity :  0.9704076411393484\n","Specificity :  0.9599663582842725\n","Training at Epoch 84 , AUROC: 0.9961283910862365 , AUPRC: 0.9962584799785134 , F1: 0.9652023170267642 , Train loss: 0.1519014835357666 , Accuracy: 0.9651507452574526\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 85 iteration 100 with loss 0.31053746\n","Training at Epoch 85 iteration 200 with loss 0.52812725\n","Training at Epoch 85 iteration 300 with loss 0.29465446\n","optimal threshold: 0.5\n","AUROC:0.540997600963307\n","AUPRC: 0.5348441612540398\n","Confusion Matrix : \n"," [[1738 1224]\n"," [1549 1377]]\n","Recall :  0.47060833902939164\n","Precision :  0.5294117647058824\n","Accuracy :  0.5290421195652174\n","Sensitivity :  0.5867656988521269\n","Specificity :  0.47060833902939164\n","Validation at Epoch 85 , AUROC: 0.540997600963307 , AUPRC: 0.5348441612540398 , F1: 0.4982811651890718 , Val loss: 1.0417369604110718 , Accuracy: 0.5290421195652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9957667331682998\n","AUPRC: 0.9958646115449747\n","Confusion Matrix : \n"," [[11392   331]\n"," [  578 11315]]\n","Recall :  0.9513999831833851\n","Precision :  0.9715782242830157\n","Accuracy :  0.9615091463414634\n","Sensitivity :  0.9717649065938753\n","Specificity :  0.9513999831833851\n","Training at Epoch 85 , AUROC: 0.9957667331682998 , AUPRC: 0.9958646115449747 , F1: 0.961383236331195 , Train loss: 0.15471766889095306 , Accuracy: 0.9615091463414634\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 86 iteration 100 with loss 0.5188232\n","Training at Epoch 86 iteration 200 with loss 0.27574134\n","Training at Epoch 86 iteration 300 with loss 0.29468173\n","optimal threshold: 0.5\n","AUROC:0.5506092115556356\n","AUPRC: 0.545361674626363\n","Confusion Matrix : \n"," [[1687 1271]\n"," [1455 1475]]\n","Recall :  0.5034129692832765\n","Precision :  0.5371449380917699\n","Accuracy :  0.5370244565217391\n","Sensitivity :  0.5703177822853279\n","Specificity :  0.5034129692832765\n","Validation at Epoch 86 , AUROC: 0.5506092115556356 , AUPRC: 0.545361674626363 , F1: 0.5197322057787175 , Val loss: 1.04839026927948 , Accuracy: 0.5370244565217391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.996067312918211\n","AUPRC: 0.9962122891004493\n","Confusion Matrix : \n"," [[11413   312]\n"," [  544 11347]]\n","Recall :  0.954251114288117\n","Precision :  0.9732395574234497\n","Accuracy :  0.9637533875338753\n","Sensitivity :  0.9733901918976546\n","Specificity :  0.954251114288117\n","Training at Epoch 86 , AUROC: 0.996067312918211 , AUPRC: 0.9962122891004493 , F1: 0.9636518046709129 , Train loss: 0.14798420667648315 , Accuracy: 0.9637533875338753\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 87 iteration 100 with loss 0.23233588\n","Training at Epoch 87 iteration 200 with loss 0.2480121\n","Training at Epoch 87 iteration 300 with loss 0.25967017\n","optimal threshold: 0.5\n","AUROC:0.5463967027322157\n","AUPRC: 0.5433573454872924\n","Confusion Matrix : \n"," [[1708 1254]\n"," [1501 1425]]\n","Recall :  0.487012987012987\n","Precision :  0.5319148936170213\n","Accuracy :  0.5320991847826086\n","Sensitivity :  0.5766374071573261\n","Specificity :  0.487012987012987\n","Validation at Epoch 87 , AUROC: 0.5463967027322157 , AUPRC: 0.5433573454872924 , F1: 0.5084745762711865 , Val loss: 1.0510884523391724 , Accuracy: 0.5320991847826086\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9969183186168843\n","AUPRC: 0.9970145967659358\n","Confusion Matrix : \n"," [[11484   249]\n"," [  555 11328]]\n","Recall :  0.953294622570058\n","Precision :  0.9784918372635398\n","Accuracy :  0.9659552845528455\n","Sensitivity :  0.9787778061876757\n","Specificity :  0.953294622570058\n","Training at Epoch 87 , AUROC: 0.9969183186168843 , AUPRC: 0.9970145967659358 , F1: 0.9657289002557545 , Train loss: 0.14061933755874634 , Accuracy: 0.9659552845528455\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 88 iteration 100 with loss 0.2840845\n","Training at Epoch 88 iteration 200 with loss 0.21019131\n","Training at Epoch 88 iteration 300 with loss 0.33276334\n","optimal threshold: 0.5\n","AUROC:0.5473717367375337\n","AUPRC: 0.5385644401222527\n","Confusion Matrix : \n"," [[1680 1278]\n"," [1462 1468]]\n","Recall :  0.5010238907849829\n","Precision :  0.5345957756737072\n","Accuracy :  0.5346467391304348\n","Sensitivity :  0.5679513184584178\n","Specificity :  0.5010238907849829\n","Validation at Epoch 88 , AUROC: 0.5473717367375337 , AUPRC: 0.5385644401222527 , F1: 0.5172656800563776 , Val loss: 1.0532236099243164 , Accuracy: 0.5346467391304348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9968636794881153\n","AUPRC: 0.9969623069567806\n","Confusion Matrix : \n"," [[11422   303]\n"," [  466 11425]]\n","Recall :  0.9608106971659238\n","Precision :  0.9741643929058663\n","Accuracy :  0.9674373306233063\n","Sensitivity :  0.9741577825159915\n","Specificity :  0.9608106971659238\n","Training at Epoch 88 , AUROC: 0.9968636794881153 , AUPRC: 0.9969623069567806 , F1: 0.9674414666158602 , Train loss: 0.137648344039917 , Accuracy: 0.9674373306233063\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 89 iteration 100 with loss 0.3057155\n","Training at Epoch 89 iteration 200 with loss 0.15220964\n","Training at Epoch 89 iteration 300 with loss 0.3049791\n","optimal threshold: 0.5\n","AUROC:0.5529338408766187\n","AUPRC: 0.5472320439930637\n","Confusion Matrix : \n"," [[1708 1253]\n"," [1451 1476]]\n","Recall :  0.5042705842159207\n","Precision :  0.5408574569439355\n","Accuracy :  0.5407608695652174\n","Sensitivity :  0.5768321513002365\n","Specificity :  0.5042705842159207\n","Validation at Epoch 89 , AUROC: 0.5529338408766187 , AUPRC: 0.5472320439930637 , F1: 0.521923620933522 , Val loss: 1.0731298923492432 , Accuracy: 0.5407608695652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9970220655867552\n","AUPRC: 0.9971288340268958\n","Confusion Matrix : \n"," [[11417   307]\n"," [  398 11494]]\n","Recall :  0.9665321224352506\n","Precision :  0.9739852554868231\n","Accuracy :  0.9701473577235772\n","Sensitivity :  0.9738143978164449\n","Specificity :  0.9665321224352506\n","Training at Epoch 89 , AUROC: 0.9970220655867552 , AUPRC: 0.9971288340268958 , F1: 0.9702443759760266 , Train loss: 0.12991364300251007 , Accuracy: 0.9701473577235772\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 90 iteration 100 with loss 0.21743175\n","Training at Epoch 90 iteration 200 with loss 0.23712763\n","Training at Epoch 90 iteration 300 with loss 0.2562908\n","optimal threshold: 0.5\n","AUROC:0.5470513541657652\n","AUPRC: 0.5378542736809879\n","Confusion Matrix : \n"," [[1745 1218]\n"," [1536 1389]]\n","Recall :  0.4748717948717949\n","Precision :  0.5327963176064442\n","Accuracy :  0.5322690217391305\n","Sensitivity :  0.5889301383732704\n","Specificity :  0.4748717948717949\n","Validation at Epoch 90 , AUROC: 0.5470513541657652 , AUPRC: 0.5378542736809879 , F1: 0.5021691973969632 , Val loss: 1.092826008796692 , Accuracy: 0.5322690217391305\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9971293291732386\n","AUPRC: 0.9972276256270649\n","Confusion Matrix : \n"," [[11508   220]\n"," [  539 11349]]\n","Recall :  0.9546601615074024\n","Precision :  0.9809836632379635\n","Accuracy :  0.9678607723577236\n","Sensitivity :  0.9812414733969986\n","Specificity :  0.9546601615074024\n","Training at Epoch 90 , AUROC: 0.9971293291732386 , AUPRC: 0.9972276256270649 , F1: 0.9676429210896533 , Train loss: 0.1318749338388443 , Accuracy: 0.9678607723577236\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 91 iteration 100 with loss 0.20008731\n","Training at Epoch 91 iteration 200 with loss 0.43271828\n","Training at Epoch 91 iteration 300 with loss 0.3015529\n","optimal threshold: 0.5\n","AUROC:0.5498332733348101\n","AUPRC: 0.5384394724890094\n","Confusion Matrix : \n"," [[1766 1194]\n"," [1510 1418]]\n","Recall :  0.4842896174863388\n","Precision :  0.5428790199081164\n","Accuracy :  0.5407608695652174\n","Sensitivity :  0.5966216216216216\n","Specificity :  0.4842896174863388\n","Validation at Epoch 91 , AUROC: 0.5498332733348101 , AUPRC: 0.5384394724890094 , F1: 0.5119133574007221 , Val loss: 1.069981336593628 , Accuracy: 0.5407608695652174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9969466291092205\n","AUPRC: 0.9970535341443496\n","Confusion Matrix : \n"," [[11417   308]\n"," [  431 11460]]\n","Recall :  0.9637540997392986\n","Precision :  0.9738273283480625\n","Accuracy :  0.9687076558265583\n","Sensitivity :  0.9737313432835821\n","Specificity :  0.9637540997392986\n","Training at Epoch 91 , AUROC: 0.9969466291092205 , AUPRC: 0.9970535341443496 , F1: 0.9687645293545796 , Train loss: 0.13598084449768066 , Accuracy: 0.9687076558265583\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 92 iteration 100 with loss 0.16916242\n","Training at Epoch 92 iteration 200 with loss 0.35249156\n","Training at Epoch 92 iteration 300 with loss 0.2887398\n","optimal threshold: 0.5\n","AUROC:0.5539894925482798\n","AUPRC: 0.5444891434787956\n","Confusion Matrix : \n"," [[1552 1404]\n"," [1320 1612]]\n","Recall :  0.5497953615279673\n","Precision :  0.5344827586206896\n","Accuracy :  0.5373641304347826\n","Sensitivity :  0.5250338294993234\n","Specificity :  0.5497953615279673\n","Validation at Epoch 92 , AUROC: 0.5539894925482798 , AUPRC: 0.5444891434787956 , F1: 0.5420309347679892 , Val loss: 1.0491642951965332 , Accuracy: 0.5373641304347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9975485392456964\n","AUPRC: 0.997645549140147\n","Confusion Matrix : \n"," [[11231   494]\n"," [  212 11679]]\n","Recall :  0.9821713901269868\n","Precision :  0.9594183849502999\n","Accuracy :  0.9701050135501355\n","Sensitivity :  0.9578678038379531\n","Specificity :  0.9821713901269868\n","Training at Epoch 92 , AUROC: 0.9975485392456964 , AUPRC: 0.997645549140147 , F1: 0.9706615691489362 , Train loss: 0.13042889535427094 , Accuracy: 0.9701050135501355\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 93 iteration 100 with loss 0.26334947\n","Training at Epoch 93 iteration 200 with loss 0.3148045\n","Training at Epoch 93 iteration 300 with loss 0.19380063\n","optimal threshold: 0.5\n","AUROC:0.5486101680287244\n","AUPRC: 0.5450632341207096\n","Confusion Matrix : \n"," [[1649 1310]\n"," [1445 1484]]\n","Recall :  0.5066575623079549\n","Precision :  0.5311381531853973\n","Accuracy :  0.5320991847826086\n","Sensitivity :  0.5572828658330518\n","Specificity :  0.5066575623079549\n","Validation at Epoch 93 , AUROC: 0.5486101680287244 , AUPRC: 0.5450632341207096 , F1: 0.5186091210903372 , Val loss: 1.0715152025222778 , Accuracy: 0.5320991847826086\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.997420182091326\n","AUPRC: 0.9974998559275292\n","Confusion Matrix : \n"," [[11331   391]\n"," [  280 11614]]\n","Recall :  0.9764587186816882\n","Precision :  0.9674302374010829\n","Accuracy :  0.9715870596205962\n","Sensitivity :  0.9666439174202355\n","Specificity :  0.9764587186816882\n","Training at Epoch 93 , AUROC: 0.997420182091326 , AUPRC: 0.9974998559275292 , F1: 0.9719235114439936 , Train loss: 0.12332134693861008 , Accuracy: 0.9715870596205962\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 94 iteration 100 with loss 0.30114177\n","Training at Epoch 94 iteration 200 with loss 0.5010002\n","Training at Epoch 94 iteration 300 with loss 0.28128126\n","optimal threshold: 0.5\n","AUROC:0.5496866409684107\n","AUPRC: 0.5415187043733414\n","Confusion Matrix : \n"," [[1735 1229]\n"," [1534 1390]]\n","Recall :  0.47537619699042405\n","Precision :  0.5307369224894998\n","Accuracy :  0.5307404891304348\n","Sensitivity :  0.585357624831309\n","Specificity :  0.47537619699042405\n","Validation at Epoch 94 , AUROC: 0.5496866409684107 , AUPRC: 0.5415187043733414 , F1: 0.501533465632329 , Val loss: 1.114552617073059 , Accuracy: 0.5307404891304348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9978231418430609\n","AUPRC: 0.9978742924066044\n","Confusion Matrix : \n"," [[11449   275]\n"," [  374 11518]]\n","Recall :  0.9685502859064917\n","Precision :  0.9766810819977954\n","Accuracy :  0.9725186314363143\n","Sensitivity :  0.9765438416922552\n","Specificity :  0.9685502859064917\n","Training at Epoch 94 , AUROC: 0.9978231418430609 , AUPRC: 0.9978742924066044 , F1: 0.9725986911547392 , Train loss: 0.11644765734672546 , Accuracy: 0.9725186314363143\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 95 iteration 100 with loss 0.25912097\n","Training at Epoch 95 iteration 200 with loss 0.26673782\n","Training at Epoch 95 iteration 300 with loss 0.26044628\n","optimal threshold: 0.5\n","AUROC:0.5488091529420995\n","AUPRC: 0.5462867607182795\n","Confusion Matrix : \n"," [[1715 1243]\n"," [1502 1428]]\n","Recall :  0.48737201365187716\n","Precision :  0.5346312242605765\n","Accuracy :  0.533797554347826\n","Sensitivity :  0.5797836375929682\n","Specificity :  0.48737201365187716\n","Validation at Epoch 95 , AUROC: 0.5488091529420995 , AUPRC: 0.5462867607182795 , F1: 0.50990894483128 , Val loss: 1.0938762426376343 , Accuracy: 0.533797554347826\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9977930855695114\n","AUPRC: 0.9978502855830313\n","Confusion Matrix : \n"," [[11408   316]\n"," [  324 11568]]\n","Recall :  0.9727547931382442\n","Precision :  0.9734096263884214\n","Accuracy :  0.9728997289972899\n","Sensitivity :  0.9730467417263733\n","Specificity :  0.9727547931382442\n","Training at Epoch 95 , AUROC: 0.9977930855695114 , AUPRC: 0.9978502855830313 , F1: 0.9730820995962315 , Train loss: 0.11817048490047455 , Accuracy: 0.9728997289972899\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 96 iteration 100 with loss 0.41434595\n","Training at Epoch 96 iteration 200 with loss 0.30129856\n","Training at Epoch 96 iteration 300 with loss 0.3300208\n","optimal threshold: 0.5\n","AUROC:0.5440620334281765\n","AUPRC: 0.5376676788235839\n","Confusion Matrix : \n"," [[1789 1169]\n"," [1614 1316]]\n","Recall :  0.4491467576791809\n","Precision :  0.5295774647887324\n","Accuracy :  0.52734375\n","Sensitivity :  0.6048005409060175\n","Specificity :  0.4491467576791809\n","Validation at Epoch 96 , AUROC: 0.5440620334281765 , AUPRC: 0.5376676788235839 , F1: 0.4860572483841181 , Val loss: 1.1006218194961548 , Accuracy: 0.52734375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9975247403317723\n","AUPRC: 0.9975882822636248\n","Confusion Matrix : \n"," [[11534   192]\n"," [  532 11358]]\n","Recall :  0.9552565180824222\n","Precision :  0.9833766233766233\n","Accuracy :  0.9693428184281843\n","Sensitivity :  0.9836261299675934\n","Specificity :  0.9552565180824222\n","Training at Epoch 96 , AUROC: 0.9975247403317723 , AUPRC: 0.9975882822636248 , F1: 0.9691126279863481 , Train loss: 0.1243518590927124 , Accuracy: 0.9693428184281843\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 97 iteration 100 with loss 0.25823832\n","Training at Epoch 97 iteration 200 with loss 0.3071736\n","Training at Epoch 97 iteration 300 with loss 0.22952104\n","optimal threshold: 0.5\n","AUROC:0.5417596880826399\n","AUPRC: 0.5373686867587111\n","Confusion Matrix : \n"," [[1695 1264]\n"," [1540 1389]]\n","Recall :  0.47422328439740524\n","Precision :  0.5235582359592914\n","Accuracy :  0.5237771739130435\n","Sensitivity :  0.5728286583305171\n","Specificity :  0.47422328439740524\n","Validation at Epoch 97 , AUROC: 0.5417596880826399 , AUPRC: 0.5373686867587111 , F1: 0.4976710856323898 , Val loss: 1.0671131610870361 , Accuracy: 0.5237771739130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9981027152502464\n","AUPRC: 0.9981461666367899\n","Confusion Matrix : \n"," [[11480   246]\n"," [  338 11552]]\n","Recall :  0.9715727502102607\n","Precision :  0.9791490083064927\n","Accuracy :  0.9752710027100271\n","Sensitivity :  0.9790209790209791\n","Specificity :  0.9715727502102607\n","Training at Epoch 97 , AUROC: 0.9981027152502464 , AUPRC: 0.9981461666367899 , F1: 0.9753461668355284 , Train loss: 0.12270906567573547 , Accuracy: 0.9752710027100271\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 98 iteration 100 with loss 0.18434614\n","Training at Epoch 98 iteration 200 with loss 0.4164602\n","Training at Epoch 98 iteration 300 with loss 0.30262345\n","optimal threshold: 0.5\n","AUROC:0.5472974953189247\n","AUPRC: 0.540675952462057\n","Confusion Matrix : \n"," [[1622 1340]\n"," [1395 1531]]\n","Recall :  0.5232399179767601\n","Precision :  0.5332636711947056\n","Accuracy :  0.5354959239130435\n","Sensitivity :  0.5476029709655638\n","Specificity :  0.5232399179767601\n","Validation at Epoch 98 , AUROC: 0.5472974953189247 , AUPRC: 0.540675952462057 , F1: 0.5282042435742627 , Val loss: 1.1278061866760254 , Accuracy: 0.5354959239130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.998096904780579\n","AUPRC: 0.9981558542654769\n","Confusion Matrix : \n"," [[11365   356]\n"," [  230 11665]]\n","Recall :  0.9806641445985709\n","Precision :  0.9703851593045504\n","Accuracy :  0.9751863143631436\n","Sensitivity :  0.9696271649176691\n","Specificity :  0.9806641445985709\n","Training at Epoch 98 , AUROC: 0.998096904780579 , AUPRC: 0.9981558542654769 , F1: 0.9754975748452919 , Train loss: 0.11264785379171371 , Accuracy: 0.9751863143631436\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 99 iteration 100 with loss 0.3386988\n","Training at Epoch 99 iteration 200 with loss 0.34725398\n","Training at Epoch 99 iteration 300 with loss 0.15955971\n","optimal threshold: 0.5\n","AUROC:0.5439857239317063\n","AUPRC: 0.5379563991974767\n","Confusion Matrix : \n"," [[1770 1192]\n"," [1589 1337]]\n","Recall :  0.4569377990430622\n","Precision :  0.5286674574930803\n","Accuracy :  0.5276834239130435\n","Sensitivity :  0.5975692099932478\n","Specificity :  0.4569377990430622\n","Validation at Epoch 99 , AUROC: 0.5439857239317063 , AUPRC: 0.5379563991974767 , F1: 0.4901924839596701 , Val loss: 1.1158610582351685 , Accuracy: 0.5276834239130435\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9982415118452201\n","AUPRC: 0.9982842202500589\n","Confusion Matrix : \n"," [[11529   193]\n"," [  390 11504]]\n","Recall :  0.9672103581637801\n","Precision :  0.9835000427460032\n","Accuracy :  0.9753133468834688\n","Sensitivity :  0.9835352328954103\n","Specificity :  0.9672103581637801\n","Training at Epoch 99 , AUROC: 0.9982415118452201 , AUPRC: 0.9982842202500589 , F1: 0.9752871857911916 , Train loss: 0.11252041161060333 , Accuracy: 0.9753133468834688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["Training at Epoch 100 iteration 100 with loss 0.29450095\n","Training at Epoch 100 iteration 200 with loss 0.32679528\n","Training at Epoch 100 iteration 300 with loss 0.36892617\n","optimal threshold: 0.5\n","AUROC:0.5500623061586176\n","AUPRC: 0.5451173151439852\n","Confusion Matrix : \n"," [[1649 1311]\n"," [1427 1501]]\n","Recall :  0.512636612021858\n","Precision :  0.5337837837837838\n","Accuracy :  0.5349864130434783\n","Sensitivity :  0.5570945945945946\n","Specificity :  0.512636612021858\n","Validation at Epoch 100 , AUROC: 0.5500623061586176 , AUPRC: 0.5451173151439852 , F1: 0.5229965156794425 , Val loss: 1.1213092803955078 , Accuracy: 0.5349864130434783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.9983022821917708\n","AUPRC: 0.9983538836786199\n","Confusion Matrix : \n"," [[11517   211]\n"," [  338 11550]]\n","Recall :  0.9715679676985195\n","Precision :  0.9820593486948389\n","Accuracy :  0.9767530487804879\n","Sensitivity :  0.9820088676671214\n","Specificity :  0.9715679676985195\n","Training at Epoch 100 , AUROC: 0.9983022821917708 , AUPRC: 0.9983538836786199 , F1: 0.9767854877584675 , Train loss: 0.1074172779917717 , Accuracy: 0.9767530487804879\n","max validation accuracy 0.5961476599584167\n","3349.759884595871\n"]}]},{"cell_type":"code","source":["#@title loss plot\n","plt.rcParams['figure.figsize'] = [10,5]\n","fig,(ax1,ax2) = plt.subplots(1,2)\n","fig.suptitle(\"model3;lr:0.01;batch_size:64*1;train_size:23660\",fontsize=16)\n","loss_train =[ loss.cpu().detach().numpy() for loss in loss_history]\n","\n","\n","lh = list(filter(lambda x: x < 1, loss_train))\n","lh = [lh[i] for i in list(range(0,len(lh),369))]\n","# lh = list(filter(lambda x: x < 1, loss_val))\n","ax1.plot(lh)\n","ax1.set_title('train/val loss')\n","ax1.plot(loss_val,color='tab:orange')\n","ax2.plot(acc_train)\n","ax2.set_title('train/val accuracy')\n","ax2.plot(acc_val,color='tab:orange')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"-B0UODPAqZSX","executionInfo":{"status":"ok","timestamp":1647569932321,"user_tz":420,"elapsed":1831,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"517b8f5a-3d63-493b-c915-1132d1de993d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f0f3467f6d0>]"]},"metadata":{},"execution_count":6},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#@title total parameters\n","from prettytable import PrettyTable\n","\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params+=params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","    \n","count_parameters(model_max)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTNLzkZ9qTCf","executionInfo":{"status":"ok","timestamp":1647471968649,"user_tz":420,"elapsed":423,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"b51f4ffb-d6b6-4733-cbe5-efd3b257474f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+------------+\n","|     Modules      | Parameters |\n","+------------------+------------+\n","|  demb.l1.weight  |   393216   |\n","|   demb.l1.bias   |    512     |\n","| demb.bn1.weight  |    512     |\n","|  demb.bn1.bias   |    512     |\n","|  pemb.l1.weight  |   98304    |\n","|   pemb.l1.bias   |    256     |\n","| pemb.bn1.weight  |    256     |\n","|  pemb.bn1.bias   |    256     |\n","| decoder.0.weight |   393216   |\n","|  decoder.0.bias  |    512     |\n","| decoder.2.weight |    512     |\n","|  decoder.2.bias  |    512     |\n","| decoder.3.weight |   32768    |\n","|  decoder.3.bias  |     64     |\n","| decoder.5.weight |     64     |\n","|  decoder.5.bias  |     64     |\n","| decoder.6.weight |    2048    |\n","|  decoder.6.bias  |     32     |\n","| decoder.8.weight |     32     |\n","|  decoder.8.bias  |     1      |\n","+------------------+------------+\n","Total Trainable Params: 923649\n"]},{"output_type":"execute_result","data":{"text/plain":["923649"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#@title define configurations\n","config = BIN_config_DBPE()\n","\n","lr = config['learning_rate']\n","BATCH_SIZE = config['batch_size']\n","train_epoch = config['train_epoch']\n","accumulation_steps = config['accumulation_steps']\n","\n","print(\"learning rate:\",lr)\n","print(\"batch size:\",BATCH_SIZE)\n","print(\"training epoch:\",train_epoch)\n","print(\"accumulation steps:\", accumulation_steps)\n","\n","\n","loss_history = []\n","loss_history_val = []\n","\n","model = BIN_Interaction_Flat(**config)\n","\n","if use_cuda:\n","  model = model.cuda()\n","\n","if torch.cuda.device_count() > 1:\n","  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","  model = nn.DataParallel(model, dim = 0)\n","elif torch.cuda.device_count() < 1:\n","  print(\"Let's use cpu!\")\n","\n","opt = torch.optim.Adam(model.parameters(), lr = lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MV2FMsTQgH9","outputId":"dd0bb243-30a2-4e03-dbe8-6e1e80130a43","executionInfo":{"status":"ok","timestamp":1647474863486,"user_tz":420,"elapsed":269,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["learning rate: 0.0001\n","batch size: 64\n","training epoch: 500\n","accumulation steps: 10\n"]}]},{"cell_type":"code","source":["#@title import data\n","print('--- Data Preparation ---')\n","params = {'batch_size': BATCH_SIZE,\n","  'shuffle': True,\n","  'num_workers': 6, \n","  'drop_last': True}\n","dataFolder = '/content/drive/MyDrive/Proj4_DPI/data/data_with_embedding/'\n","df = pd.read_pickle(dataFolder + '/train_loc0.pkl')\n","df_train, df_val = train_test_split(df, test_size=0.2)\n","\n","training_set = BIN_Data_Encoder(np.array([i for i in range(df_train.shape[0])]), df_train.label.values, df_train)\n","training_generator = data.DataLoader(training_set, **params)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvwmSYG6Qp-L","outputId":"36d69ce4-527f-4878-c8d3-3507c340b15c","executionInfo":{"status":"ok","timestamp":1647475885034,"user_tz":420,"elapsed":87395,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Data Preparation ---\n"]}]},{"cell_type":"code","source":["dataFolder = '/content/drive/MyDrive/Proj4_DPI/data/data_with_embedding/'\n","df1 = pd.read_pickle(dataFolder + 'AP2A_test.pkl')\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"hLSlZDMkRkNo","executionInfo":{"status":"ok","timestamp":1647538613348,"user_tz":420,"elapsed":68165,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"0a67d0e3-8989-42ae-aeb0-4dfa56a02bfa"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                loc  \\\n","0      >chr1:46269501-46269601_shuf   \n","1        >chr12:133263989-133264089   \n","2     >chr22:37593175-37593275_shuf   \n","3          >chr17:80208886-80208986   \n","4     >chr12:96825025-96825125_shuf   \n","...                             ...   \n","7389       >chr12:93964945-93965045   \n","7390       >chr18:45494536-45494636   \n","7391      >chr3:134204549-134204649   \n","7392       >chr16:29836592-29836692   \n","7393      >chr3:180630144-180630244   \n","\n","                                                    dna  label protein  \\\n","0     TGCACGGCGGAGCCGGCCTCCGCAATGCGTGCCCGGCCCGTGCTGC...      0    AP2A   \n","1     TCAAGAGGCGCGCTCCGCCCCTCCCCCGCCCCCCGAGGCGCTCCAA...      1    AP2A   \n","2     TCAACTTGATGCTCTGCCAACCCAGAGGGCAAGGGGGATTAGAACC...      0    AP2A   \n","3     CTCGTGGGCACCACGACCATGTGGCACAGCGAATGGGAATGCGCAC...      1    AP2A   \n","4     GGAGGCAACAGGAGAAGAGGTAGTGGAAGGTAAGAAGGAAGGTGGC...      0    AP2A   \n","...                                                 ...    ...     ...   \n","7389  GCACAGCCTCAGGATACCCCGTGCCCGCAGCTCGGGCGCCCGCGGC...      1    AP2A   \n","7390  ACCCTAAATCACATTGTTAGACTATCTGGAGTGACCCAAGGCACTC...      1    AP2A   \n","7391  ACAGGCCGTCCCTCAGCTGCGGCTTCCTGCCTCAGGCAGGATGTAC...      1    AP2A   \n","7392  GAAGTTGGGTGGATGAGTGGATCTGGGGAGCAGGGGCCAAGCCTGA...      1    AP2A   \n","7393  GGCACTACTCGGCCGCCGCGGTGCGAACTGCGGGCACTGTGGGGCG...      1    AP2A   \n","\n","                                          dna_embedding  \\\n","0     [[tensor(-0.2545), tensor(-1.1461), tensor(1.9...   \n","1     [[tensor(0.3619), tensor(-0.0255), tensor(-1.0...   \n","2     [[tensor(0.1183), tensor(0.1185), tensor(-1.11...   \n","3     [[tensor(-0.0361), tensor(-0.8620), tensor(0.7...   \n","4     [[tensor(-0.8833), tensor(-0.3277), tensor(0.6...   \n","...                                                 ...   \n","7389  [[tensor(-1.5224), tensor(-0.9559), tensor(1.3...   \n","7390  [[tensor(0.6827), tensor(-1.2677), tensor(-1.1...   \n","7391  [[tensor(-0.2463), tensor(0.0003), tensor(-1.3...   \n","7392  [[tensor(0.0367), tensor(-0.1440), tensor(0.48...   \n","7393  [[tensor(2.3220), tensor(0.8628), tensor(-1.11...   \n","\n","                                      protein_embedding  \n","0     [[-30.172863, -10.496992, 86.36631, 16.755226,...  \n","1     [[-30.167542, -10.492926, 86.37228, 16.762302,...  \n","2     [[-20.186104, 26.972698, -42.055893, 2.5008981...  \n","3     [[-30.167542, -10.492926, 86.37228, 16.762302,...  \n","4     [[-20.186108, 26.972656, -42.055893, 2.5009115...  \n","...                                                 ...  \n","7389  [[-20.186108, 26.972656, -42.055893, 2.5009115...  \n","7390  [[-30.167542, -10.492926, 86.37228, 16.762302,...  \n","7391  [[-30.167542, -10.492926, 86.37228, 16.762302,...  \n","7392  [[-20.186104, 26.972698, -42.055893, 2.5008981...  \n","7393  [[-20.186104, 26.972698, -42.055893, 2.5008981...  \n","\n","[7394 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-f5d29305-3298-4878-9c37-4df6c00a1323\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loc</th>\n","      <th>dna</th>\n","      <th>label</th>\n","      <th>protein</th>\n","      <th>dna_embedding</th>\n","      <th>protein_embedding</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&gt;chr1:46269501-46269601_shuf</td>\n","      <td>TGCACGGCGGAGCCGGCCTCCGCAATGCGTGCCCGGCCCGTGCTGC...</td>\n","      <td>0</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(-0.2545), tensor(-1.1461), tensor(1.9...</td>\n","      <td>[[-30.172863, -10.496992, 86.36631, 16.755226,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&gt;chr12:133263989-133264089</td>\n","      <td>TCAAGAGGCGCGCTCCGCCCCTCCCCCGCCCCCCGAGGCGCTCCAA...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(0.3619), tensor(-0.0255), tensor(-1.0...</td>\n","      <td>[[-30.167542, -10.492926, 86.37228, 16.762302,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&gt;chr22:37593175-37593275_shuf</td>\n","      <td>TCAACTTGATGCTCTGCCAACCCAGAGGGCAAGGGGGATTAGAACC...</td>\n","      <td>0</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(0.1183), tensor(0.1185), tensor(-1.11...</td>\n","      <td>[[-20.186104, 26.972698, -42.055893, 2.5008981...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&gt;chr17:80208886-80208986</td>\n","      <td>CTCGTGGGCACCACGACCATGTGGCACAGCGAATGGGAATGCGCAC...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(-0.0361), tensor(-0.8620), tensor(0.7...</td>\n","      <td>[[-30.167542, -10.492926, 86.37228, 16.762302,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&gt;chr12:96825025-96825125_shuf</td>\n","      <td>GGAGGCAACAGGAGAAGAGGTAGTGGAAGGTAAGAAGGAAGGTGGC...</td>\n","      <td>0</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(-0.8833), tensor(-0.3277), tensor(0.6...</td>\n","      <td>[[-20.186108, 26.972656, -42.055893, 2.5009115...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7389</th>\n","      <td>&gt;chr12:93964945-93965045</td>\n","      <td>GCACAGCCTCAGGATACCCCGTGCCCGCAGCTCGGGCGCCCGCGGC...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(-1.5224), tensor(-0.9559), tensor(1.3...</td>\n","      <td>[[-20.186108, 26.972656, -42.055893, 2.5009115...</td>\n","    </tr>\n","    <tr>\n","      <th>7390</th>\n","      <td>&gt;chr18:45494536-45494636</td>\n","      <td>ACCCTAAATCACATTGTTAGACTATCTGGAGTGACCCAAGGCACTC...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(0.6827), tensor(-1.2677), tensor(-1.1...</td>\n","      <td>[[-30.167542, -10.492926, 86.37228, 16.762302,...</td>\n","    </tr>\n","    <tr>\n","      <th>7391</th>\n","      <td>&gt;chr3:134204549-134204649</td>\n","      <td>ACAGGCCGTCCCTCAGCTGCGGCTTCCTGCCTCAGGCAGGATGTAC...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(-0.2463), tensor(0.0003), tensor(-1.3...</td>\n","      <td>[[-30.167542, -10.492926, 86.37228, 16.762302,...</td>\n","    </tr>\n","    <tr>\n","      <th>7392</th>\n","      <td>&gt;chr16:29836592-29836692</td>\n","      <td>GAAGTTGGGTGGATGAGTGGATCTGGGGAGCAGGGGCCAAGCCTGA...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(0.0367), tensor(-0.1440), tensor(0.48...</td>\n","      <td>[[-20.186104, 26.972698, -42.055893, 2.5008981...</td>\n","    </tr>\n","    <tr>\n","      <th>7393</th>\n","      <td>&gt;chr3:180630144-180630244</td>\n","      <td>GGCACTACTCGGCCGCCGCGGTGCGAACTGCGGGCACTGTGGGGCG...</td>\n","      <td>1</td>\n","      <td>AP2A</td>\n","      <td>[[tensor(2.3220), tensor(0.8628), tensor(-1.11...</td>\n","      <td>[[-20.186104, 26.972698, -42.055893, 2.5008981...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7394 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5d29305-3298-4878-9c37-4df6c00a1323')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f5d29305-3298-4878-9c37-4df6c00a1323 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f5d29305-3298-4878-9c37-4df6c00a1323');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["np.mean(df1.protein_embedding[2],0)\n","# np.mean(df1.protein_embedding[0],0).shape\n","\n","# torch.mean(df_train.dna_embedding[1],1)\n","# df_train.dna_embedding[1]\n","# df_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2SeshV-JxTw","executionInfo":{"status":"ok","timestamp":1647538784142,"user_tz":420,"elapsed":440,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"b4532f85-0bb6-46c1-ed2e-cf9470b89e5b"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.72474270e+01,  1.94261017e+01,  3.16818447e+01,  2.61945572e+01,\n","        4.93630505e+00,  2.88548183e+01,  5.32391510e+01,  5.11433363e+00,\n","        5.30914497e+01, -4.67658669e-01,  3.23271751e+01,  2.59690475e+01,\n","        5.10427933e+01,  8.17041302e+00,  2.62861753e+00,  3.18373513e+00,\n","        6.14768066e+01,  4.20012856e+01,  1.39204607e+01,  9.57683029e+01,\n","        7.15247269e+01,  1.69385872e+01,  3.28646660e+01, -6.52385235e-01,\n","        5.09144306e-01,  1.71958237e+01,  8.92241516e+01,  3.98124580e+01,\n","        2.81149139e+01,  3.14567032e+01, -9.74705315e+00,  3.35254822e+01,\n","       -9.98736095e+00,  2.00740547e+01,  7.95193863e+00,  8.22505951e+00,\n","        2.29431019e+01,  2.87653828e+01,  6.57051706e+00, -2.03486462e+01,\n","        9.05561676e+01,  2.51319695e+01, -4.99575138e+00,  9.26465149e+01,\n","       -3.48928662e+03,  1.43617802e+01,  5.40350227e+01,  4.73154106e+01,\n","        4.91893539e+01,  1.07471466e+02,  2.12962971e+01,  4.90958290e+01,\n","        2.42263222e+01,  4.96661072e+01,  7.08911085e+00,  2.53046417e+01,\n","        3.29535604e-01,  4.03226805e+00,  3.50878296e+01,  1.77156239e+01,\n","        2.24204559e+01,  1.92983665e+01,  1.14770031e+01,  2.87588749e+01,\n","        5.28922882e+01,  7.55882034e+01,  1.16581411e+01, -2.16500988e+01,\n","        3.76798782e+01,  9.95657444e+00,  1.91087592e+00,  5.06405945e+01,\n","        1.47270222e+01, -1.11199636e+01,  2.97055302e+01, -3.10264722e+03,\n","        1.90125256e+01, -3.50048608e+03, -8.18648148e+00,  3.33225799e+00,\n","       -9.00104427e+00,  4.49560127e+01, -6.09411812e+00,  3.92017097e+01,\n","        5.32203257e-01,  3.49779663e+01,  3.86962700e+01, -4.46846932e-01,\n","        3.72941322e+01,  5.40354042e+01,  3.63804674e+00, -1.96600075e+01,\n","        5.25793953e+01,  1.14431453e+00, -1.80632095e+01,  3.59913445e+01,\n","        4.69141054e+00,  5.84678650e+01, -3.31683276e+03,  8.89787483e+00,\n","        2.53887730e+01, -6.10347700e+00, -4.57557259e+01,  3.81153603e+01,\n","        8.95882249e-01, -3.47536469e+00,  7.89034247e-01,  1.29679132e+00,\n","        1.87918377e+01,  2.37889595e+01,  1.85526600e+01,  7.71921310e+01,\n","        2.82753696e+01,  5.61329041e+01,  1.52652674e+01,  3.55199585e+01,\n","        3.51534386e+01,  5.71022272e+00,  9.93716908e+00,  3.07480106e+01,\n","       -1.59269104e+01,  3.66674728e+01,  2.00200825e+01, -8.21724892e+00,\n","        1.33413372e+01,  2.33790169e+01, -1.42585220e+01,  2.64970436e+01,\n","        4.50643206e+00,  3.39985428e+01,  1.17359406e+02,  4.36449928e+01,\n","        2.02833767e+01,  4.91775436e+01,  6.53913498e+01, -1.64579716e+01,\n","        3.25542183e+01,  6.60145378e+00,  2.72005234e+01,  4.28947105e+01,\n","        2.47560425e+01,  4.74654236e+01, -2.77103901e+01,  2.12947750e+01,\n","        8.75707722e+00,  1.46954718e+01, -1.08332596e+01,  5.13980408e+01,\n","        4.15737343e+01,  4.85734024e+01, -9.37930012e+00, -9.44065475e+00,\n","        1.42443955e+00,  2.38012333e+01,  5.97132645e+01,  5.66605644e+01,\n","        6.56939087e+01,  4.09950867e+01,  2.99457378e+01,  3.61638298e+01,\n","        5.06696701e-01,  1.15696564e+01,  6.03173256e+01,  1.80560627e+01,\n","        3.43234558e+01,  6.12944174e+00, -2.21102657e+01,  1.73616841e-01,\n","        6.47499313e+01,  3.11534729e+01,  6.75553513e+01,  5.17627869e+01,\n","        1.39835785e+02,  8.41540432e+00,  2.01632710e+01,  1.19687233e+01,\n","        7.09691095e+00,  1.56084280e+01, -1.38342724e+01,  6.20720329e+01,\n","        2.95844631e+01,  3.85081863e+01, -7.13793230e+00, -6.06499243e+00,\n","        1.86490288e+01,  5.92951012e+01,  4.19968796e+01,  1.53324747e+01,\n","       -5.39280748e+00, -4.49001503e+00, -1.12106047e+01,  8.88944092e+01,\n","        4.86324692e+00,  7.96162720e+01,  2.35977306e+01,  2.36584225e+01,\n","        4.43065147e+01,  1.25561676e+01,  2.51412582e+01,  4.19346581e+01,\n","        1.62438068e+01,  1.77185802e+01,  1.60944729e+01, -4.45836067e+00,\n","        2.49758987e+01, -2.05100274e+00,  4.62115364e+01,  2.31324558e+01,\n","        2.30431213e+01,  5.76520503e-01,  2.52381058e+01,  4.73049450e+00,\n","        2.27185516e+01,  1.24917870e+01,  1.58263168e+01,  9.64387035e+00,\n","       -3.57215571e+00,  6.91162643e+01, -2.34410143e+00,  7.96477842e+00,\n","        6.66744184e+00,  5.87574577e+01,  2.68596153e+01,  6.22860336e+01,\n","        4.06694527e+01, -5.61301184e+00,  1.10869148e+02,  1.58240948e+01,\n","        2.18895626e+01,  2.17983985e+00,  1.36363401e+01,  4.47796288e+01,\n","        7.91803646e+00,  9.20841904e+01,  5.02711601e+01,  3.47693977e+01,\n","       -9.30076027e+00,  9.55009613e+01, -3.29092163e+03,  3.07254195e+00,\n","        8.71281204e+01,  1.71254516e-01,  1.21509676e+01, -2.13486099e+01,\n","        3.43789024e+01,  3.21655464e+01,  5.20253906e+01,  4.72337875e+01,\n","        5.86407242e+01, -1.16614609e+01,  6.72604294e+01,  1.64654732e+01,\n","        5.15956917e+01,  2.27902431e+01, -5.38080835e+00, -1.97453442e+01,\n","        3.84924197e+00,  2.12501335e+01, -7.69542027e+00,  2.97570915e+01,\n","       -6.30184221e+00,  1.51824827e+01, -3.38515854e+00,  5.91844130e+00,\n","       -1.12122607e+00,  1.01146927e+01, -8.24190426e+00,  3.08070984e+01,\n","        5.02160835e+01,  3.98423424e+01, -1.23987083e+02, -3.78546429e+00,\n","        1.52805262e+01,  8.21503830e+00, -1.46756468e+01,  2.42304230e+01,\n","       -1.08773422e+01,  1.91466701e+00, -1.32702336e-01, -1.22812109e+01,\n","        4.72847328e+01, -3.84792519e+00,  3.09049873e+01, -2.40315604e+00,\n","        3.01908398e+01,  3.78993683e+01,  3.02544951e+00,  7.16138411e+00,\n","        1.24804153e+01,  3.87836990e+01,  3.76600304e+01,  3.91841888e+01,\n","        9.60738297e+01,  6.26225357e+01,  5.58215189e+00,  9.58752346e+00,\n","        6.61980820e+01,  2.86117482e+00,  5.22144556e+00,  7.63897467e+00,\n","        1.42714663e+01,  1.03684149e+01,  4.75898857e+01,  5.19768639e+01,\n","       -2.39166451e+01, -3.09269543e+01,  1.50335417e+01,  1.62065353e+01,\n","       -5.22118807e+00, -5.29762173e+00,  1.09602757e+01,  2.26907711e+01,\n","        1.07189951e+01, -6.13032997e-01,  7.91694641e+00,  5.33250523e+00,\n","        7.96128387e+01,  5.27702026e+01, -6.10569286e+00,  2.08304844e+01,\n","        2.59573612e+01,  4.25213280e+01, -8.83791065e+00,  1.24230251e+01,\n","       -6.38845730e+00,  4.26563072e+00,  1.07766731e+02,  3.51230888e+01,\n","        1.13693533e+01,  5.24323750e+00,  2.92496376e+01,  3.66283417e+01,\n","        5.06811905e+01,  4.74538898e+00,  4.03664436e+01,  7.65195465e+01,\n","        5.77911663e+00,  5.60560303e+01,  2.47139530e+01,  5.54222832e+01,\n","       -3.38820972e+03,  5.41159592e+01,  6.01699486e+01, -1.26179099e+00,\n","        5.67385435e-01, -2.46892986e+01,  1.78323174e+01,  2.61986504e+01,\n","        7.29713211e+01,  2.48105545e+01,  6.71229935e+01,  6.30191498e+01,\n","       -1.01852541e+01,  7.79723969e+01, -2.35457573e+01,  1.50098429e+01,\n","        2.01138000e+01,  1.12326035e+02,  8.72246647e+00, -1.83957860e-01,\n","        3.51443863e+00, -3.59296727e+00,  3.12661982e+00, -6.83131409e+01,\n","        3.83502846e+01, -1.01021072e+02,  1.25780606e+00,  2.31067715e+01,\n","       -1.31590521e+00,  1.82532597e+00,  5.82110634e+01,  1.03155127e+01,\n","        3.20827560e+01, -3.65484352e+01,  2.26180911e+00,  3.35622292e+01,\n","        1.17206888e+01,  6.50061131e-01,  3.28834190e+01,  3.07974663e+01,\n","        1.81762829e+01, -3.39923218e+03, -7.51906967e+00,  1.83999691e+01],\n","      dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df1.protein_embedding[2]"],"metadata":{"id":"XqC774Uck0eH","executionInfo":{"status":"ok","timestamp":1647538689164,"user_tz":420,"elapsed":235,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"ed1cfac2-8d12-4481-9f7d-f1cb3b4802a1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.0186104e+01,  2.6972698e+01, -4.2055893e+01, ...,\n","        -1.9898030e+03,  7.7662311e+00,  1.8435698e+01],\n","       [ 9.3969259e+00, -1.8718648e-01, -4.6260705e+00, ...,\n","        -2.6276663e+03, -2.1458220e+01,  1.2331333e+01],\n","       [-5.8022790e+00,  7.2602730e+01, -3.4618668e+01, ...,\n","        -3.1940386e+03,  6.6911148e+01,  8.8883423e+01],\n","       ...,\n","       [-5.8207962e+01, -1.4634252e-01,  5.8878094e+01, ...,\n","        -2.9482605e+03,  1.3981899e+01, -2.1234919e+01],\n","       [-5.8207962e+01, -1.4634252e-01,  5.8878094e+01, ...,\n","        -2.9482605e+03,  1.3981899e+01, -2.1234919e+01],\n","       [-5.8207977e+01, -1.4636159e-01,  5.8878105e+01, ...,\n","        -2.9482607e+03,  1.3981879e+01, -2.1234911e+01]], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["file = files[0]\n","print(file)\n","df1 = pd.read_pickle(dataFolder + file)\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zucsmkQlejfO","executionInfo":{"status":"ok","timestamp":1647480330355,"user_tz":420,"elapsed":248,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"d24dec7b-3801-40de-e83a-d8553f5657b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label0_TCAATATTTTGCTGATTGAATTTAGTTTCCCTGTTCCATTATCTGAAGAGGCCTGGGACGTGGGATTTCAACATCTTTGGTTGCCTTAAACTT\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.2271e+00, -3.5486e-01,  2.2246e-02,  ..., -1.1064e+00,\n","         -1.3647e+00, -1.3455e-01],\n","        [-1.2310e+00, -3.5493e-01,  3.9212e-03,  ..., -1.0964e+00,\n","         -1.3682e+00, -1.3454e-01],\n","        [-1.2321e+00, -3.5506e-01,  4.2392e-03,  ..., -1.0968e+00,\n","         -1.3678e+00, -1.3280e-01],\n","        ...,\n","        [-1.2355e+00, -3.5438e-01,  6.9817e-03,  ..., -1.0961e+00,\n","         -1.3674e+00, -1.2779e-01],\n","        [-1.2365e+00, -3.5423e-01,  5.7010e-03,  ..., -1.0952e+00,\n","         -1.3680e+00, -1.2630e-01],\n","        [-1.2365e+00, -3.5390e-01,  1.1665e-03,  ..., -1.0893e+00,\n","         -1.3727e+00, -1.2243e-01]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# torch.mean(df_train.dna_embedding[200],1)\n","df_train.dna_embedding[200]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLA_Noz_K96K","executionInfo":{"status":"ok","timestamp":1647475973777,"user_tz":420,"elapsed":530,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"61d23982-714a-4176-88bf-588f8018e855"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.2271e+00, -3.5486e-01,  2.2246e-02,  ..., -1.1064e+00,\n","         -1.3647e+00, -1.3455e-01],\n","        [-1.2310e+00, -3.5494e-01,  3.9210e-03,  ..., -1.0964e+00,\n","         -1.3682e+00, -1.3454e-01],\n","        [-1.2321e+00, -3.5505e-01,  4.2388e-03,  ..., -1.0968e+00,\n","         -1.3678e+00, -1.3280e-01],\n","        ...,\n","        [-1.2355e+00, -3.5438e-01,  6.9819e-03,  ..., -1.0961e+00,\n","         -1.3674e+00, -1.2779e-01],\n","        [-1.2365e+00, -3.5423e-01,  5.7008e-03,  ..., -1.0952e+00,\n","         -1.3680e+00, -1.2630e-01],\n","        [-1.2365e+00, -3.5390e-01,  1.1674e-03,  ..., -1.0894e+00,\n","         -1.3727e+00, -1.2243e-01]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["#@title model structure\n","!pip install torchviz\n","from torchviz import make_dot\n","batch = next(iter(training_generator))\n","d, p, targets = batch[0], batch[1], batch[2]\n","d = d.cuda()\n","p = p.cuda() \n","# make_dot(model(d,p),params=dict(list(model.named_parameters)))\n","make_dot(model(d,p))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_7qJZBsVFZJz","executionInfo":{"status":"ok","timestamp":1647472146087,"user_tz":420,"elapsed":6471,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"7fa94f0e-88c1-482a-9123-5bdb90375ffe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchviz\n","  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.10.0+cu111)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.10.0.2)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=2d42a576120ba4915c70b22c3b3792b9bab08de015a8bce09762349d1d93ae78\n","  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.2\n"]},{"output_type":"execute_result","data":{"text/plain":["<graphviz.dot.Digraph at 0x7f94a5552790>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"940pt\" height=\"1106pt\"\n viewBox=\"0.00 0.00 940.00 1106.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1102)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1102 936,-1102 936,4 -4,4\"/>\n<!-- 140275985917040 -->\n<g id=\"node1\" class=\"node\">\n<title>140275985917040</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"733,-31 668,-31 668,0 733,0 733,-31\"/>\n<text text-anchor=\"middle\" x=\"700.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64, 1)</text>\n</g>\n<!-- 140276405917776 -->\n<g id=\"node2\" class=\"node\">\n<title>140276405917776</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"751,-86 650,-86 650,-67 751,-67 751,-86\"/>\n<text text-anchor=\"middle\" x=\"700.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140276405917776&#45;&gt;140275985917040 -->\n<g id=\"edge64\" class=\"edge\">\n<title>140276405917776&#45;&gt;140275985917040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M700.5,-66.9688C700.5,-60.1289 700.5,-50.5621 700.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"704.0001,-41.3678 700.5,-31.3678 697.0001,-41.3678 704.0001,-41.3678\"/>\n</g>\n<!-- 140276405917968 -->\n<g id=\"node3\" class=\"node\">\n<title>140276405917968</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"635,-141 534,-141 534,-122 635,-122 635,-141\"/>\n<text text-anchor=\"middle\" x=\"584.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276405917968&#45;&gt;140276405917776 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140276405917968&#45;&gt;140276405917776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M604.7057,-121.9197C622.9737,-113.2581 650.1018,-100.3957 670.8304,-90.5675\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"672.6004,-93.6018 680.1367,-86.155 669.6014,-87.2768 672.6004,-93.6018\"/>\n</g>\n<!-- 140276405825616 -->\n<g id=\"node4\" class=\"node\">\n<title>140276405825616</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"611.5,-208 557.5,-208 557.5,-177 611.5,-177 611.5,-208\"/>\n<text text-anchor=\"middle\" x=\"584.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140276405825616&#45;&gt;140276405917968 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140276405825616&#45;&gt;140276405917968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M584.5,-176.791C584.5,-169.0249 584.5,-159.5706 584.5,-151.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"588.0001,-151.0647 584.5,-141.0648 581.0001,-151.0648 588.0001,-151.0647\"/>\n</g>\n<!-- 140275988619792 -->\n<g id=\"node5\" class=\"node\">\n<title>140275988619792</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"748,-141 653,-141 653,-122 748,-122 748,-141\"/>\n<text text-anchor=\"middle\" x=\"700.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140275988619792&#45;&gt;140276405917776 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140275988619792&#45;&gt;140276405917776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M700.5,-121.9197C700.5,-114.9083 700.5,-105.1442 700.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"704.0001,-96.3408 700.5,-86.3408 697.0001,-96.3409 704.0001,-96.3408\"/>\n</g>\n<!-- 140275988620560 -->\n<g id=\"node6\" class=\"node\">\n<title>140275988620560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"746,-202 645,-202 645,-183 746,-183 746,-202\"/>\n<text text-anchor=\"middle\" x=\"695.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140275988620560&#45;&gt;140275988619792 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140275988620560&#45;&gt;140275988619792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M696.2813,-182.9688C696.9743,-174.5131 698.009,-161.8901 698.8802,-151.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"702.379,-151.4182 699.7077,-141.1656 695.4024,-150.8462 702.379,-151.4182\"/>\n</g>\n<!-- 140275988620176 -->\n<g id=\"node7\" class=\"node\">\n<title>140275988620176</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"515,-269 414,-269 414,-250 515,-250 515,-269\"/>\n<text text-anchor=\"middle\" x=\"464.5\" y=\"-257\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988620176&#45;&gt;140275988620560 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140275988620176&#45;&gt;140275988620560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.5967,-249.9005C538.4221,-238.0594 607.9082,-217.9054 652.7391,-204.9025\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"653.8355,-208.2288 662.4647,-202.0817 651.8855,-201.5059 653.8355,-208.2288\"/>\n</g>\n<!-- 140276405747344 -->\n<g id=\"node8\" class=\"node\">\n<title>140276405747344</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"461.5,-342 407.5,-342 407.5,-311 461.5,-311 461.5,-342\"/>\n<text text-anchor=\"middle\" x=\"434.5\" y=\"-318\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140276405747344&#45;&gt;140275988620176 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140276405747344&#45;&gt;140275988620176</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M441.458,-310.9604C445.768,-301.3348 451.3356,-288.9004 455.9183,-278.6659\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"459.1972,-279.9073 460.0895,-269.3501 452.8084,-277.0466 459.1972,-279.9073\"/>\n</g>\n<!-- 140275988621072 -->\n<g id=\"node9\" class=\"node\">\n<title>140275988621072</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"724,-269 563,-269 563,-250 724,-250 724,-269\"/>\n<text text-anchor=\"middle\" x=\"643.5\" y=\"-257\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NativeBatchNormBackward0</text>\n</g>\n<!-- 140275988621072&#45;&gt;140275988620560 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140275988621072&#45;&gt;140275988620560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M650.9503,-249.9005C658.9821,-239.552 671.9415,-222.8542 681.8174,-210.1295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"684.6972,-212.1275 688.0635,-202.0817 679.1672,-207.8356 684.6972,-212.1275\"/>\n</g>\n<!-- 140275988621712 -->\n<g id=\"node10\" class=\"node\">\n<title>140275988621712</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"575,-336 480,-336 480,-317 575,-317 575,-336\"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-324\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140275988621712&#45;&gt;140275988621072 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140275988621712&#45;&gt;140275988621072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M544.12,-316.9005C563.5012,-305.7062 595.7455,-287.0823 618.2315,-274.0947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"620.002,-277.114 626.9109,-269.0817 616.5009,-271.0525 620.002,-277.114\"/>\n</g>\n<!-- 140275988619664 -->\n<g id=\"node11\" class=\"node\">\n<title>140275988619664</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"578,-403 477,-403 477,-384 578,-384 578,-403\"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-391\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140275988619664&#45;&gt;140275988621712 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140275988619664&#45;&gt;140275988621712</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M527.5,-383.9005C527.5,-374.149 527.5,-358.7597 527.5,-346.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.0001,-346.0816 527.5,-336.0817 524.0001,-346.0817 531.0001,-346.0816\"/>\n</g>\n<!-- 140275988621584 -->\n<g id=\"node12\" class=\"node\">\n<title>140275988621584</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"399,-464 298,-464 298,-445 399,-445 399,-464\"/>\n<text text-anchor=\"middle\" x=\"348.5\" y=\"-452\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988621584&#45;&gt;140275988619664 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140275988621584&#45;&gt;140275988619664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M376.4688,-444.9688C406.986,-434.569 456.0022,-417.8652 489.8764,-406.3214\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"491.0964,-409.6034 499.4329,-403.0648 488.8384,-402.9776 491.0964,-409.6034\"/>\n</g>\n<!-- 140276405746672 -->\n<g id=\"node13\" class=\"node\">\n<title>140276405746672</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"345.5,-531 291.5,-531 291.5,-500 345.5,-500 345.5,-531\"/>\n<text text-anchor=\"middle\" x=\"318.5\" y=\"-507\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140276405746672&#45;&gt;140275988621584 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140276405746672&#45;&gt;140275988621584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M326.2257,-499.791C330.2188,-491.6719 335.1192,-481.7077 339.306,-473.1945\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.5235,-474.5829 343.796,-464.0648 336.242,-471.4937 342.5235,-474.5829\"/>\n</g>\n<!-- 140275988622224 -->\n<g id=\"node14\" class=\"node\">\n<title>140275988622224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"608,-464 447,-464 447,-445 608,-445 608,-464\"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-452\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NativeBatchNormBackward0</text>\n</g>\n<!-- 140275988622224&#45;&gt;140275988619664 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140275988622224&#45;&gt;140275988619664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M527.5,-444.9688C527.5,-436.5131 527.5,-423.8901 527.5,-413.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.0001,-413.1656 527.5,-403.1656 524.0001,-413.1657 531.0001,-413.1656\"/>\n</g>\n<!-- 140275988622736 -->\n<g id=\"node15\" class=\"node\">\n<title>140275988622736</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"459,-525 364,-525 364,-506 459,-506 459,-525\"/>\n<text text-anchor=\"middle\" x=\"411.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140275988622736&#45;&gt;140275988622224 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140275988622736&#45;&gt;140275988622224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M429.625,-505.9688C448.4973,-496.0445 478.2864,-480.3795 500.0475,-468.9362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"501.8976,-471.9178 509.1195,-464.1656 498.6396,-465.7222 501.8976,-471.9178\"/>\n</g>\n<!-- 140275988622480 -->\n<g id=\"node16\" class=\"node\">\n<title>140275988622480</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"462,-592 361,-592 361,-573 462,-573 462,-592\"/>\n<text text-anchor=\"middle\" x=\"411.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140275988622480&#45;&gt;140275988622736 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140275988622480&#45;&gt;140275988622736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M411.5,-572.9005C411.5,-563.149 411.5,-547.7597 411.5,-535.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"415.0001,-535.0816 411.5,-525.0817 408.0001,-535.0817 415.0001,-535.0816\"/>\n</g>\n<!-- 140275988620048 -->\n<g id=\"node17\" class=\"node\">\n<title>140275988620048</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"347,-653 246,-653 246,-634 347,-634 347,-653\"/>\n<text text-anchor=\"middle\" x=\"296.5\" y=\"-641\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988620048&#45;&gt;140275988622480 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140275988620048&#45;&gt;140275988622480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M314.4688,-633.9688C333.1783,-624.0445 362.7107,-608.3795 384.2842,-596.9362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"386.0839,-599.9436 393.2779,-592.1656 382.8037,-593.7597 386.0839,-599.9436\"/>\n</g>\n<!-- 140276405746000 -->\n<g id=\"node18\" class=\"node\">\n<title>140276405746000</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"271.5,-720 217.5,-720 217.5,-689 271.5,-689 271.5,-720\"/>\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-696\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405746000&#45;&gt;140275988620048 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140276405746000&#45;&gt;140275988620048</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M257.8913,-688.791C265.1887,-680.2306 274.2345,-669.6191 281.7355,-660.8198\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.5226,-662.9455 288.3464,-653.0648 279.1955,-658.4044 284.5226,-662.9455\"/>\n</g>\n<!-- 140275988622608 -->\n<g id=\"node19\" class=\"node\">\n<title>140275988622608</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"456,-653 367,-653 367,-634 456,-634 456,-653\"/>\n<text text-anchor=\"middle\" x=\"411.5\" y=\"-641\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">CatBackward0</text>\n</g>\n<!-- 140275988622608&#45;&gt;140275988622480 -->\n<g id=\"edge17\" class=\"edge\">\n<title>140275988622608&#45;&gt;140275988622480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M411.5,-633.9688C411.5,-625.5131 411.5,-612.8901 411.5,-602.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"415.0001,-602.1656 411.5,-592.1656 408.0001,-602.1657 415.0001,-602.1656\"/>\n</g>\n<!-- 140275988620304 -->\n<g id=\"node20\" class=\"node\">\n<title>140275988620304</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"433,-714 290,-714 290,-695 433,-695 433,-714\"/>\n<text text-anchor=\"middle\" x=\"361.5\" y=\"-702\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">FusedDropoutBackward0</text>\n</g>\n<!-- 140275988620304&#45;&gt;140275988622608 -->\n<g id=\"edge18\" class=\"edge\">\n<title>140275988620304&#45;&gt;140275988622608</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M369.3125,-694.9688C376.754,-685.8901 388.1334,-672.0072 397.1992,-660.947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.9449,-663.1183 403.5774,-653.1656 394.5312,-658.6808 399.9449,-663.1183\"/>\n</g>\n<!-- 140275988640976 -->\n<g id=\"node21\" class=\"node\">\n<title>140275988640976</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"404,-781 309,-781 309,-762 404,-762 404,-781\"/>\n<text text-anchor=\"middle\" x=\"356.5\" y=\"-769\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140275988640976&#45;&gt;140275988620304 -->\n<g id=\"edge19\" class=\"edge\">\n<title>140275988640976&#45;&gt;140275988620304</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M357.2164,-761.9005C357.9441,-752.149 359.0926,-736.7597 360.0172,-724.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"363.531,-724.3144 360.785,-714.0817 356.5504,-723.7934 363.531,-724.3144\"/>\n</g>\n<!-- 140275988640336 -->\n<g id=\"node22\" class=\"node\">\n<title>140275988640336</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"428,-842 267,-842 267,-823 428,-823 428,-842\"/>\n<text text-anchor=\"middle\" x=\"347.5\" y=\"-830\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NativeBatchNormBackward0</text>\n</g>\n<!-- 140275988640336&#45;&gt;140275988640976 -->\n<g id=\"edge20\" class=\"edge\">\n<title>140275988640336&#45;&gt;140275988640976</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M348.9063,-822.9688C350.1538,-814.5131 352.0162,-801.8901 353.5844,-791.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"357.0767,-791.5694 355.0739,-781.1656 350.1517,-790.5476 357.0767,-791.5694\"/>\n</g>\n<!-- 140275988639952 -->\n<g id=\"node23\" class=\"node\">\n<title>140275988639952</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"190,-897 89,-897 89,-878 190,-878 190,-897\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140275988639952&#45;&gt;140275988640336 -->\n<g id=\"edge21\" class=\"edge\">\n<title>140275988639952&#45;&gt;140275988640336</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M175.7308,-877.9197C210.6693,-868.6812 263.6816,-854.6635 301.5659,-844.646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"302.563,-848.0027 311.336,-842.0626 300.7735,-841.2353 302.563,-848.0027\"/>\n</g>\n<!-- 140275988640848 -->\n<g id=\"node24\" class=\"node\">\n<title>140275988640848</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-958 0,-958 0,-939 101,-939 101,-958\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-946\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988640848&#45;&gt;140275988639952 -->\n<g id=\"edge22\" class=\"edge\">\n<title>140275988640848&#45;&gt;140275988639952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M64.4063,-938.9688C78.4313,-929.3561 100.3147,-914.3573 116.8473,-903.026\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"119.1279,-905.7061 125.3977,-897.1656 115.1704,-899.9322 119.1279,-905.7061\"/>\n</g>\n<!-- 140276405912784 -->\n<g id=\"node25\" class=\"node\">\n<title>140276405912784</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-1031 23.5,-1031 23.5,-1000 77.5,-1000 77.5,-1031\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-1007\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405912784&#45;&gt;140275988640848 -->\n<g id=\"edge23\" class=\"edge\">\n<title>140276405912784&#45;&gt;140275988640848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-999.9604C50.5,-990.6356 50.5,-978.6748 50.5,-968.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-968.35 50.5,-958.3501 47.0001,-968.3501 54.0001,-968.35\"/>\n</g>\n<!-- 140276444959824 -->\n<g id=\"node26\" class=\"node\">\n<title>140276444959824</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"196,-958 119,-958 119,-939 196,-939 196,-958\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-946\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140276444959824&#45;&gt;140275988639952 -->\n<g id=\"edge24\" class=\"edge\">\n<title>140276444959824&#45;&gt;140275988639952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M154.6875,-938.9688C152.1661,-930.4241 148.389,-917.6239 145.2324,-906.9265\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"148.5393,-905.7662 142.3522,-897.1656 141.8255,-907.7474 148.5393,-905.7662\"/>\n</g>\n<!-- 140276444960144 -->\n<g id=\"node27\" class=\"node\">\n<title>140276444960144</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"208,-1025 107,-1025 107,-1006 208,-1006 208,-1025\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-1013\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276444960144&#45;&gt;140276444959824 -->\n<g id=\"edge25\" class=\"edge\">\n<title>140276444960144&#45;&gt;140276444959824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5,-1005.9005C157.5,-996.149 157.5,-980.7597 157.5,-968.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.0001,-968.0816 157.5,-958.0817 154.0001,-968.0817 161.0001,-968.0816\"/>\n</g>\n<!-- 140276405915472 -->\n<g id=\"node28\" class=\"node\">\n<title>140276405915472</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"199,-1098 116,-1098 116,-1067 199,-1067 199,-1098\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-1074\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512, 768)</text>\n</g>\n<!-- 140276405915472&#45;&gt;140276444960144 -->\n<g id=\"edge26\" class=\"edge\">\n<title>140276405915472&#45;&gt;140276444960144</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5,-1066.9604C157.5,-1057.6356 157.5,-1045.6748 157.5,-1035.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.0001,-1035.35 157.5,-1025.3501 154.0001,-1035.3501 161.0001,-1035.35\"/>\n</g>\n<!-- 140275988639824 -->\n<g id=\"node29\" class=\"node\">\n<title>140275988639824</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"309,-897 208,-897 208,-878 309,-878 309,-897\"/>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988639824&#45;&gt;140275988640336 -->\n<g id=\"edge27\" class=\"edge\">\n<title>140275988639824&#45;&gt;140275988640336</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M274.0026,-877.9197C287.5747,-869.5325 307.5207,-857.2063 323.2106,-847.5103\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.2096,-850.3894 331.8764,-842.155 321.5297,-844.4347 325.2096,-850.3894\"/>\n</g>\n<!-- 140276405911920 -->\n<g id=\"node30\" class=\"node\">\n<title>140276405911920</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"285.5,-964 231.5,-964 231.5,-933 285.5,-933 285.5,-964\"/>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-940\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405911920&#45;&gt;140275988639824 -->\n<g id=\"edge28\" class=\"edge\">\n<title>140276405911920&#45;&gt;140275988639824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M258.5,-932.791C258.5,-925.0249 258.5,-915.5706 258.5,-907.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.0001,-907.0647 258.5,-897.0648 255.0001,-907.0648 262.0001,-907.0647\"/>\n</g>\n<!-- 140275988640464 -->\n<g id=\"node31\" class=\"node\">\n<title>140275988640464</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"428,-897 327,-897 327,-878 428,-878 428,-897\"/>\n<text text-anchor=\"middle\" x=\"377.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988640464&#45;&gt;140275988640336 -->\n<g id=\"edge29\" class=\"edge\">\n<title>140275988640464&#45;&gt;140275988640336</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M372.2744,-877.9197C368.28,-870.5967 362.6478,-860.2709 357.7626,-851.3147\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"360.7289,-849.4438 352.8677,-842.3408 354.5837,-852.7958 360.7289,-849.4438\"/>\n</g>\n<!-- 140276405915280 -->\n<g id=\"node32\" class=\"node\">\n<title>140276405915280</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"392.5,-964 338.5,-964 338.5,-933 392.5,-933 392.5,-964\"/>\n<text text-anchor=\"middle\" x=\"365.5\" y=\"-940\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405915280&#45;&gt;140275988640464 -->\n<g id=\"edge30\" class=\"edge\">\n<title>140276405915280&#45;&gt;140275988640464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M368.5903,-932.791C370.1354,-924.9366 372.0202,-915.3555 373.6577,-907.0318\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"377.1223,-907.5523 375.6184,-897.0648 370.2539,-906.2011 377.1223,-907.5523\"/>\n</g>\n<!-- 140275988622864 -->\n<g id=\"node33\" class=\"node\">\n<title>140275988622864</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"594,-714 451,-714 451,-695 594,-695 594,-714\"/>\n<text text-anchor=\"middle\" x=\"522.5\" y=\"-702\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">FusedDropoutBackward0</text>\n</g>\n<!-- 140275988622864&#45;&gt;140275988622608 -->\n<g id=\"edge31\" class=\"edge\">\n<title>140275988622864&#45;&gt;140275988622608</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M505.1563,-694.9688C487.1784,-685.089 458.8477,-669.5199 438.0498,-658.0904\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.5378,-654.9145 429.0883,-653.1656 436.1664,-661.0492 439.5378,-654.9145\"/>\n</g>\n<!-- 140275988640208 -->\n<g id=\"node34\" class=\"node\">\n<title>140275988640208</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"576,-781 481,-781 481,-762 576,-762 576,-781\"/>\n<text text-anchor=\"middle\" x=\"528.5\" y=\"-769\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140275988640208&#45;&gt;140275988622864 -->\n<g id=\"edge32\" class=\"edge\">\n<title>140275988640208&#45;&gt;140275988622864</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M527.6403,-761.9005C526.7671,-752.149 525.3889,-736.7597 524.2794,-724.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"527.7361,-723.7296 523.3581,-714.0817 520.7641,-724.354 527.7361,-723.7296\"/>\n</g>\n<!-- 140275988640592 -->\n<g id=\"node35\" class=\"node\">\n<title>140275988640592</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"619,-842 458,-842 458,-823 619,-823 619,-842\"/>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-830\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NativeBatchNormBackward0</text>\n</g>\n<!-- 140275988640592&#45;&gt;140275988640208 -->\n<g id=\"edge33\" class=\"edge\">\n<title>140275988640592&#45;&gt;140275988640208</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M536.9375,-822.9688C535.5513,-814.5131 533.482,-801.8901 531.7396,-791.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"535.1563,-790.4677 530.0845,-781.1656 528.2485,-791.6002 535.1563,-790.4677\"/>\n</g>\n<!-- 140276444958800 -->\n<g id=\"node36\" class=\"node\">\n<title>140276444958800</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"559,-897 458,-897 458,-878 559,-878 559,-897\"/>\n<text text-anchor=\"middle\" x=\"508.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140276444958800&#45;&gt;140275988640592 -->\n<g id=\"edge34\" class=\"edge\">\n<title>140276444958800&#45;&gt;140275988640592</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M513.7256,-877.9197C517.72,-870.5967 523.3522,-860.2709 528.2374,-851.3147\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.4163,-852.7958 533.1323,-842.3408 525.2711,-849.4438 531.4163,-852.7958\"/>\n</g>\n<!-- 140275812729040 -->\n<g id=\"node37\" class=\"node\">\n<title>140275812729040</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"512,-958 411,-958 411,-939 512,-939 512,-958\"/>\n<text text-anchor=\"middle\" x=\"461.5\" y=\"-946\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275812729040&#45;&gt;140276444958800 -->\n<g id=\"edge35\" class=\"edge\">\n<title>140275812729040&#45;&gt;140276444958800</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M468.8438,-938.9688C475.7702,-929.9791 486.326,-916.279 494.806,-905.2731\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"497.7218,-907.2233 501.0527,-897.1656 492.1768,-902.9509 497.7218,-907.2233\"/>\n</g>\n<!-- 140276405745040 -->\n<g id=\"node38\" class=\"node\">\n<title>140276405745040</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"488.5,-1031 434.5,-1031 434.5,-1000 488.5,-1000 488.5,-1031\"/>\n<text text-anchor=\"middle\" x=\"461.5\" y=\"-1007\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 140276405745040&#45;&gt;140275812729040 -->\n<g id=\"edge36\" class=\"edge\">\n<title>140276405745040&#45;&gt;140275812729040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M461.5,-999.9604C461.5,-990.6356 461.5,-978.6748 461.5,-968.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"465.0001,-968.35 461.5,-958.3501 458.0001,-968.3501 465.0001,-968.35\"/>\n</g>\n<!-- 140275812730768 -->\n<g id=\"node39\" class=\"node\">\n<title>140275812730768</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"607,-958 530,-958 530,-939 607,-939 607,-958\"/>\n<text text-anchor=\"middle\" x=\"568.5\" y=\"-946\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140275812730768&#45;&gt;140276444958800 -->\n<g id=\"edge37\" class=\"edge\">\n<title>140275812730768&#45;&gt;140276444958800</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M559.125,-938.9688C550.0201,-929.7121 536.0026,-915.461 525.0243,-904.2997\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"527.5149,-901.8406 518.0072,-897.1656 522.5243,-906.7493 527.5149,-901.8406\"/>\n</g>\n<!-- 140276405702416 -->\n<g id=\"node40\" class=\"node\">\n<title>140276405702416</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"619,-1025 518,-1025 518,-1006 619,-1006 619,-1025\"/>\n<text text-anchor=\"middle\" x=\"568.5\" y=\"-1013\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276405702416&#45;&gt;140275812730768 -->\n<g id=\"edge38\" class=\"edge\">\n<title>140276405702416&#45;&gt;140275812730768</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M568.5,-1005.9005C568.5,-996.149 568.5,-980.7597 568.5,-968.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"572.0001,-968.0816 568.5,-958.0817 565.0001,-968.0817 572.0001,-968.0816\"/>\n</g>\n<!-- 140276405745808 -->\n<g id=\"node41\" class=\"node\">\n<title>140276405745808</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"610,-1098 527,-1098 527,-1067 610,-1067 610,-1098\"/>\n<text text-anchor=\"middle\" x=\"568.5\" y=\"-1074\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256, 384)</text>\n</g>\n<!-- 140276405745808&#45;&gt;140276405702416 -->\n<g id=\"edge39\" class=\"edge\">\n<title>140276405745808&#45;&gt;140276405702416</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M568.5,-1066.9604C568.5,-1057.6356 568.5,-1045.6748 568.5,-1035.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"572.0001,-1035.35 568.5,-1025.3501 565.0001,-1035.3501 572.0001,-1035.35\"/>\n</g>\n<!-- 140276405552080 -->\n<g id=\"node42\" class=\"node\">\n<title>140276405552080</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"678,-897 577,-897 577,-878 678,-878 678,-897\"/>\n<text text-anchor=\"middle\" x=\"627.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276405552080&#45;&gt;140275988640592 -->\n<g id=\"edge40\" class=\"edge\">\n<title>140276405552080&#45;&gt;140275988640592</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M611.9974,-877.9197C598.4253,-869.5325 578.4793,-857.2063 562.7894,-847.5103\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.4703,-844.4347 554.1236,-842.155 560.7904,-850.3894 564.4703,-844.4347\"/>\n</g>\n<!-- 140276405745712 -->\n<g id=\"node43\" class=\"node\">\n<title>140276405745712</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"679.5,-964 625.5,-964 625.5,-933 679.5,-933 679.5,-964\"/>\n<text text-anchor=\"middle\" x=\"652.5\" y=\"-940\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 140276405745712&#45;&gt;140276405552080 -->\n<g id=\"edge41\" class=\"edge\">\n<title>140276405745712&#45;&gt;140276405552080</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M646.0619,-932.791C642.7705,-924.7601 638.7394,-914.9241 635.2757,-906.4726\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"638.4509,-904.9905 631.42,-897.0648 631.9737,-907.6451 638.4509,-904.9905\"/>\n</g>\n<!-- 140276405552464 -->\n<g id=\"node44\" class=\"node\">\n<title>140276405552464</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"797,-897 696,-897 696,-878 797,-878 797,-897\"/>\n<text text-anchor=\"middle\" x=\"746.5\" y=\"-885\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276405552464&#45;&gt;140275988640592 -->\n<g id=\"edge42\" class=\"edge\">\n<title>140276405552464&#45;&gt;140275988640592</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M710.2692,-877.9197C675.3307,-868.6812 622.3184,-854.6635 584.4341,-844.646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"585.2265,-841.2353 574.664,-842.0626 583.437,-848.0027 585.2265,-841.2353\"/>\n</g>\n<!-- 140276405745616 -->\n<g id=\"node45\" class=\"node\">\n<title>140276405745616</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"773.5,-964 719.5,-964 719.5,-933 773.5,-933 773.5,-964\"/>\n<text text-anchor=\"middle\" x=\"746.5\" y=\"-940\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 140276405745616&#45;&gt;140276405552464 -->\n<g id=\"edge43\" class=\"edge\">\n<title>140276405745616&#45;&gt;140276405552464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M746.5,-932.791C746.5,-925.0249 746.5,-915.5706 746.5,-907.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"750.0001,-907.0647 746.5,-897.0648 743.0001,-907.0648 750.0001,-907.0647\"/>\n</g>\n<!-- 140275988623248 -->\n<g id=\"node46\" class=\"node\">\n<title>140275988623248</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"651,-653 574,-653 574,-634 651,-634 651,-653\"/>\n<text text-anchor=\"middle\" x=\"612.5\" y=\"-641\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140275988623248&#45;&gt;140275988622480 -->\n<g id=\"edge44\" class=\"edge\">\n<title>140275988623248&#45;&gt;140275988622480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M581.0938,-633.9688C546.5316,-623.4797 490.8388,-606.5779 452.772,-595.0253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"453.6022,-591.6197 443.0167,-592.0648 451.5693,-598.3181 453.6022,-591.6197\"/>\n</g>\n<!-- 140275812731024 -->\n<g id=\"node47\" class=\"node\">\n<title>140275812731024</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"713,-714 612,-714 612,-695 713,-695 713,-714\"/>\n<text text-anchor=\"middle\" x=\"662.5\" y=\"-702\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275812731024&#45;&gt;140275988623248 -->\n<g id=\"edge45\" class=\"edge\">\n<title>140275812731024&#45;&gt;140275988623248</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M654.6875,-694.9688C647.246,-685.8901 635.8666,-672.0072 626.8008,-660.947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"629.4688,-658.6808 620.4226,-653.1656 624.0551,-663.1183 629.4688,-658.6808\"/>\n</g>\n<!-- 140276405746096 -->\n<g id=\"node48\" class=\"node\">\n<title>140276405746096</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"704,-787 621,-787 621,-756 704,-756 704,-787\"/>\n<text text-anchor=\"middle\" x=\"662.5\" y=\"-763\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512, 768)</text>\n</g>\n<!-- 140276405746096&#45;&gt;140275812731024 -->\n<g id=\"edge46\" class=\"edge\">\n<title>140276405746096&#45;&gt;140275812731024</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M662.5,-755.9604C662.5,-746.6356 662.5,-734.6748 662.5,-724.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"666.0001,-724.35 662.5,-714.3501 659.0001,-724.3501 666.0001,-724.35\"/>\n</g>\n<!-- 140275988621968 -->\n<g id=\"node49\" class=\"node\">\n<title>140275988621968</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"578,-525 477,-525 477,-506 578,-506 578,-525\"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988621968&#45;&gt;140275988622224 -->\n<g id=\"edge47\" class=\"edge\">\n<title>140275988621968&#45;&gt;140275988622224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M527.5,-505.9688C527.5,-497.5131 527.5,-484.8901 527.5,-474.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.0001,-474.1656 527.5,-464.1656 524.0001,-474.1657 531.0001,-474.1656\"/>\n</g>\n<!-- 140276405746192 -->\n<g id=\"node50\" class=\"node\">\n<title>140276405746192</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"554.5,-598 500.5,-598 500.5,-567 554.5,-567 554.5,-598\"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-574\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405746192&#45;&gt;140275988621968 -->\n<g id=\"edge48\" class=\"edge\">\n<title>140276405746192&#45;&gt;140275988621968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M527.5,-566.9604C527.5,-557.6356 527.5,-545.6748 527.5,-535.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.0001,-535.35 527.5,-525.3501 524.0001,-535.3501 531.0001,-535.35\"/>\n</g>\n<!-- 140275988621840 -->\n<g id=\"node51\" class=\"node\">\n<title>140275988621840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"697,-525 596,-525 596,-506 697,-506 697,-525\"/>\n<text text-anchor=\"middle\" x=\"646.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988621840&#45;&gt;140275988622224 -->\n<g id=\"edge49\" class=\"edge\">\n<title>140275988621840&#45;&gt;140275988622224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M627.9063,-505.9688C608.4591,-496 577.712,-480.2389 555.3626,-468.7825\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"556.8515,-465.6127 546.3559,-464.1656 553.6583,-471.842 556.8515,-465.6127\"/>\n</g>\n<!-- 140276405746288 -->\n<g id=\"node52\" class=\"node\">\n<title>140276405746288</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"673.5,-598 619.5,-598 619.5,-567 673.5,-567 673.5,-598\"/>\n<text text-anchor=\"middle\" x=\"646.5\" y=\"-574\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140276405746288&#45;&gt;140275988621840 -->\n<g id=\"edge50\" class=\"edge\">\n<title>140276405746288&#45;&gt;140275988621840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M646.5,-566.9604C646.5,-557.6356 646.5,-545.6748 646.5,-535.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"650.0001,-535.35 646.5,-525.3501 643.0001,-535.3501 650.0001,-535.35\"/>\n</g>\n<!-- 140275988621456 -->\n<g id=\"node53\" class=\"node\">\n<title>140275988621456</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"753,-464 676,-464 676,-445 753,-445 753,-464\"/>\n<text text-anchor=\"middle\" x=\"714.5\" y=\"-452\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140275988621456&#45;&gt;140275988619664 -->\n<g id=\"edge51\" class=\"edge\">\n<title>140275988621456&#45;&gt;140275988619664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M685.2813,-444.9688C653.2632,-434.5244 601.7533,-417.7217 566.3503,-406.1731\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"567.414,-402.8386 556.8215,-403.0648 565.2431,-409.4935 567.414,-402.8386\"/>\n</g>\n<!-- 140276405551888 -->\n<g id=\"node54\" class=\"node\">\n<title>140276405551888</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"816,-525 715,-525 715,-506 816,-506 816,-525\"/>\n<text text-anchor=\"middle\" x=\"765.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276405551888&#45;&gt;140275988621456 -->\n<g id=\"edge52\" class=\"edge\">\n<title>140276405551888&#45;&gt;140275988621456</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M757.5313,-505.9688C749.9409,-496.8901 738.3339,-483.0072 729.0868,-471.947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"731.6805,-469.5926 722.5811,-464.1656 726.3102,-474.0825 731.6805,-469.5926\"/>\n</g>\n<!-- 140276405746768 -->\n<g id=\"node55\" class=\"node\">\n<title>140276405746768</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"804,-598 727,-598 727,-567 804,-567 804,-598\"/>\n<text text-anchor=\"middle\" x=\"765.5\" y=\"-574\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64, 512)</text>\n</g>\n<!-- 140276405746768&#45;&gt;140276405551888 -->\n<g id=\"edge53\" class=\"edge\">\n<title>140276405746768&#45;&gt;140276405551888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M765.5,-566.9604C765.5,-557.6356 765.5,-545.6748 765.5,-535.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"769.0001,-535.35 765.5,-525.3501 762.0001,-535.3501 769.0001,-535.35\"/>\n</g>\n<!-- 140275988619408 -->\n<g id=\"node56\" class=\"node\">\n<title>140275988619408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"694,-336 593,-336 593,-317 694,-317 694,-336\"/>\n<text text-anchor=\"middle\" x=\"643.5\" y=\"-324\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988619408&#45;&gt;140275988621072 -->\n<g id=\"edge54\" class=\"edge\">\n<title>140275988619408&#45;&gt;140275988621072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M643.5,-316.9005C643.5,-307.149 643.5,-291.7597 643.5,-279.3695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"647.0001,-279.0816 643.5,-269.0817 640.0001,-279.0817 647.0001,-279.0816\"/>\n</g>\n<!-- 140276405746864 -->\n<g id=\"node57\" class=\"node\">\n<title>140276405746864</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"670.5,-409 616.5,-409 616.5,-378 670.5,-378 670.5,-409\"/>\n<text text-anchor=\"middle\" x=\"643.5\" y=\"-385\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140276405746864&#45;&gt;140275988619408 -->\n<g id=\"edge55\" class=\"edge\">\n<title>140276405746864&#45;&gt;140275988619408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M643.5,-377.9604C643.5,-368.6356 643.5,-356.6748 643.5,-346.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"647.0001,-346.35 643.5,-336.3501 640.0001,-346.3501 647.0001,-346.35\"/>\n</g>\n<!-- 140275988620688 -->\n<g id=\"node58\" class=\"node\">\n<title>140275988620688</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"813,-336 712,-336 712,-317 813,-317 813,-336\"/>\n<text text-anchor=\"middle\" x=\"762.5\" y=\"-324\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988620688&#45;&gt;140275988621072 -->\n<g id=\"edge56\" class=\"edge\">\n<title>140275988620688&#45;&gt;140275988621072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M745.4502,-316.9005C725.5677,-305.7062 692.4895,-287.0823 669.422,-274.0947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"670.9491,-270.938 660.5182,-269.0817 667.5148,-277.0376 670.9491,-270.938\"/>\n</g>\n<!-- 140276405746960 -->\n<g id=\"node59\" class=\"node\">\n<title>140276405746960</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"789.5,-409 735.5,-409 735.5,-378 789.5,-378 789.5,-409\"/>\n<text text-anchor=\"middle\" x=\"762.5\" y=\"-385\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140276405746960&#45;&gt;140275988620688 -->\n<g id=\"edge57\" class=\"edge\">\n<title>140276405746960&#45;&gt;140275988620688</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M762.5,-377.9604C762.5,-368.6356 762.5,-356.6748 762.5,-346.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"766.0001,-346.35 762.5,-336.3501 759.0001,-346.3501 766.0001,-346.35\"/>\n</g>\n<!-- 140275988621200 -->\n<g id=\"node60\" class=\"node\">\n<title>140275988621200</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"819,-269 742,-269 742,-250 819,-250 819,-269\"/>\n<text text-anchor=\"middle\" x=\"780.5\" y=\"-257\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140275988621200&#45;&gt;140275988620560 -->\n<g id=\"edge58\" class=\"edge\">\n<title>140275988621200&#45;&gt;140275988620560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M768.3216,-249.9005C754.5616,-239.0544 731.9535,-221.2339 715.5738,-208.3229\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"717.6761,-205.5234 707.6558,-202.0817 713.3427,-211.0209 717.6761,-205.5234\"/>\n</g>\n<!-- 140276444961424 -->\n<g id=\"node61\" class=\"node\">\n<title>140276444961424</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"932,-336 831,-336 831,-317 932,-317 932,-336\"/>\n<text text-anchor=\"middle\" x=\"881.5\" y=\"-324\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140276444961424&#45;&gt;140275988621200 -->\n<g id=\"edge59\" class=\"edge\">\n<title>140276444961424&#45;&gt;140275988621200</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M867.0292,-316.9005C850.3791,-305.8554 822.826,-287.5776 803.2886,-274.6172\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"805.212,-271.693 794.944,-269.0817 801.3424,-277.5263 805.212,-271.693\"/>\n</g>\n<!-- 140276405747440 -->\n<g id=\"node62\" class=\"node\">\n<title>140276405747440</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"917,-409 846,-409 846,-378 917,-378 917,-409\"/>\n<text text-anchor=\"middle\" x=\"881.5\" y=\"-385\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (32, 64)</text>\n</g>\n<!-- 140276405747440&#45;&gt;140276444961424 -->\n<g id=\"edge60\" class=\"edge\">\n<title>140276405747440&#45;&gt;140276444961424</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M881.5,-377.9604C881.5,-368.6356 881.5,-356.6748 881.5,-346.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"885.0001,-346.35 881.5,-336.3501 878.0001,-346.3501 885.0001,-346.35\"/>\n</g>\n<!-- 140275988620432 -->\n<g id=\"node63\" class=\"node\">\n<title>140275988620432</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"851,-141 774,-141 774,-122 851,-122 851,-141\"/>\n<text text-anchor=\"middle\" x=\"812.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140275988620432&#45;&gt;140276405917776 -->\n<g id=\"edge61\" class=\"edge\">\n<title>140275988620432&#45;&gt;140276405917776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M792.9911,-121.9197C775.353,-113.2581 749.1603,-100.3957 729.1465,-90.5675\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"730.68,-87.4213 720.1611,-86.155 727.5945,-93.7046 730.68,-87.4213\"/>\n</g>\n<!-- 140275988640080 -->\n<g id=\"node64\" class=\"node\">\n<title>140275988640080</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"867,-202 766,-202 766,-183 867,-183 867,-202\"/>\n<text text-anchor=\"middle\" x=\"816.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140275988640080&#45;&gt;140275988620432 -->\n<g id=\"edge62\" class=\"edge\">\n<title>140275988640080&#45;&gt;140275988620432</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M815.875,-182.9688C815.3205,-174.5131 814.4928,-161.8901 813.7958,-151.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"817.2807,-150.9152 813.1338,-141.1656 810.2957,-151.3732 817.2807,-150.9152\"/>\n</g>\n<!-- 140276405747536 -->\n<g id=\"node65\" class=\"node\">\n<title>140276405747536</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"902,-275 837,-275 837,-244 902,-244 902,-275\"/>\n<text text-anchor=\"middle\" x=\"869.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1, 32)</text>\n</g>\n<!-- 140276405747536&#45;&gt;140275988640080 -->\n<g id=\"edge63\" class=\"edge\">\n<title>140276405747536&#45;&gt;140275988640080</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M857.2075,-243.9604C849.2759,-233.9337 838.9335,-220.8594 830.6584,-210.3984\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"833.2409,-208.0215 824.2919,-202.3501 827.7509,-212.3644 833.2409,-208.0215\"/>\n</g>\n</g>\n</svg>\n"},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train.label.sum()\n","train.shape\n","test.shape\n","test.label.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jxCrxaZGzO9","executionInfo":{"status":"ok","timestamp":1647457317616,"user_tz":420,"elapsed":276,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"2a545192-fc16-4ac7-9064-8ebed0219518"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["487"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["with torch.set_grad_enabled(False):\n","    auc, auprc, f1, logits, loss = test(training_generator, model_max, use_cuda)\n","    print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Test loss: '+str(loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hzfo3-lzsdlB","executionInfo":{"status":"ok","timestamp":1647413364714,"user_tz":420,"elapsed":2406,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}},"outputId":"d352afe5-b4e9-4fd2-d72c-9e103d22f125"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["optimal threshold: 0.5\n","AUROC:0.6595319721727312\n","AUPRC: 0.663322982355117\n","Confusion Matrix : \n"," [[320 131]\n"," [231 278]]\n","Recall :  0.5461689587426326\n","Precision :  0.6797066014669927\n","Accuracy :  0.6229166666666667\n","Sensitivity :  0.7095343680709535\n","Specificity :  0.5461689587426326\n","Testing AUROC: 0.6595319721727312 , AUPRC: 0.663322982355117 , F1: 0.6056644880174293 , Test loss: 1.774868130683899\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"code","source":["#@title train model\n","print('--- Go for Training ---')\n","torch.backends.cudnn.benchmark = True\n","for epo in range(1000):\n","    model.train()\n","    for i, (d, p, label) in enumerate(training_generator):\n","        \n","        label = Variable(torch.from_numpy(np.array(label)).float())\n","        if use_cuda:\n","            d = d.cuda()\n","            p = p.cuda()\n","            label = label.cuda()\n","\n","        \n","        score = model(d, p)\n","        loss_fct = torch.nn.BCELoss()\n","        m = torch.nn.Sigmoid()\n","        n = torch.squeeze(m(score))\n","        # print(d.isnan().any())\n","        # print(p.isnan().any())\n","        # print(p)\n","        \n","        loss = loss_fct(n, label)\n","        loss_history.append(loss)\n","        \n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","  \n","        print('Training at Epoch ' + str(epo + 1) + ' iteration ' + str(i) + ' with loss ' + str(loss.cpu().detach().numpy()))\n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Re1jWEUcQw7I","outputId":"115c68b5-bccb-4759-9db5-fceb614808e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Go for Training ---\n","Training at Epoch 1 iteration 0 with loss 0.7160621\n","Training at Epoch 2 iteration 0 with loss 0.70942146\n","Training at Epoch 3 iteration 0 with loss 0.69520783\n","Training at Epoch 4 iteration 0 with loss 0.7019872\n","Training at Epoch 5 iteration 0 with loss 0.6908716\n","Training at Epoch 6 iteration 0 with loss 0.67784256\n","Training at Epoch 7 iteration 0 with loss 0.7078518\n","Training at Epoch 8 iteration 0 with loss 0.7020625\n","Training at Epoch 9 iteration 0 with loss 0.6767439\n","Training at Epoch 10 iteration 0 with loss 0.6813489\n","Training at Epoch 11 iteration 0 with loss 0.69095546\n","Training at Epoch 12 iteration 0 with loss 0.6821579\n","Training at Epoch 13 iteration 0 with loss 0.68481475\n","Training at Epoch 14 iteration 0 with loss 0.6866348\n","Training at Epoch 15 iteration 0 with loss 0.6909596\n","Training at Epoch 16 iteration 0 with loss 0.6863352\n","Training at Epoch 17 iteration 0 with loss 0.6871693\n","Training at Epoch 18 iteration 0 with loss 0.68436444\n","Training at Epoch 19 iteration 0 with loss 0.68891287\n","Training at Epoch 20 iteration 0 with loss 0.6909111\n","Training at Epoch 21 iteration 0 with loss 0.69289315\n","Training at Epoch 22 iteration 0 with loss 0.68591195\n","Training at Epoch 23 iteration 0 with loss 0.67941236\n","Training at Epoch 24 iteration 0 with loss 0.678633\n","Training at Epoch 25 iteration 0 with loss 0.67681056\n","Training at Epoch 26 iteration 0 with loss 0.69034946\n","Training at Epoch 27 iteration 0 with loss 0.6946785\n","Training at Epoch 28 iteration 0 with loss 0.6771091\n","Training at Epoch 29 iteration 0 with loss 0.6826868\n","Training at Epoch 30 iteration 0 with loss 0.67313313\n","Training at Epoch 31 iteration 0 with loss 0.6683063\n","Training at Epoch 32 iteration 0 with loss 0.6722816\n","Training at Epoch 33 iteration 0 with loss 0.6650195\n","Training at Epoch 34 iteration 0 with loss 0.6819525\n","Training at Epoch 35 iteration 0 with loss 0.677376\n","Training at Epoch 36 iteration 0 with loss 0.67271423\n","Training at Epoch 37 iteration 0 with loss 0.6798696\n","Training at Epoch 38 iteration 0 with loss 0.67351794\n","Training at Epoch 39 iteration 0 with loss 0.67512894\n","Training at Epoch 40 iteration 0 with loss 0.6696204\n","Training at Epoch 41 iteration 0 with loss 0.6711766\n","Training at Epoch 42 iteration 0 with loss 0.65951216\n","Training at Epoch 43 iteration 0 with loss 0.65881056\n","Training at Epoch 44 iteration 0 with loss 0.6596679\n","Training at Epoch 45 iteration 0 with loss 0.64217925\n","Training at Epoch 46 iteration 0 with loss 0.6732874\n","Training at Epoch 47 iteration 0 with loss 0.646756\n","Training at Epoch 48 iteration 0 with loss 0.6531521\n","Training at Epoch 49 iteration 0 with loss 0.66975075\n","Training at Epoch 50 iteration 0 with loss 0.62902534\n","Training at Epoch 51 iteration 0 with loss 0.61105096\n","Training at Epoch 52 iteration 0 with loss 0.64943796\n","Training at Epoch 53 iteration 0 with loss 0.6660782\n","Training at Epoch 54 iteration 0 with loss 0.6428533\n","Training at Epoch 55 iteration 0 with loss 0.64679694\n","Training at Epoch 56 iteration 0 with loss 0.6271558\n","Training at Epoch 57 iteration 0 with loss 0.66095436\n","Training at Epoch 58 iteration 0 with loss 0.60518646\n","Training at Epoch 59 iteration 0 with loss 0.63403136\n","Training at Epoch 60 iteration 0 with loss 0.6150863\n","Training at Epoch 61 iteration 0 with loss 0.62561876\n","Training at Epoch 62 iteration 0 with loss 0.60102636\n","Training at Epoch 63 iteration 0 with loss 0.6046827\n","Training at Epoch 64 iteration 0 with loss 0.5759256\n","Training at Epoch 65 iteration 0 with loss 0.57656777\n","Training at Epoch 66 iteration 0 with loss 0.6042778\n","Training at Epoch 67 iteration 0 with loss 0.5536196\n","Training at Epoch 68 iteration 0 with loss 0.60575694\n","Training at Epoch 69 iteration 0 with loss 0.61443084\n","Training at Epoch 70 iteration 0 with loss 0.6068292\n","Training at Epoch 71 iteration 0 with loss 0.5274236\n","Training at Epoch 72 iteration 0 with loss 0.5804568\n","Training at Epoch 73 iteration 0 with loss 0.5406148\n","Training at Epoch 74 iteration 0 with loss 0.56362087\n","Training at Epoch 75 iteration 0 with loss 0.5444626\n","Training at Epoch 76 iteration 0 with loss 0.55275834\n","Training at Epoch 77 iteration 0 with loss 0.5387343\n","Training at Epoch 78 iteration 0 with loss 0.65308344\n","Training at Epoch 79 iteration 0 with loss 0.5393377\n","Training at Epoch 80 iteration 0 with loss 0.48593608\n","Training at Epoch 81 iteration 0 with loss 0.5397787\n","Training at Epoch 82 iteration 0 with loss 0.55444014\n","Training at Epoch 83 iteration 0 with loss 0.52727056\n","Training at Epoch 84 iteration 0 with loss 0.509022\n","Training at Epoch 85 iteration 0 with loss 0.54533714\n","Training at Epoch 86 iteration 0 with loss 0.48689765\n","Training at Epoch 87 iteration 0 with loss 0.53954107\n","Training at Epoch 88 iteration 0 with loss 0.5069796\n","Training at Epoch 89 iteration 0 with loss 0.4648085\n","Training at Epoch 90 iteration 0 with loss 0.50009346\n","Training at Epoch 91 iteration 0 with loss 0.48707062\n","Training at Epoch 92 iteration 0 with loss 0.49365708\n","Training at Epoch 93 iteration 0 with loss 0.5068542\n","Training at Epoch 94 iteration 0 with loss 0.50839734\n","Training at Epoch 95 iteration 0 with loss 0.5343446\n","Training at Epoch 96 iteration 0 with loss 0.5569762\n","Training at Epoch 97 iteration 0 with loss 0.51308465\n","Training at Epoch 98 iteration 0 with loss 0.5085466\n","Training at Epoch 99 iteration 0 with loss 0.5383986\n","Training at Epoch 100 iteration 0 with loss 0.5096625\n","Training at Epoch 101 iteration 0 with loss 0.5163098\n","Training at Epoch 102 iteration 0 with loss 0.4817857\n","Training at Epoch 103 iteration 0 with loss 0.49306557\n","Training at Epoch 104 iteration 0 with loss 0.5068928\n","Training at Epoch 105 iteration 0 with loss 0.5014507\n","Training at Epoch 106 iteration 0 with loss 0.5083278\n","Training at Epoch 107 iteration 0 with loss 0.5275306\n","Training at Epoch 108 iteration 0 with loss 0.48310384\n","Training at Epoch 109 iteration 0 with loss 0.47487825\n","Training at Epoch 110 iteration 0 with loss 0.45009288\n","Training at Epoch 111 iteration 0 with loss 0.4818487\n","Training at Epoch 112 iteration 0 with loss 0.4450537\n","Training at Epoch 113 iteration 0 with loss 0.55405873\n","Training at Epoch 114 iteration 0 with loss 0.47674227\n","Training at Epoch 115 iteration 0 with loss 0.45586053\n","Training at Epoch 116 iteration 0 with loss 0.4624792\n","Training at Epoch 117 iteration 0 with loss 0.4575181\n","Training at Epoch 118 iteration 0 with loss 0.41894853\n","Training at Epoch 119 iteration 0 with loss 0.4091366\n","Training at Epoch 120 iteration 0 with loss 0.4701692\n","Training at Epoch 121 iteration 0 with loss 0.44009763\n","Training at Epoch 122 iteration 0 with loss 0.49996755\n","Training at Epoch 123 iteration 0 with loss 0.4225812\n","Training at Epoch 124 iteration 0 with loss 0.4241375\n","Training at Epoch 125 iteration 0 with loss 0.3929236\n","Training at Epoch 126 iteration 0 with loss 0.4539074\n","Training at Epoch 127 iteration 0 with loss 0.4655481\n","Training at Epoch 128 iteration 0 with loss 0.3996568\n","Training at Epoch 129 iteration 0 with loss 0.40193826\n","Training at Epoch 130 iteration 0 with loss 0.41012245\n","Training at Epoch 131 iteration 0 with loss 0.4001732\n","Training at Epoch 132 iteration 0 with loss 0.41271\n","Training at Epoch 133 iteration 0 with loss 0.4787607\n","Training at Epoch 134 iteration 0 with loss 0.42366576\n","Training at Epoch 135 iteration 0 with loss 0.41411322\n","Training at Epoch 136 iteration 0 with loss 0.41695794\n","Training at Epoch 137 iteration 0 with loss 0.34898478\n","Training at Epoch 138 iteration 0 with loss 0.378852\n","Training at Epoch 139 iteration 0 with loss 0.3847012\n","Training at Epoch 140 iteration 0 with loss 0.33122468\n","Training at Epoch 141 iteration 0 with loss 0.3526772\n","Training at Epoch 142 iteration 0 with loss 0.40215987\n","Training at Epoch 143 iteration 0 with loss 0.326197\n","Training at Epoch 144 iteration 0 with loss 0.42078373\n","Training at Epoch 145 iteration 0 with loss 0.40547782\n","Training at Epoch 146 iteration 0 with loss 0.31172213\n","Training at Epoch 147 iteration 0 with loss 0.3726783\n","Training at Epoch 148 iteration 0 with loss 0.3392019\n","Training at Epoch 149 iteration 0 with loss 0.4304882\n","Training at Epoch 150 iteration 0 with loss 0.39488414\n","Training at Epoch 151 iteration 0 with loss 0.35695294\n","Training at Epoch 152 iteration 0 with loss 0.34887287\n","Training at Epoch 153 iteration 0 with loss 0.36956447\n","Training at Epoch 154 iteration 0 with loss 0.45533216\n","Training at Epoch 155 iteration 0 with loss 0.3651036\n","Training at Epoch 156 iteration 0 with loss 0.3196261\n","Training at Epoch 157 iteration 0 with loss 0.3345549\n","Training at Epoch 158 iteration 0 with loss 0.37707525\n","Training at Epoch 159 iteration 0 with loss 0.30613872\n","Training at Epoch 160 iteration 0 with loss 0.36930996\n","Training at Epoch 161 iteration 0 with loss 0.34390172\n","Training at Epoch 162 iteration 0 with loss 0.31004906\n","Training at Epoch 163 iteration 0 with loss 0.2977402\n","Training at Epoch 164 iteration 0 with loss 0.29987857\n","Training at Epoch 165 iteration 0 with loss 0.32773858\n","Training at Epoch 166 iteration 0 with loss 0.3188001\n","Training at Epoch 167 iteration 0 with loss 0.29519385\n","Training at Epoch 168 iteration 0 with loss 0.31257117\n","Training at Epoch 169 iteration 0 with loss 0.31861013\n","Training at Epoch 170 iteration 0 with loss 0.3007914\n","Training at Epoch 171 iteration 0 with loss 0.41496223\n","Training at Epoch 172 iteration 0 with loss 0.36622813\n","Training at Epoch 173 iteration 0 with loss 0.33990538\n","Training at Epoch 174 iteration 0 with loss 0.3057678\n","Training at Epoch 175 iteration 0 with loss 0.40372255\n","Training at Epoch 176 iteration 0 with loss 0.33475316\n","Training at Epoch 177 iteration 0 with loss 0.37520444\n","Training at Epoch 178 iteration 0 with loss 0.3234137\n","Training at Epoch 179 iteration 0 with loss 0.27772355\n","Training at Epoch 180 iteration 0 with loss 0.36587033\n","Training at Epoch 181 iteration 0 with loss 0.29541916\n","Training at Epoch 182 iteration 0 with loss 0.3248949\n","Training at Epoch 183 iteration 0 with loss 0.32038727\n","Training at Epoch 184 iteration 0 with loss 0.4051274\n","Training at Epoch 185 iteration 0 with loss 0.26076224\n","Training at Epoch 186 iteration 0 with loss 0.3299258\n","Training at Epoch 187 iteration 0 with loss 0.30751806\n","Training at Epoch 188 iteration 0 with loss 0.33775213\n","Training at Epoch 189 iteration 0 with loss 0.27874908\n","Training at Epoch 190 iteration 0 with loss 0.34148732\n","Training at Epoch 191 iteration 0 with loss 0.3032776\n","Training at Epoch 192 iteration 0 with loss 0.30158234\n","Training at Epoch 193 iteration 0 with loss 0.31709734\n","Training at Epoch 194 iteration 0 with loss 0.2513579\n","Training at Epoch 195 iteration 0 with loss 0.28229132\n","Training at Epoch 196 iteration 0 with loss 0.29485175\n","Training at Epoch 197 iteration 0 with loss 0.29243928\n","Training at Epoch 198 iteration 0 with loss 0.29995328\n","Training at Epoch 199 iteration 0 with loss 0.3060166\n","Training at Epoch 200 iteration 0 with loss 0.30733323\n","Training at Epoch 201 iteration 0 with loss 0.23393574\n","Training at Epoch 202 iteration 0 with loss 0.2705474\n","Training at Epoch 203 iteration 0 with loss 0.2749748\n","Training at Epoch 204 iteration 0 with loss 0.30635998\n","Training at Epoch 205 iteration 0 with loss 0.26415917\n","Training at Epoch 206 iteration 0 with loss 0.3292859\n","Training at Epoch 207 iteration 0 with loss 0.24860615\n","Training at Epoch 208 iteration 0 with loss 0.3189288\n","Training at Epoch 209 iteration 0 with loss 0.3091719\n","Training at Epoch 210 iteration 0 with loss 0.2846982\n","Training at Epoch 211 iteration 0 with loss 0.26227427\n","Training at Epoch 212 iteration 0 with loss 0.2471739\n","Training at Epoch 213 iteration 0 with loss 0.3575521\n","Training at Epoch 214 iteration 0 with loss 0.33376032\n","Training at Epoch 215 iteration 0 with loss 0.27622652\n","Training at Epoch 216 iteration 0 with loss 0.2535344\n","Training at Epoch 217 iteration 0 with loss 0.27664164\n","Training at Epoch 218 iteration 0 with loss 0.31517455\n","Training at Epoch 219 iteration 0 with loss 0.2423458\n","Training at Epoch 220 iteration 0 with loss 0.25436318\n","Training at Epoch 221 iteration 0 with loss 0.24609235\n","Training at Epoch 222 iteration 0 with loss 0.28680003\n","Training at Epoch 223 iteration 0 with loss 0.27199167\n","Training at Epoch 224 iteration 0 with loss 0.2933738\n","Training at Epoch 225 iteration 0 with loss 0.25679383\n","Training at Epoch 226 iteration 0 with loss 0.28016472\n","Training at Epoch 227 iteration 0 with loss 0.27581754\n","Training at Epoch 228 iteration 0 with loss 0.31939706\n","Training at Epoch 229 iteration 0 with loss 0.24263544\n","Training at Epoch 230 iteration 0 with loss 0.25082082\n","Training at Epoch 231 iteration 0 with loss 0.3429827\n","Training at Epoch 232 iteration 0 with loss 0.23728424\n","Training at Epoch 233 iteration 0 with loss 0.27619752\n","Training at Epoch 234 iteration 0 with loss 0.2606546\n","Training at Epoch 235 iteration 0 with loss 0.21592537\n","Training at Epoch 236 iteration 0 with loss 0.3125788\n","Training at Epoch 237 iteration 0 with loss 0.19245933\n","Training at Epoch 238 iteration 0 with loss 0.25195175\n","Training at Epoch 239 iteration 0 with loss 0.26552054\n","Training at Epoch 240 iteration 0 with loss 0.22274232\n","Training at Epoch 241 iteration 0 with loss 0.18629472\n","Training at Epoch 242 iteration 0 with loss 0.211863\n","Training at Epoch 243 iteration 0 with loss 0.23109895\n","Training at Epoch 244 iteration 0 with loss 0.19873822\n","Training at Epoch 245 iteration 0 with loss 0.30482155\n","Training at Epoch 246 iteration 0 with loss 0.2715964\n","Training at Epoch 247 iteration 0 with loss 0.25436425\n","Training at Epoch 248 iteration 0 with loss 0.28308123\n","Training at Epoch 249 iteration 0 with loss 0.22264794\n","Training at Epoch 250 iteration 0 with loss 0.2809246\n","Training at Epoch 251 iteration 0 with loss 0.23037727\n","Training at Epoch 252 iteration 0 with loss 0.29505002\n","Training at Epoch 253 iteration 0 with loss 0.24616212\n","Training at Epoch 254 iteration 0 with loss 0.23646739\n","Training at Epoch 255 iteration 0 with loss 0.2549276\n","Training at Epoch 256 iteration 0 with loss 0.28175512\n","Training at Epoch 257 iteration 0 with loss 0.2698924\n","Training at Epoch 258 iteration 0 with loss 0.22368917\n","Training at Epoch 259 iteration 0 with loss 0.21139577\n","Training at Epoch 260 iteration 0 with loss 0.296173\n","Training at Epoch 261 iteration 0 with loss 0.27763116\n","Training at Epoch 262 iteration 0 with loss 0.33366874\n","Training at Epoch 263 iteration 0 with loss 0.26455545\n","Training at Epoch 264 iteration 0 with loss 0.306596\n","Training at Epoch 265 iteration 0 with loss 0.28350765\n","Training at Epoch 266 iteration 0 with loss 0.21241662\n","Training at Epoch 267 iteration 0 with loss 0.30555692\n","Training at Epoch 268 iteration 0 with loss 0.2442752\n","Training at Epoch 269 iteration 0 with loss 0.25967887\n","Training at Epoch 270 iteration 0 with loss 0.3219012\n","Training at Epoch 271 iteration 0 with loss 0.2373932\n","Training at Epoch 272 iteration 0 with loss 0.3284178\n","Training at Epoch 273 iteration 0 with loss 0.25049227\n","Training at Epoch 274 iteration 0 with loss 0.24687092\n","Training at Epoch 275 iteration 0 with loss 0.2670498\n","Training at Epoch 276 iteration 0 with loss 0.25203818\n","Training at Epoch 277 iteration 0 with loss 0.28544623\n","Training at Epoch 278 iteration 0 with loss 0.26195836\n","Training at Epoch 279 iteration 0 with loss 0.31119442\n","Training at Epoch 280 iteration 0 with loss 0.23322576\n","Training at Epoch 281 iteration 0 with loss 0.24645272\n","Training at Epoch 282 iteration 0 with loss 0.21676308\n","Training at Epoch 283 iteration 0 with loss 0.2613266\n","Training at Epoch 284 iteration 0 with loss 0.22469078\n","Training at Epoch 285 iteration 0 with loss 0.21825463\n","Training at Epoch 286 iteration 0 with loss 0.26908162\n","Training at Epoch 287 iteration 0 with loss 0.25486594\n","Training at Epoch 288 iteration 0 with loss 0.23998672\n","Training at Epoch 289 iteration 0 with loss 0.25488475\n","Training at Epoch 290 iteration 0 with loss 0.2303595\n","Training at Epoch 291 iteration 0 with loss 0.24269637\n","Training at Epoch 292 iteration 0 with loss 0.28252652\n","Training at Epoch 293 iteration 0 with loss 0.23092216\n","Training at Epoch 294 iteration 0 with loss 0.25129122\n","Training at Epoch 295 iteration 0 with loss 0.28654477\n","Training at Epoch 296 iteration 0 with loss 0.27468944\n","Training at Epoch 297 iteration 0 with loss 0.29074895\n","Training at Epoch 298 iteration 0 with loss 0.2507151\n","Training at Epoch 299 iteration 0 with loss 0.26622903\n","Training at Epoch 300 iteration 0 with loss 0.2324613\n","Training at Epoch 301 iteration 0 with loss 0.2188438\n","Training at Epoch 302 iteration 0 with loss 0.17719765\n","Training at Epoch 303 iteration 0 with loss 0.23923598\n","Training at Epoch 304 iteration 0 with loss 0.22926298\n","Training at Epoch 305 iteration 0 with loss 0.23606174\n","Training at Epoch 306 iteration 0 with loss 0.2522613\n","Training at Epoch 307 iteration 0 with loss 0.23495413\n","Training at Epoch 308 iteration 0 with loss 0.25351757\n","Training at Epoch 309 iteration 0 with loss 0.19251268\n","Training at Epoch 310 iteration 0 with loss 0.19969146\n","Training at Epoch 311 iteration 0 with loss 0.21605659\n","Training at Epoch 312 iteration 0 with loss 0.19464149\n","Training at Epoch 313 iteration 0 with loss 0.196506\n","Training at Epoch 314 iteration 0 with loss 0.23223142\n","Training at Epoch 315 iteration 0 with loss 0.24688515\n","Training at Epoch 316 iteration 0 with loss 0.281315\n","Training at Epoch 317 iteration 0 with loss 0.22093491\n","Training at Epoch 318 iteration 0 with loss 0.21454094\n","Training at Epoch 319 iteration 0 with loss 0.22805709\n","Training at Epoch 320 iteration 0 with loss 0.19724303\n","Training at Epoch 321 iteration 0 with loss 0.19771104\n","Training at Epoch 322 iteration 0 with loss 0.25077975\n","Training at Epoch 323 iteration 0 with loss 0.22595537\n","Training at Epoch 324 iteration 0 with loss 0.25666606\n","Training at Epoch 325 iteration 0 with loss 0.28594458\n","Training at Epoch 326 iteration 0 with loss 0.25105056\n","Training at Epoch 327 iteration 0 with loss 0.23566672\n","Training at Epoch 328 iteration 0 with loss 0.23757088\n","Training at Epoch 329 iteration 0 with loss 0.18926044\n","Training at Epoch 330 iteration 0 with loss 0.25892943\n","Training at Epoch 331 iteration 0 with loss 0.22136076\n","Training at Epoch 332 iteration 0 with loss 0.26284173\n","Training at Epoch 333 iteration 0 with loss 0.2549085\n","Training at Epoch 334 iteration 0 with loss 0.28137755\n","Training at Epoch 335 iteration 0 with loss 0.22271444\n","Training at Epoch 336 iteration 0 with loss 0.24852374\n","Training at Epoch 337 iteration 0 with loss 0.257668\n","Training at Epoch 338 iteration 0 with loss 0.2226497\n","Training at Epoch 339 iteration 0 with loss 0.20961528\n","Training at Epoch 340 iteration 0 with loss 0.19826138\n","Training at Epoch 341 iteration 0 with loss 0.22675587\n","Training at Epoch 342 iteration 0 with loss 0.2054377\n","Training at Epoch 343 iteration 0 with loss 0.22695817\n","Training at Epoch 344 iteration 0 with loss 0.23240365\n","Training at Epoch 345 iteration 0 with loss 0.2146489\n","Training at Epoch 346 iteration 0 with loss 0.20801605\n","Training at Epoch 347 iteration 0 with loss 0.19500218\n","Training at Epoch 348 iteration 0 with loss 0.20501529\n","Training at Epoch 349 iteration 0 with loss 0.18759796\n","Training at Epoch 350 iteration 0 with loss 0.23244298\n","Training at Epoch 351 iteration 0 with loss 0.26787978\n","Training at Epoch 352 iteration 0 with loss 0.21676359\n","Training at Epoch 353 iteration 0 with loss 0.22241509\n","Training at Epoch 354 iteration 0 with loss 0.20012736\n","Training at Epoch 355 iteration 0 with loss 0.1879287\n","Training at Epoch 356 iteration 0 with loss 0.24156247\n","Training at Epoch 357 iteration 0 with loss 0.24538143\n","Training at Epoch 358 iteration 0 with loss 0.22124666\n","Training at Epoch 359 iteration 0 with loss 0.2195156\n","Training at Epoch 360 iteration 0 with loss 0.19464612\n","Training at Epoch 361 iteration 0 with loss 0.21627204\n","Training at Epoch 362 iteration 0 with loss 0.23289415\n","Training at Epoch 363 iteration 0 with loss 0.3122219\n","Training at Epoch 364 iteration 0 with loss 0.24902722\n","Training at Epoch 365 iteration 0 with loss 0.23405752\n","Training at Epoch 366 iteration 0 with loss 0.23363599\n","Training at Epoch 367 iteration 0 with loss 0.27602476\n","Training at Epoch 368 iteration 0 with loss 0.27672297\n","Training at Epoch 369 iteration 0 with loss 0.25974736\n","Training at Epoch 370 iteration 0 with loss 0.25183126\n","Training at Epoch 371 iteration 0 with loss 0.20570812\n","Training at Epoch 372 iteration 0 with loss 0.20936313\n","Training at Epoch 373 iteration 0 with loss 0.2463336\n","Training at Epoch 374 iteration 0 with loss 0.22750813\n","Training at Epoch 375 iteration 0 with loss 0.29234526\n","Training at Epoch 376 iteration 0 with loss 0.20515783\n","Training at Epoch 377 iteration 0 with loss 0.21886344\n","Training at Epoch 378 iteration 0 with loss 0.21989386\n","Training at Epoch 379 iteration 0 with loss 0.29635313\n","Training at Epoch 380 iteration 0 with loss 0.20533003\n","Training at Epoch 381 iteration 0 with loss 0.22604595\n","Training at Epoch 382 iteration 0 with loss 0.2355415\n","Training at Epoch 383 iteration 0 with loss 0.26143616\n","Training at Epoch 384 iteration 0 with loss 0.21821699\n","Training at Epoch 385 iteration 0 with loss 0.22824147\n","Training at Epoch 386 iteration 0 with loss 0.20744365\n","Training at Epoch 387 iteration 0 with loss 0.1670065\n","Training at Epoch 388 iteration 0 with loss 0.16602364\n","Training at Epoch 389 iteration 0 with loss 0.22793949\n","Training at Epoch 390 iteration 0 with loss 0.20860362\n","Training at Epoch 391 iteration 0 with loss 0.22016771\n","Training at Epoch 392 iteration 0 with loss 0.18950501\n","Training at Epoch 393 iteration 0 with loss 0.21480127\n","Training at Epoch 394 iteration 0 with loss 0.20931157\n","Training at Epoch 395 iteration 0 with loss 0.22434317\n","Training at Epoch 396 iteration 0 with loss 0.18692699\n","Training at Epoch 397 iteration 0 with loss 0.27678755\n","Training at Epoch 398 iteration 0 with loss 0.174535\n","Training at Epoch 399 iteration 0 with loss 0.23960884\n","Training at Epoch 400 iteration 0 with loss 0.22530629\n","Training at Epoch 401 iteration 0 with loss 0.24458009\n","Training at Epoch 402 iteration 0 with loss 0.21956712\n","Training at Epoch 403 iteration 0 with loss 0.16986747\n","Training at Epoch 404 iteration 0 with loss 0.1871304\n","Training at Epoch 405 iteration 0 with loss 0.24739803\n","Training at Epoch 406 iteration 0 with loss 0.22384536\n","Training at Epoch 407 iteration 0 with loss 0.23950674\n","Training at Epoch 408 iteration 0 with loss 0.22857751\n","Training at Epoch 409 iteration 0 with loss 0.23551033\n","Training at Epoch 410 iteration 0 with loss 0.15484081\n","Training at Epoch 411 iteration 0 with loss 0.22557458\n","Training at Epoch 412 iteration 0 with loss 0.13346861\n","Training at Epoch 413 iteration 0 with loss 0.21452567\n","Training at Epoch 414 iteration 0 with loss 0.22870907\n","Training at Epoch 415 iteration 0 with loss 0.22066563\n","Training at Epoch 416 iteration 0 with loss 0.25117916\n","Training at Epoch 417 iteration 0 with loss 0.26866353\n","Training at Epoch 418 iteration 0 with loss 0.22103712\n","Training at Epoch 419 iteration 0 with loss 0.16013585\n","Training at Epoch 420 iteration 0 with loss 0.23219922\n","Training at Epoch 421 iteration 0 with loss 0.22601217\n","Training at Epoch 422 iteration 0 with loss 0.22151522\n","Training at Epoch 423 iteration 0 with loss 0.25271258\n","Training at Epoch 424 iteration 0 with loss 0.20277113\n","Training at Epoch 425 iteration 0 with loss 0.1984445\n","Training at Epoch 426 iteration 0 with loss 0.18803675\n","Training at Epoch 427 iteration 0 with loss 0.255893\n","Training at Epoch 428 iteration 0 with loss 0.2372473\n","Training at Epoch 429 iteration 0 with loss 0.25374246\n","Training at Epoch 430 iteration 0 with loss 0.1848154\n","Training at Epoch 431 iteration 0 with loss 0.23391873\n","Training at Epoch 432 iteration 0 with loss 0.21432021\n","Training at Epoch 433 iteration 0 with loss 0.20314437\n","Training at Epoch 434 iteration 0 with loss 0.1975354\n","Training at Epoch 435 iteration 0 with loss 0.21753563\n","Training at Epoch 436 iteration 0 with loss 0.26894224\n","Training at Epoch 437 iteration 0 with loss 0.21082176\n","Training at Epoch 438 iteration 0 with loss 0.25140506\n","Training at Epoch 439 iteration 0 with loss 0.21728018\n","Training at Epoch 440 iteration 0 with loss 0.25280944\n","Training at Epoch 441 iteration 0 with loss 0.19445476\n","Training at Epoch 442 iteration 0 with loss 0.26848805\n","Training at Epoch 443 iteration 0 with loss 0.18233554\n","Training at Epoch 444 iteration 0 with loss 0.20561238\n","Training at Epoch 445 iteration 0 with loss 0.21388939\n","Training at Epoch 446 iteration 0 with loss 0.18184584\n","Training at Epoch 447 iteration 0 with loss 0.20444983\n","Training at Epoch 448 iteration 0 with loss 0.22436231\n","Training at Epoch 449 iteration 0 with loss 0.21048793\n","Training at Epoch 450 iteration 0 with loss 0.20336126\n","Training at Epoch 451 iteration 0 with loss 0.2284931\n","Training at Epoch 452 iteration 0 with loss 0.19689025\n","Training at Epoch 453 iteration 0 with loss 0.17318682\n","Training at Epoch 454 iteration 0 with loss 0.17181602\n","Training at Epoch 455 iteration 0 with loss 0.24264465\n","Training at Epoch 456 iteration 0 with loss 0.28601408\n","Training at Epoch 457 iteration 0 with loss 0.2013587\n","Training at Epoch 458 iteration 0 with loss 0.22345988\n","Training at Epoch 459 iteration 0 with loss 0.25766426\n","Training at Epoch 460 iteration 0 with loss 0.2287278\n","Training at Epoch 461 iteration 0 with loss 0.20485878\n","Training at Epoch 462 iteration 0 with loss 0.29358312\n","Training at Epoch 463 iteration 0 with loss 0.21009749\n","Training at Epoch 464 iteration 0 with loss 0.13889045\n","Training at Epoch 465 iteration 0 with loss 0.23437269\n","Training at Epoch 466 iteration 0 with loss 0.24889123\n","Training at Epoch 467 iteration 0 with loss 0.24975286\n","Training at Epoch 468 iteration 0 with loss 0.22636716\n","Training at Epoch 469 iteration 0 with loss 0.21855699\n","Training at Epoch 470 iteration 0 with loss 0.26360822\n","Training at Epoch 471 iteration 0 with loss 0.18642043\n","Training at Epoch 472 iteration 0 with loss 0.20829217\n","Training at Epoch 473 iteration 0 with loss 0.2212207\n","Training at Epoch 474 iteration 0 with loss 0.263781\n","Training at Epoch 475 iteration 0 with loss 0.17330529\n","Training at Epoch 476 iteration 0 with loss 0.20296086\n","Training at Epoch 477 iteration 0 with loss 0.19251047\n","Training at Epoch 478 iteration 0 with loss 0.25153196\n","Training at Epoch 479 iteration 0 with loss 0.25512457\n","Training at Epoch 480 iteration 0 with loss 0.20247616\n","Training at Epoch 481 iteration 0 with loss 0.1833339\n","Training at Epoch 482 iteration 0 with loss 0.17651019\n","Training at Epoch 483 iteration 0 with loss 0.19350961\n","Training at Epoch 484 iteration 0 with loss 0.21765515\n","Training at Epoch 485 iteration 0 with loss 0.17884678\n","Training at Epoch 486 iteration 0 with loss 0.28088596\n","Training at Epoch 487 iteration 0 with loss 0.1624271\n","Training at Epoch 488 iteration 0 with loss 0.19039252\n","Training at Epoch 489 iteration 0 with loss 0.14771765\n","Training at Epoch 490 iteration 0 with loss 0.21618646\n","Training at Epoch 491 iteration 0 with loss 0.20500532\n","Training at Epoch 492 iteration 0 with loss 0.21500121\n","Training at Epoch 493 iteration 0 with loss 0.15427543\n","Training at Epoch 494 iteration 0 with loss 0.16835561\n","Training at Epoch 495 iteration 0 with loss 0.21254136\n","Training at Epoch 496 iteration 0 with loss 0.17034715\n","Training at Epoch 497 iteration 0 with loss 0.1964371\n","Training at Epoch 498 iteration 0 with loss 0.16542473\n","Training at Epoch 499 iteration 0 with loss 0.2136769\n","Training at Epoch 500 iteration 0 with loss 0.19379115\n","Training at Epoch 501 iteration 0 with loss 0.19433512\n","Training at Epoch 502 iteration 0 with loss 0.23920636\n","Training at Epoch 503 iteration 0 with loss 0.29778346\n","Training at Epoch 504 iteration 0 with loss 0.2504795\n","Training at Epoch 505 iteration 0 with loss 0.16566803\n","Training at Epoch 506 iteration 0 with loss 0.16822234\n","Training at Epoch 507 iteration 0 with loss 0.23070095\n","Training at Epoch 508 iteration 0 with loss 0.21460426\n","Training at Epoch 509 iteration 0 with loss 0.21323584\n","Training at Epoch 510 iteration 0 with loss 0.23279768\n","Training at Epoch 511 iteration 0 with loss 0.18690541\n","Training at Epoch 512 iteration 0 with loss 0.1860971\n","Training at Epoch 513 iteration 0 with loss 0.18559748\n","Training at Epoch 514 iteration 0 with loss 0.23479776\n","Training at Epoch 515 iteration 0 with loss 0.19865984\n","Training at Epoch 516 iteration 0 with loss 0.2715953\n","Training at Epoch 517 iteration 0 with loss 0.20707585\n","Training at Epoch 518 iteration 0 with loss 0.2031104\n","Training at Epoch 519 iteration 0 with loss 0.20500647\n","Training at Epoch 520 iteration 0 with loss 0.2304123\n","Training at Epoch 521 iteration 0 with loss 0.19726403\n","Training at Epoch 522 iteration 0 with loss 0.17976655\n","Training at Epoch 523 iteration 0 with loss 0.21000367\n","Training at Epoch 524 iteration 0 with loss 0.17909613\n","Training at Epoch 525 iteration 0 with loss 0.16190746\n","Training at Epoch 526 iteration 0 with loss 0.18933165\n","Training at Epoch 527 iteration 0 with loss 0.17097054\n","Training at Epoch 528 iteration 0 with loss 0.1771911\n","Training at Epoch 529 iteration 0 with loss 0.19191845\n","Training at Epoch 530 iteration 0 with loss 0.18540215\n","Training at Epoch 531 iteration 0 with loss 0.19727977\n","Training at Epoch 532 iteration 0 with loss 0.19056839\n","Training at Epoch 533 iteration 0 with loss 0.19824731\n","Training at Epoch 534 iteration 0 with loss 0.30104512\n","Training at Epoch 535 iteration 0 with loss 0.24538276\n","Training at Epoch 536 iteration 0 with loss 0.21641256\n","Training at Epoch 537 iteration 0 with loss 0.17430612\n","Training at Epoch 538 iteration 0 with loss 0.21695958\n","Training at Epoch 539 iteration 0 with loss 0.19904354\n","Training at Epoch 540 iteration 0 with loss 0.19367313\n","Training at Epoch 541 iteration 0 with loss 0.21392474\n","Training at Epoch 542 iteration 0 with loss 0.23141693\n","Training at Epoch 543 iteration 0 with loss 0.18890768\n","Training at Epoch 544 iteration 0 with loss 0.19770712\n","Training at Epoch 545 iteration 0 with loss 0.22170016\n","Training at Epoch 546 iteration 0 with loss 0.22844118\n","Training at Epoch 547 iteration 0 with loss 0.18342644\n","Training at Epoch 548 iteration 0 with loss 0.24988252\n","Training at Epoch 549 iteration 0 with loss 0.214643\n","Training at Epoch 550 iteration 0 with loss 0.20565301\n","Training at Epoch 551 iteration 0 with loss 0.26878673\n","Training at Epoch 552 iteration 0 with loss 0.17150271\n","Training at Epoch 553 iteration 0 with loss 0.16484293\n","Training at Epoch 554 iteration 0 with loss 0.20929453\n","Training at Epoch 555 iteration 0 with loss 0.17560531\n","Training at Epoch 556 iteration 0 with loss 0.20226362\n","Training at Epoch 557 iteration 0 with loss 0.17059347\n","Training at Epoch 558 iteration 0 with loss 0.16459972\n","Training at Epoch 559 iteration 0 with loss 0.2093345\n","Training at Epoch 560 iteration 0 with loss 0.14729226\n","Training at Epoch 561 iteration 0 with loss 0.21999818\n","Training at Epoch 562 iteration 0 with loss 0.19660841\n","Training at Epoch 563 iteration 0 with loss 0.21378617\n","Training at Epoch 564 iteration 0 with loss 0.19794479\n","Training at Epoch 565 iteration 0 with loss 0.13248396\n","Training at Epoch 566 iteration 0 with loss 0.2554588\n","Training at Epoch 567 iteration 0 with loss 0.20143932\n","Training at Epoch 568 iteration 0 with loss 0.1297032\n","Training at Epoch 569 iteration 0 with loss 0.14681955\n","Training at Epoch 570 iteration 0 with loss 0.18767628\n","Training at Epoch 571 iteration 0 with loss 0.19651787\n","Training at Epoch 572 iteration 0 with loss 0.20504463\n","Training at Epoch 573 iteration 0 with loss 0.19001922\n","Training at Epoch 574 iteration 0 with loss 0.19233243\n","Training at Epoch 575 iteration 0 with loss 0.1756792\n","Training at Epoch 576 iteration 0 with loss 0.26834375\n","Training at Epoch 577 iteration 0 with loss 0.14197217\n","Training at Epoch 578 iteration 0 with loss 0.19503671\n","Training at Epoch 579 iteration 0 with loss 0.25692052\n","Training at Epoch 580 iteration 0 with loss 0.15856403\n","Training at Epoch 581 iteration 0 with loss 0.16488193\n","Training at Epoch 582 iteration 0 with loss 0.21276239\n","Training at Epoch 583 iteration 0 with loss 0.23513031\n","Training at Epoch 584 iteration 0 with loss 0.21878853\n","Training at Epoch 585 iteration 0 with loss 0.24622124\n","Training at Epoch 586 iteration 0 with loss 0.14770365\n","Training at Epoch 587 iteration 0 with loss 0.16428484\n","Training at Epoch 588 iteration 0 with loss 0.204889\n","Training at Epoch 589 iteration 0 with loss 0.2604582\n","Training at Epoch 590 iteration 0 with loss 0.19796938\n","Training at Epoch 591 iteration 0 with loss 0.111003384\n","Training at Epoch 592 iteration 0 with loss 0.16603987\n","Training at Epoch 593 iteration 0 with loss 0.23370124\n","Training at Epoch 594 iteration 0 with loss 0.1773182\n","Training at Epoch 595 iteration 0 with loss 0.20695984\n","Training at Epoch 596 iteration 0 with loss 0.17980488\n","Training at Epoch 597 iteration 0 with loss 0.20443504\n","Training at Epoch 598 iteration 0 with loss 0.18851803\n","Training at Epoch 599 iteration 0 with loss 0.16275842\n","Training at Epoch 600 iteration 0 with loss 0.1770275\n","Training at Epoch 601 iteration 0 with loss 0.11635831\n","Training at Epoch 602 iteration 0 with loss 0.20816119\n","Training at Epoch 603 iteration 0 with loss 0.21956474\n","Training at Epoch 604 iteration 0 with loss 0.23600979\n","Training at Epoch 605 iteration 0 with loss 0.20994036\n","Training at Epoch 606 iteration 0 with loss 0.17269593\n","Training at Epoch 607 iteration 0 with loss 0.20847683\n","Training at Epoch 608 iteration 0 with loss 0.14706387\n","Training at Epoch 609 iteration 0 with loss 0.20626667\n","Training at Epoch 610 iteration 0 with loss 0.19616054\n","Training at Epoch 611 iteration 0 with loss 0.17554703\n","Training at Epoch 612 iteration 0 with loss 0.2084457\n","Training at Epoch 613 iteration 0 with loss 0.16445974\n","Training at Epoch 614 iteration 0 with loss 0.18861642\n","Training at Epoch 615 iteration 0 with loss 0.20762452\n","Training at Epoch 616 iteration 0 with loss 0.20940298\n","Training at Epoch 617 iteration 0 with loss 0.17727058\n","Training at Epoch 618 iteration 0 with loss 0.20038582\n","Training at Epoch 619 iteration 0 with loss 0.26877543\n","Training at Epoch 620 iteration 0 with loss 0.20576175\n","Training at Epoch 621 iteration 0 with loss 0.1644828\n","Training at Epoch 622 iteration 0 with loss 0.22785786\n","Training at Epoch 623 iteration 0 with loss 0.15325983\n","Training at Epoch 624 iteration 0 with loss 0.19307992\n","Training at Epoch 625 iteration 0 with loss 0.16543682\n","Training at Epoch 626 iteration 0 with loss 0.21070561\n","Training at Epoch 627 iteration 0 with loss 0.16967443\n","Training at Epoch 628 iteration 0 with loss 0.18834433\n","Training at Epoch 629 iteration 0 with loss 0.18146741\n","Training at Epoch 630 iteration 0 with loss 0.15183991\n","Training at Epoch 631 iteration 0 with loss 0.24153279\n","Training at Epoch 632 iteration 0 with loss 0.25950605\n","Training at Epoch 633 iteration 0 with loss 0.22994837\n","Training at Epoch 634 iteration 0 with loss 0.19750722\n","Training at Epoch 635 iteration 0 with loss 0.15864983\n","Training at Epoch 636 iteration 0 with loss 0.27839103\n","Training at Epoch 637 iteration 0 with loss 0.21278286\n","Training at Epoch 638 iteration 0 with loss 0.2331554\n","Training at Epoch 639 iteration 0 with loss 0.16311908\n","Training at Epoch 640 iteration 0 with loss 0.22249828\n","Training at Epoch 641 iteration 0 with loss 0.17108239\n","Training at Epoch 642 iteration 0 with loss 0.21265653\n","Training at Epoch 643 iteration 0 with loss 0.20447952\n","Training at Epoch 644 iteration 0 with loss 0.15782021\n","Training at Epoch 645 iteration 0 with loss 0.21018966\n","Training at Epoch 646 iteration 0 with loss 0.18214461\n","Training at Epoch 647 iteration 0 with loss 0.2036857\n","Training at Epoch 648 iteration 0 with loss 0.2086855\n","Training at Epoch 649 iteration 0 with loss 0.18437769\n","Training at Epoch 650 iteration 0 with loss 0.22438367\n","Training at Epoch 651 iteration 0 with loss 0.18915142\n","Training at Epoch 652 iteration 0 with loss 0.18819454\n","Training at Epoch 653 iteration 0 with loss 0.1883643\n","Training at Epoch 654 iteration 0 with loss 0.23186843\n","Training at Epoch 655 iteration 0 with loss 0.16838615\n","Training at Epoch 656 iteration 0 with loss 0.18385144\n","Training at Epoch 657 iteration 0 with loss 0.20556405\n","Training at Epoch 658 iteration 0 with loss 0.19587386\n","Training at Epoch 659 iteration 0 with loss 0.15925033\n","Training at Epoch 660 iteration 0 with loss 0.15459144\n","Training at Epoch 661 iteration 0 with loss 0.21319081\n","Training at Epoch 662 iteration 0 with loss 0.23424374\n","Training at Epoch 663 iteration 0 with loss 0.24333209\n","Training at Epoch 664 iteration 0 with loss 0.18739516\n","Training at Epoch 665 iteration 0 with loss 0.2062301\n","Training at Epoch 666 iteration 0 with loss 0.2473477\n","Training at Epoch 667 iteration 0 with loss 0.12947035\n","Training at Epoch 668 iteration 0 with loss 0.23674133\n","Training at Epoch 669 iteration 0 with loss 0.18383762\n","Training at Epoch 670 iteration 0 with loss 0.21532796\n","Training at Epoch 671 iteration 0 with loss 0.161641\n","Training at Epoch 672 iteration 0 with loss 0.19279933\n","Training at Epoch 673 iteration 0 with loss 0.18204285\n","Training at Epoch 674 iteration 0 with loss 0.21719445\n","Training at Epoch 675 iteration 0 with loss 0.17453378\n","Training at Epoch 676 iteration 0 with loss 0.27849975\n","Training at Epoch 677 iteration 0 with loss 0.1774539\n","Training at Epoch 678 iteration 0 with loss 0.17291707\n","Training at Epoch 679 iteration 0 with loss 0.17927359\n","Training at Epoch 680 iteration 0 with loss 0.22179125\n","Training at Epoch 681 iteration 0 with loss 0.23363057\n","Training at Epoch 682 iteration 0 with loss 0.18966435\n","Training at Epoch 683 iteration 0 with loss 0.19307883\n","Training at Epoch 684 iteration 0 with loss 0.15651102\n","Training at Epoch 685 iteration 0 with loss 0.17111692\n","Training at Epoch 686 iteration 0 with loss 0.14767042\n","Training at Epoch 687 iteration 0 with loss 0.18909736\n","Training at Epoch 688 iteration 0 with loss 0.17626281\n","Training at Epoch 689 iteration 0 with loss 0.16387945\n","Training at Epoch 690 iteration 0 with loss 0.22546622\n","Training at Epoch 691 iteration 0 with loss 0.16081671\n","Training at Epoch 692 iteration 0 with loss 0.18307002\n","Training at Epoch 693 iteration 0 with loss 0.18828002\n","Training at Epoch 694 iteration 0 with loss 0.22531798\n","Training at Epoch 695 iteration 0 with loss 0.16597481\n","Training at Epoch 696 iteration 0 with loss 0.17988953\n","Training at Epoch 697 iteration 0 with loss 0.19118527\n","Training at Epoch 698 iteration 0 with loss 0.21432628\n","Training at Epoch 699 iteration 0 with loss 0.12439474\n","Training at Epoch 700 iteration 0 with loss 0.15877008\n","Training at Epoch 701 iteration 0 with loss 0.18120648\n","Training at Epoch 702 iteration 0 with loss 0.15240693\n","Training at Epoch 703 iteration 0 with loss 0.16855691\n","Training at Epoch 704 iteration 0 with loss 0.16129486\n","Training at Epoch 705 iteration 0 with loss 0.1665136\n","Training at Epoch 706 iteration 0 with loss 0.113586314\n","Training at Epoch 707 iteration 0 with loss 0.1701007\n","Training at Epoch 708 iteration 0 with loss 0.18304123\n","Training at Epoch 709 iteration 0 with loss 0.23083624\n","Training at Epoch 710 iteration 0 with loss 0.18013142\n","Training at Epoch 711 iteration 0 with loss 0.15359376\n","Training at Epoch 712 iteration 0 with loss 0.20216902\n","Training at Epoch 713 iteration 0 with loss 0.18276112\n","Training at Epoch 714 iteration 0 with loss 0.15403944\n","Training at Epoch 715 iteration 0 with loss 0.2144971\n","Training at Epoch 716 iteration 0 with loss 0.17720413\n","Training at Epoch 717 iteration 0 with loss 0.15959562\n","Training at Epoch 718 iteration 0 with loss 0.13603301\n","Training at Epoch 719 iteration 0 with loss 0.21207002\n","Training at Epoch 720 iteration 0 with loss 0.20240587\n","Training at Epoch 721 iteration 0 with loss 0.18931977\n","Training at Epoch 722 iteration 0 with loss 0.17660889\n","Training at Epoch 723 iteration 0 with loss 0.17723645\n","Training at Epoch 724 iteration 0 with loss 0.1625312\n","Training at Epoch 725 iteration 0 with loss 0.20019925\n","Training at Epoch 726 iteration 0 with loss 0.18382558\n","Training at Epoch 727 iteration 0 with loss 0.14780831\n","Training at Epoch 728 iteration 0 with loss 0.1887365\n","Training at Epoch 729 iteration 0 with loss 0.17594625\n","Training at Epoch 730 iteration 0 with loss 0.20046973\n","Training at Epoch 731 iteration 0 with loss 0.15001613\n","Training at Epoch 732 iteration 0 with loss 0.16768697\n","Training at Epoch 733 iteration 0 with loss 0.16206175\n","Training at Epoch 734 iteration 0 with loss 0.1881038\n","Training at Epoch 735 iteration 0 with loss 0.1920841\n","Training at Epoch 736 iteration 0 with loss 0.17443337\n","Training at Epoch 737 iteration 0 with loss 0.17722346\n","Training at Epoch 738 iteration 0 with loss 0.17545025\n","Training at Epoch 739 iteration 0 with loss 0.18378878\n","Training at Epoch 740 iteration 0 with loss 0.18313196\n","Training at Epoch 741 iteration 0 with loss 0.15602762\n","Training at Epoch 742 iteration 0 with loss 0.13730843\n","Training at Epoch 743 iteration 0 with loss 0.2066232\n","Training at Epoch 744 iteration 0 with loss 0.19237593\n","Training at Epoch 745 iteration 0 with loss 0.15531576\n","Training at Epoch 746 iteration 0 with loss 0.21982357\n","Training at Epoch 747 iteration 0 with loss 0.16422051\n","Training at Epoch 748 iteration 0 with loss 0.11278061\n","Training at Epoch 749 iteration 0 with loss 0.17313023\n","Training at Epoch 750 iteration 0 with loss 0.19348823\n","Training at Epoch 751 iteration 0 with loss 0.2094749\n","Training at Epoch 752 iteration 0 with loss 0.17313607\n","Training at Epoch 753 iteration 0 with loss 0.15082239\n","Training at Epoch 754 iteration 0 with loss 0.18930823\n","Training at Epoch 755 iteration 0 with loss 0.17684941\n","Training at Epoch 756 iteration 0 with loss 0.14620501\n","Training at Epoch 757 iteration 0 with loss 0.1536926\n","Training at Epoch 758 iteration 0 with loss 0.18681604\n","Training at Epoch 759 iteration 0 with loss 0.22472821\n","Training at Epoch 760 iteration 0 with loss 0.14342456\n","Training at Epoch 761 iteration 0 with loss 0.1859072\n","Training at Epoch 762 iteration 0 with loss 0.16921648\n","Training at Epoch 763 iteration 0 with loss 0.20335308\n","Training at Epoch 764 iteration 0 with loss 0.22766383\n","Training at Epoch 765 iteration 0 with loss 0.15011998\n","Training at Epoch 766 iteration 0 with loss 0.18383439\n","Training at Epoch 767 iteration 0 with loss 0.20151722\n","Training at Epoch 768 iteration 0 with loss 0.17757326\n","Training at Epoch 769 iteration 0 with loss 0.14954615\n","Training at Epoch 770 iteration 0 with loss 0.19131193\n","Training at Epoch 771 iteration 0 with loss 0.15805875\n","Training at Epoch 772 iteration 0 with loss 0.13536136\n","Training at Epoch 773 iteration 0 with loss 0.15079057\n","Training at Epoch 774 iteration 0 with loss 0.2167469\n","Training at Epoch 775 iteration 0 with loss 0.20354167\n","Training at Epoch 776 iteration 0 with loss 0.17167445\n","Training at Epoch 777 iteration 0 with loss 0.17145537\n","Training at Epoch 778 iteration 0 with loss 0.13962436\n","Training at Epoch 779 iteration 0 with loss 0.20309933\n","Training at Epoch 780 iteration 0 with loss 0.1701732\n","Training at Epoch 781 iteration 0 with loss 0.19169676\n","Training at Epoch 782 iteration 0 with loss 0.19506046\n","Training at Epoch 783 iteration 0 with loss 0.15430275\n","Training at Epoch 784 iteration 0 with loss 0.16516635\n","Training at Epoch 785 iteration 0 with loss 0.16858754\n","Training at Epoch 786 iteration 0 with loss 0.14091186\n","Training at Epoch 787 iteration 0 with loss 0.17461522\n","Training at Epoch 788 iteration 0 with loss 0.16118735\n","Training at Epoch 789 iteration 0 with loss 0.17225118\n","Training at Epoch 790 iteration 0 with loss 0.16434494\n","Training at Epoch 791 iteration 0 with loss 0.1718801\n","Training at Epoch 792 iteration 0 with loss 0.21550298\n","Training at Epoch 793 iteration 0 with loss 0.17528607\n","Training at Epoch 794 iteration 0 with loss 0.16322465\n","Training at Epoch 795 iteration 0 with loss 0.16549948\n","Training at Epoch 796 iteration 0 with loss 0.19189335\n","Training at Epoch 797 iteration 0 with loss 0.16149499\n","Training at Epoch 798 iteration 0 with loss 0.20885855\n","Training at Epoch 799 iteration 0 with loss 0.16771156\n","Training at Epoch 800 iteration 0 with loss 0.1784112\n","Training at Epoch 801 iteration 0 with loss 0.16716468\n","Training at Epoch 802 iteration 0 with loss 0.17979181\n","Training at Epoch 803 iteration 0 with loss 0.16044396\n","Training at Epoch 804 iteration 0 with loss 0.11875367\n","Training at Epoch 805 iteration 0 with loss 0.15621442\n","Training at Epoch 806 iteration 0 with loss 0.17252815\n","Training at Epoch 807 iteration 0 with loss 0.16079238\n","Training at Epoch 808 iteration 0 with loss 0.18610506\n","Training at Epoch 809 iteration 0 with loss 0.13340841\n","Training at Epoch 810 iteration 0 with loss 0.19229904\n","Training at Epoch 811 iteration 0 with loss 0.1354605\n","Training at Epoch 812 iteration 0 with loss 0.14613056\n","Training at Epoch 813 iteration 0 with loss 0.18585159\n","Training at Epoch 814 iteration 0 with loss 0.17805935\n","Training at Epoch 815 iteration 0 with loss 0.17059302\n","Training at Epoch 816 iteration 0 with loss 0.1863088\n","Training at Epoch 817 iteration 0 with loss 0.1475555\n","Training at Epoch 818 iteration 0 with loss 0.15570177\n","Training at Epoch 819 iteration 0 with loss 0.20323059\n","Training at Epoch 820 iteration 0 with loss 0.16320246\n","Training at Epoch 821 iteration 0 with loss 0.14602405\n","Training at Epoch 822 iteration 0 with loss 0.15661378\n","Training at Epoch 823 iteration 0 with loss 0.15915118\n","Training at Epoch 824 iteration 0 with loss 0.16942042\n","Training at Epoch 825 iteration 0 with loss 0.16555348\n","Training at Epoch 826 iteration 0 with loss 0.1959477\n","Training at Epoch 827 iteration 0 with loss 0.19611792\n","Training at Epoch 828 iteration 0 with loss 0.16307107\n","Training at Epoch 829 iteration 0 with loss 0.20734042\n","Training at Epoch 830 iteration 0 with loss 0.18702543\n","Training at Epoch 831 iteration 0 with loss 0.15475042\n","Training at Epoch 832 iteration 0 with loss 0.1274899\n","Training at Epoch 833 iteration 0 with loss 0.18763398\n","Training at Epoch 834 iteration 0 with loss 0.2194567\n","Training at Epoch 835 iteration 0 with loss 0.1827589\n","Training at Epoch 836 iteration 0 with loss 0.19259182\n","Training at Epoch 837 iteration 0 with loss 0.18971567\n","Training at Epoch 838 iteration 0 with loss 0.1621017\n","Training at Epoch 839 iteration 0 with loss 0.2136746\n","Training at Epoch 840 iteration 0 with loss 0.2242532\n","Training at Epoch 841 iteration 0 with loss 0.16116089\n","Training at Epoch 842 iteration 0 with loss 0.17745835\n","Training at Epoch 843 iteration 0 with loss 0.1483599\n","Training at Epoch 844 iteration 0 with loss 0.14347157\n","Training at Epoch 845 iteration 0 with loss 0.20470078\n","Training at Epoch 846 iteration 0 with loss 0.16019605\n","Training at Epoch 847 iteration 0 with loss 0.1605001\n","Training at Epoch 848 iteration 0 with loss 0.16346437\n","Training at Epoch 849 iteration 0 with loss 0.1478968\n","Training at Epoch 850 iteration 0 with loss 0.1979513\n","Training at Epoch 851 iteration 0 with loss 0.18846424\n","Training at Epoch 852 iteration 0 with loss 0.17639215\n","Training at Epoch 853 iteration 0 with loss 0.20305331\n","Training at Epoch 854 iteration 0 with loss 0.20325752\n","Training at Epoch 855 iteration 0 with loss 0.15047108\n","Training at Epoch 856 iteration 0 with loss 0.146298\n","Training at Epoch 857 iteration 0 with loss 0.19711027\n","Training at Epoch 858 iteration 0 with loss 0.18997295\n","Training at Epoch 859 iteration 0 with loss 0.18654354\n","Training at Epoch 860 iteration 0 with loss 0.20947301\n","Training at Epoch 861 iteration 0 with loss 0.20790675\n","Training at Epoch 862 iteration 0 with loss 0.20620589\n","Training at Epoch 863 iteration 0 with loss 0.19010778\n","Training at Epoch 864 iteration 0 with loss 0.20249553\n","Training at Epoch 865 iteration 0 with loss 0.12855369\n","Training at Epoch 866 iteration 0 with loss 0.15202582\n","Training at Epoch 867 iteration 0 with loss 0.18029779\n","Training at Epoch 868 iteration 0 with loss 0.19405441\n","Training at Epoch 869 iteration 0 with loss 0.21561942\n","Training at Epoch 870 iteration 0 with loss 0.1843445\n","Training at Epoch 871 iteration 0 with loss 0.19950506\n","Training at Epoch 872 iteration 0 with loss 0.21728426\n","Training at Epoch 873 iteration 0 with loss 0.21177083\n","Training at Epoch 874 iteration 0 with loss 0.16144595\n","Training at Epoch 875 iteration 0 with loss 0.15310831\n","Training at Epoch 876 iteration 0 with loss 0.18916652\n","Training at Epoch 877 iteration 0 with loss 0.18458879\n","Training at Epoch 878 iteration 0 with loss 0.14763834\n","Training at Epoch 879 iteration 0 with loss 0.15935299\n","Training at Epoch 880 iteration 0 with loss 0.13617715\n","Training at Epoch 881 iteration 0 with loss 0.17313051\n","Training at Epoch 882 iteration 0 with loss 0.16778207\n","Training at Epoch 883 iteration 0 with loss 0.16331461\n","Training at Epoch 884 iteration 0 with loss 0.16663344\n","Training at Epoch 885 iteration 0 with loss 0.1745226\n","Training at Epoch 886 iteration 0 with loss 0.14729255\n","Training at Epoch 887 iteration 0 with loss 0.16643845\n","Training at Epoch 888 iteration 0 with loss 0.17326123\n","Training at Epoch 889 iteration 0 with loss 0.16120432\n","Training at Epoch 890 iteration 0 with loss 0.1771778\n","Training at Epoch 891 iteration 0 with loss 0.15424201\n","Training at Epoch 892 iteration 0 with loss 0.16634397\n","Training at Epoch 893 iteration 0 with loss 0.18628424\n","Training at Epoch 894 iteration 0 with loss 0.1476576\n","Training at Epoch 895 iteration 0 with loss 0.16274129\n","Training at Epoch 896 iteration 0 with loss 0.14556429\n","Training at Epoch 897 iteration 0 with loss 0.17959781\n","Training at Epoch 898 iteration 0 with loss 0.16269597\n","Training at Epoch 899 iteration 0 with loss 0.17476426\n","Training at Epoch 900 iteration 0 with loss 0.23265365\n","Training at Epoch 901 iteration 0 with loss 0.14620325\n","Training at Epoch 902 iteration 0 with loss 0.1467645\n","Training at Epoch 903 iteration 0 with loss 0.18768106\n","Training at Epoch 904 iteration 0 with loss 0.1536308\n","Training at Epoch 905 iteration 0 with loss 0.21938005\n","Training at Epoch 906 iteration 0 with loss 0.1409902\n","Training at Epoch 907 iteration 0 with loss 0.19710019\n","Training at Epoch 908 iteration 0 with loss 0.16376463\n","Training at Epoch 909 iteration 0 with loss 0.11695732\n","Training at Epoch 910 iteration 0 with loss 0.2181694\n","Training at Epoch 911 iteration 0 with loss 0.22102664\n","Training at Epoch 912 iteration 0 with loss 0.17098807\n","Training at Epoch 913 iteration 0 with loss 0.17036545\n","Training at Epoch 914 iteration 0 with loss 0.16981904\n","Training at Epoch 915 iteration 0 with loss 0.20998602\n","Training at Epoch 916 iteration 0 with loss 0.16274211\n","Training at Epoch 917 iteration 0 with loss 0.16697574\n","Training at Epoch 918 iteration 0 with loss 0.17021985\n","Training at Epoch 919 iteration 0 with loss 0.21020052\n","Training at Epoch 920 iteration 0 with loss 0.15442821\n","Training at Epoch 921 iteration 0 with loss 0.24641973\n","Training at Epoch 922 iteration 0 with loss 0.18076648\n","Training at Epoch 923 iteration 0 with loss 0.19262163\n","Training at Epoch 924 iteration 0 with loss 0.15199938\n","Training at Epoch 925 iteration 0 with loss 0.18191141\n","Training at Epoch 926 iteration 0 with loss 0.20002085\n","Training at Epoch 927 iteration 0 with loss 0.18277025\n","Training at Epoch 928 iteration 0 with loss 0.22624294\n","Training at Epoch 929 iteration 0 with loss 0.2004241\n","Training at Epoch 930 iteration 0 with loss 0.1474284\n","Training at Epoch 931 iteration 0 with loss 0.22079527\n","Training at Epoch 932 iteration 0 with loss 0.17340294\n","Training at Epoch 933 iteration 0 with loss 0.22693312\n","Training at Epoch 934 iteration 0 with loss 0.16174409\n","Training at Epoch 935 iteration 0 with loss 0.17783405\n","Training at Epoch 936 iteration 0 with loss 0.165735\n","Training at Epoch 937 iteration 0 with loss 0.14606099\n","Training at Epoch 938 iteration 0 with loss 0.18358047\n","Training at Epoch 939 iteration 0 with loss 0.16586156\n","Training at Epoch 940 iteration 0 with loss 0.2103014\n","Training at Epoch 941 iteration 0 with loss 0.13575841\n","Training at Epoch 942 iteration 0 with loss 0.16240415\n","Training at Epoch 943 iteration 0 with loss 0.16684265\n","Training at Epoch 944 iteration 0 with loss 0.16755265\n","Training at Epoch 945 iteration 0 with loss 0.15763897\n","Training at Epoch 946 iteration 0 with loss 0.21213189\n","Training at Epoch 947 iteration 0 with loss 0.16300371\n","Training at Epoch 948 iteration 0 with loss 0.1589787\n","Training at Epoch 949 iteration 0 with loss 0.2115011\n","Training at Epoch 950 iteration 0 with loss 0.17202628\n","Training at Epoch 951 iteration 0 with loss 0.20658989\n","Training at Epoch 952 iteration 0 with loss 0.1732353\n","Training at Epoch 953 iteration 0 with loss 0.23082657\n","Training at Epoch 954 iteration 0 with loss 0.20146176\n","Training at Epoch 955 iteration 0 with loss 0.19065383\n","Training at Epoch 956 iteration 0 with loss 0.14360183\n","Training at Epoch 957 iteration 0 with loss 0.1638173\n","Training at Epoch 958 iteration 0 with loss 0.18525365\n","Training at Epoch 959 iteration 0 with loss 0.1983771\n","Training at Epoch 960 iteration 0 with loss 0.16111133\n","Training at Epoch 961 iteration 0 with loss 0.15684244\n","Training at Epoch 962 iteration 0 with loss 0.2003664\n","Training at Epoch 963 iteration 0 with loss 0.15397775\n","Training at Epoch 964 iteration 0 with loss 0.22364339\n","Training at Epoch 965 iteration 0 with loss 0.19029066\n","Training at Epoch 966 iteration 0 with loss 0.1643325\n","Training at Epoch 967 iteration 0 with loss 0.19134824\n","Training at Epoch 968 iteration 0 with loss 0.16885091\n","Training at Epoch 969 iteration 0 with loss 0.163621\n","Training at Epoch 970 iteration 0 with loss 0.22484672\n","Training at Epoch 971 iteration 0 with loss 0.20269597\n","Training at Epoch 972 iteration 0 with loss 0.15671667\n","Training at Epoch 973 iteration 0 with loss 0.18423909\n","Training at Epoch 974 iteration 0 with loss 0.14552474\n","Training at Epoch 975 iteration 0 with loss 0.14871593\n","Training at Epoch 976 iteration 0 with loss 0.20594802\n","Training at Epoch 977 iteration 0 with loss 0.17523548\n","Training at Epoch 978 iteration 0 with loss 0.14456807\n","Training at Epoch 979 iteration 0 with loss 0.13615231\n","Training at Epoch 980 iteration 0 with loss 0.19085279\n","Training at Epoch 981 iteration 0 with loss 0.14466903\n","Training at Epoch 982 iteration 0 with loss 0.16835332\n","Training at Epoch 983 iteration 0 with loss 0.22574838\n","Training at Epoch 984 iteration 0 with loss 0.15631583\n","Training at Epoch 985 iteration 0 with loss 0.19930834\n","Training at Epoch 986 iteration 0 with loss 0.17441264\n","Training at Epoch 987 iteration 0 with loss 0.16266116\n","Training at Epoch 988 iteration 0 with loss 0.17170238\n","Training at Epoch 989 iteration 0 with loss 0.19169638\n","Training at Epoch 990 iteration 0 with loss 0.16173494\n","Training at Epoch 991 iteration 0 with loss 0.12745658\n","Training at Epoch 992 iteration 0 with loss 0.16734934\n","Training at Epoch 993 iteration 0 with loss 0.16726689\n","Training at Epoch 994 iteration 0 with loss 0.16345707\n","Training at Epoch 995 iteration 0 with loss 0.15992647\n","Training at Epoch 996 iteration 0 with loss 0.16656207\n","Training at Epoch 997 iteration 0 with loss 0.18180262\n","Training at Epoch 998 iteration 0 with loss 0.20576178\n","Training at Epoch 999 iteration 0 with loss 0.2012822\n","Training at Epoch 1000 iteration 0 with loss 0.17568251\n"]}]},{"cell_type":"code","source":["#@title training loss plot\n","loss_history =[ loss.detach().numpy() for loss in loss_history]\n","lh = list(filter(lambda x: x < 1, loss_history))\n","plt.plot(lh)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"3rOX0gY6Q3vC","outputId":"2633c476-c04d-44e2-8c58-11137aea89da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7febd6845410>]"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#@title validation loss\n","print('--- Data preparation ---')\n","df_val = pd.read_pickle(dataFolder + '/val_loc0.pkl')[2000:2200]\n","validation_set = BIN_Data_Encoder(np.array([i for i in range(df_val.shape[0])]), df_val.label.values, df_val, max_d, max_p)\n","validation_generator = data.DataLoader(validation_set, **params)\n","\n","print('--- Go for validation ---')\n","try:\n","    with torch.set_grad_enabled(False):\n","        auc, auprc, f1, logits, loss = test(validation_generator, model, use_cuda)\n","        print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Test loss: '+str(loss))\n","except:\n","    print('testing failed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQsBuksD-Xv6","outputId":"a1824cf1-c903-43f4-a37a-660123463182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Data preparation ---\n","--- Go for validation ---\n","optimal threshold: 2.55142236227357e-08\n","AUROC:0.48966376089663755\n","AUPRC: 0.41557115475169115\n","Confusion Matrix : \n"," [[ 2 71]\n"," [ 0 55]]\n","Recall :  1.0\n","Precision :  0.4365079365079365\n","Accuracy :  0.4453125\n","Sensitivity :  0.0273972602739726\n","Specificity :  1.0\n","Testing AUROC: 0.48966376089663755 , AUPRC: 0.41557115475169115 , F1: 0.38461538461538464 , Test loss: 2.7558815479278564\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWPwwfnNis-k","colab":{"base_uri":"https://localhost:8080/","height":694},"outputId":"731e1886-7e60-412a-a393-9055968f6099","executionInfo":{"status":"error","timestamp":1647394613947,"user_tz":420,"elapsed":475,"user":{"displayName":"cong liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05614906434306765320"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["learning rate: 0.01\n","batch size: 64\n","training epoch: 1000\n","accumulation steps: 5\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-59fa34e5e07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#biosnap interaction times 1e-6, flat, batch size 64, len 205, channel 3, epoch 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9e20f1e3e88e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(use_cuda)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mloss_history_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBIN_Interaction_Flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Proj4_DPI/scripts/model3_TransDTI/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         self.decoder = nn.Sequential(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BIN_Interaction_Flat' object has no attribute 'flatten_dim'"]}],"source":[""]},{"cell_type":"code","source":["10000/128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrslgToT3b9E","outputId":"d5eb93bf-c45a-471d-fe41-184859bacc60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78.125"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#@title training loss plot\n","plt.rcParams['figure.figsize'] = [10,5]\n","fig,(ax1,ax2) = plt.subplots(1,2)\n","fig.suptitle(\"lr:5e-5;batch_size:128*78,train_size:10000\",fontsize=16)\n","loss_train =[ loss.cpu().detach().numpy() for loss in loss_history]\n","\n","\n","lh = list(filter(lambda x: x < 1, loss_train))\n","lh = [lh[i] for i in list(range(0,len(lh),78))]\n","# lh = list(filter(lambda x: x < 1, loss_val))\n","ax1.plot(lh)\n","ax1.set_title('train loss')\n","ax2.plot(loss_val,color='tab:orange')\n","ax2.set_title('val loss')\n"],"metadata":{"id":"MRdg2Oq0f5IQ","colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"b234ab59-a3d0-457c-ac67-b621a3ee9448"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'val loss')"]},"metadata":{},"execution_count":5},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#@title validation loss plot\n","# loss_history_val =[ loss.cpu().detach().numpy() for loss in loss_history_val]\n","# loss_history_val =[ loss.cpu().detach().numpy() for loss in loss_history_val]\n","lh = list(filter(lambda x: x < 1, loss_history_val))\n","plt.plot(lh)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"id":"NykUsDt0jZ6s","outputId":"9467d90e-bcea-4b3a-cae1-9b5785fe67f0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1dba19168d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# loss_history_val =[ loss.cpu().detach().numpy() for loss in loss_history_val]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss_history_val =[ loss.cpu().detach().numpy() for loss in loss_history_val]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'loss_history_val' is not defined"]}]},{"cell_type":"code","source":["#@title define torchtest functions\n","# !pip install --upgrade torchtest\n","# install from source because I need to make some changes to the source code\n","# %%bash\n","# git clone https://github.com/suriyadeepan/torchtest.git --quiet\n","class VariablesChangeException(Exception):\n","  pass\n","def assert_vars_change(model, loss_fn, optim, batch, device, params=None):\n","  \"\"\"Make sure that the given parameters (params) DO change during training\n","  If parameters (params) aren't provided, check all parameters.\n","  Parameters\n","  ----------\n","  model : torch.nn.Module\n","    torch model, an instance of torch.nn.Module\n","  loss_fn : function\n","    a loss function from torch.nn.functional \n","  optim : torch.optim.Optimizer\n","    an optimizer instance\n","  batch : list\n","    a 2 element list of inputs and labels, to be fed to the model\n","  params : list, optional\n","    list of parameters of form (name, variable)\n","  Raises\n","  ------\n","  VariablesChangeException\n","    If params do not change during training\n","  \"\"\"\n","\n","  _var_change_helper(True, model, loss_fn, optim, batch, device, params)\n","\n","def _var_change_helper(vars_change, model, loss_fn, optim, batch, device, params=None): \n","  \"\"\"Check if given variables (params) change or not during training\n","  If parameters (params) aren't provided, check all parameters.\n","  Parameters\n","  ----------\n","  vars_change : bool\n","    a flag which controls the check for change or not change\n","  model : torch.nn.Module\n","    torch model, an instance of torch.nn.Module\n","  loss_fn : function\n","    a loss function from torch.nn.functional \n","  optim : torch.optim.Optimizer\n","    an optimizer instance\n","  batch : list\n","    a 2 ele## ment list of inputs and labels, to be fed to the model\n","  params : list, optional\n","    list of parameters of form (name, variable)\n","  Raises\n","  ------\n","  VariablesChangeException\n","    if vars_change is True and params DO NOT change during training\n","    if vars_change is False and params DO change during training\n","  \"\"\"\n","\n","  if params is None:\n","    # get a list of params that are allowed to change\n","    params = [ np for np in model.named_parameters() if np[1].requires_grad ]\n","\n","  # take a copy\n","  initial_params = [ (name, p.clone()) for (name, p) in params ]\n","\n","  # run a training step\n","  _train_step(model, loss_fn, optim, batch, device)\n","\n","  # check if variables have changed\n","  for (_, p0), (name, p1) in zip(initial_params, params):\n","    try:\n","      if vars_change:\n","        assert not torch.equal(p0.to(device), p1.to(device))\n","      else:\n","        assert torch.equal(p0.to(device), p1.to(device))\n","    except AssertionError:\n","      raise VariablesChangeException( # error message\n","          \"{var_name} {msg}\".format(\n","            var_name=name, \n","            msg='did not change!' if vars_change else 'changed!' \n","            )\n","          )\n","\n","def _train_step(model, loss_fn, optim, batch, device):\n","  \"\"\"Run a training step on model for a given batch of data\n","  Parameters of the model accumulate gradients and the optimizer performs\n","  a gradient update on the parameters\n","  Parameters\n","  ----------\n","  model : torch.nn.Module\n","    torch model, an instance of torch.nn.Module\n","  loss_fn : function\n","    a loss function from torch.nn.functional \n","  optim : torch.optim.Optimizer\n","    an optimizer instance\n","  batch : list\n","    a 2 element list of inputs and labels, to be fed to the model\n","  \"\"\"\n","\n","  # put model in train mode\n","  model.train()\n","  model.to(device)\n","\n","  #  run one forward + backward step\n","  # clear gradient\n","  optim.zero_grad()\n","  # inputs and targets\n","  inputs_d, inputs_p, targets = batch[0], batch[1], batch[2]\n","  # move data to DEVICE\n","  inputs_d = inputs_d.to(device)\n","  inputs_p = inputs_p.to(device)\n","  targets = targets.to(device)\n","  # targets = targets.unsqueeze(1)\n","  targets = Variable(torch.from_numpy(np.array(targets)).float())\n","  # forward\n","  likelihood = model(inputs_d, inputs_p)\n","  m = torch.nn.Sigmoid()\n","  likelihood = torch.squeeze(m(likelihood))\n","  print(likelihood)\n","  # calc loss\n","  loss = loss_fn(likelihood, targets)\n","  # backward\n","  loss.backward()\n","  # optimization step\n","  optim.step()"],"metadata":{"id":"zi-Myq9laEll","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title unit testing to check if the variables change\n","# from torchtest.torchtest.torchtest import assert_vars_change\n","config = BIN_config_DBPE()\n","\n","lr = 5e-6\n","BATCH_SIZE = config['batch_size']\n","train_epoch = 20\n","max_d = config['max_dna_seq']\n","max_p = config['max_protein_seq']\n","\n","loss_history = []\n","\n","model = BIN_Interaction_Flat(**config)\n","\n","if use_cuda:\n","  model = model.cuda()\n","\n","if torch.cuda.device_count() > 1:\n","  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","  model = nn.DataParallel(model, dim = 0)\n","elif torch.cuda.device_count() < 1:\n","  print(\"Let's use cpu!\")\n","\n","opt = torch.optim.Adam(model.parameters(), lr = lr)\n","#opt = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n","\n","print('--- Data Preparation ---')\n","\n","params = {'batch_size': BATCH_SIZE,\n","  'shuffle': True,\n","  'num_workers': 6, \n","  'drop_last': True}\n","\n","dataFolder = '/content/drive/MyDrive/Proj4_DPI/data/data_with_embedding/'\n","df_train = pd.read_pickle(dataFolder + '/test_loc0.pkl')\n","df_train = df_train[1:1000]\n","training_set = BIN_Data_Encoder(np.array([i for i in range(df_train.shape[0])]), df_train.label.values, df_train, max_d, max_p)\n","training_generator = data.DataLoader(training_set, **params)\n","loss_fct = torch.nn.BCELoss()\n","\n","# check if variables change\n","assert_vars_change(\n","    model=model,\n","    loss_fn=loss_fct,\n","    optim=opt,\n","    batch=next(iter(training_generator)),\n","    device = \"cpu\")\n","## the result shows that variables do change, which is normal"],"metadata":{"id":"1JDQzVQW2bMa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8cb4e06-43ff-41e3-ca74-29e2b52acba3","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Let's use cpu!\n","--- Data Preparation ---\n","tensor([0.4965, 0.5717, 0.5185, 0.4198, 0.4027, 0.4152, 0.5024, 0.5175, 0.4390,\n","        0.4893, 0.4631, 0.4672, 0.4725, 0.6192, 0.4745, 0.5834, 0.5142, 0.4815,\n","        0.5840, 0.4610, 0.5377, 0.4646, 0.5225, 0.4946, 0.5003, 0.5481, 0.4732,\n","        0.4424, 0.5784, 0.5626, 0.5347, 0.5471, 0.4890, 0.4901, 0.4970, 0.5333,\n","        0.4829, 0.5130, 0.4591, 0.4018, 0.4699, 0.5625, 0.5158, 0.5083, 0.5193,\n","        0.5327, 0.4991, 0.5059, 0.4984, 0.5503, 0.3966, 0.5136, 0.3932, 0.4666,\n","        0.4188, 0.4501, 0.4586, 0.4803, 0.4674, 0.4960, 0.5039, 0.4941, 0.5242,\n","        0.4039], grad_fn=<SqueezeBackward0>)\n"]}]},{"cell_type":"code","source":["# max(1,torch.cuda.device_count())\n","# d = main(1,5e-6, use_cuda)\n","# device\n","# batch=next(iter(training_generator))\n","# len(batch[0])\n","# batch[2]\n","# params = [ np for np in model.named_parameters() if np[1].requires_grad ]\n","# initial_params = [ (name, p.clone()) for (name, p) in params ]\n","initial_params"],"metadata":{"id":"0gognPLspBsy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be1d1d05-2fec-4470-e047-d03309c3b165"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('demb.transform.weight',\n","  tensor([[-0.0291, -0.0007,  0.0073,  ...,  0.0035,  0.0324,  0.0176],\n","          [-0.0296,  0.0276, -0.0271,  ...,  0.0228, -0.0101, -0.0187],\n","          [-0.0299,  0.0059, -0.0350,  ..., -0.0058, -0.0274, -0.0069],\n","          ...,\n","          [-0.0303, -0.0323, -0.0282,  ...,  0.0208,  0.0121,  0.0334],\n","          [ 0.0088,  0.0084,  0.0330,  ..., -0.0084,  0.0066, -0.0153],\n","          [ 0.0355, -0.0330, -0.0098,  ...,  0.0009, -0.0322,  0.0230]],\n","         grad_fn=<CloneBackward0>)),\n"," ('demb.transform.bias',\n","  tensor([ 6.3124e-03, -2.1090e-02, -3.3061e-03,  3.5418e-02, -2.7279e-02,\n","          -1.7519e-02, -2.5768e-02,  1.9395e-02,  2.3362e-02, -1.3061e-02,\n","           1.6543e-02, -1.6530e-02,  1.5928e-03, -1.8415e-02, -2.3893e-02,\n","           5.5419e-03, -2.5598e-02,  3.4201e-02, -2.3198e-02, -3.5226e-03,\n","          -2.5163e-02,  3.0936e-02, -2.6849e-02, -1.6872e-02,  2.5944e-02,\n","          -1.0825e-02,  6.8592e-03,  4.1332e-03, -3.3762e-02,  7.3368e-05,\n","           2.5649e-02,  2.9539e-02,  3.2892e-02, -2.6190e-02, -1.3207e-03,\n","           3.3720e-02, -3.0275e-02, -1.4516e-02, -2.1406e-02,  5.6274e-03,\n","           2.2696e-02, -1.7433e-02,  1.9395e-02,  5.0790e-03, -3.2087e-02,\n","           3.6769e-03, -3.4680e-02,  7.0001e-03,  7.3773e-03, -1.4339e-03,\n","           1.4256e-02, -2.4376e-02, -1.9513e-02, -5.9414e-03,  1.0852e-02,\n","          -9.3101e-04,  7.6986e-03,  3.2816e-02, -3.3921e-02, -2.1739e-02,\n","          -3.0794e-02, -5.7012e-03, -2.2454e-02, -1.0313e-02,  6.8893e-03,\n","           1.7082e-02, -1.7225e-02, -1.2761e-02,  2.3263e-02,  3.0416e-02,\n","          -3.5326e-02, -1.9002e-02, -1.7329e-02,  1.9594e-02,  6.2101e-03,\n","          -1.2744e-02, -2.3362e-02,  3.2231e-02, -2.4981e-02,  8.2867e-03,\n","           1.5779e-02,  2.2837e-03,  1.3102e-02, -1.6954e-03, -2.3874e-02,\n","           2.3925e-02, -1.1148e-02,  4.4995e-03, -8.2312e-04,  2.1595e-02,\n","           2.1122e-02,  2.2820e-02, -6.4231e-04,  1.8333e-02, -3.5067e-02,\n","          -1.9703e-03, -1.5287e-02,  2.0237e-02,  9.6030e-03,  4.9014e-03,\n","           4.9633e-03,  4.2260e-03, -2.2559e-02, -2.9638e-02,  2.8511e-02,\n","           2.6679e-02, -1.3334e-02, -2.2123e-03, -2.6631e-02,  1.8361e-02,\n","           2.1506e-02, -1.9064e-02, -3.0084e-02, -7.7337e-04,  3.2192e-02,\n","           1.9299e-02, -1.0855e-02, -7.1074e-03,  1.2656e-03, -1.3447e-02,\n","          -2.1583e-02, -2.4789e-02,  1.1591e-02, -1.3410e-02, -2.2660e-02,\n","          -9.3651e-03,  3.1388e-02,  4.3734e-03, -1.1837e-02, -1.0508e-03,\n","           1.6414e-02,  2.7452e-02,  2.1215e-03, -2.1377e-02, -8.8744e-03,\n","          -6.4687e-03,  3.4798e-02, -3.5390e-02, -3.1560e-02, -3.6023e-03,\n","          -3.3309e-02,  3.1960e-02,  1.8272e-02,  1.0102e-02,  2.8711e-02,\n","          -4.7742e-03,  2.7225e-02,  1.1981e-02,  3.2207e-02,  2.6895e-02,\n","          -9.6373e-03, -2.1826e-02,  1.8836e-02,  2.1492e-02, -1.9149e-02,\n","          -1.0496e-02,  3.2373e-02, -3.1400e-02, -2.9439e-02, -3.3334e-02,\n","          -3.1437e-02,  1.3194e-02, -2.4079e-02,  2.1365e-03, -3.1012e-03,\n","          -8.0280e-03,  2.2422e-02, -1.3198e-02, -2.8613e-02,  2.8951e-02,\n","          -1.7287e-02, -3.0402e-02, -2.8531e-02, -1.7960e-02,  2.9935e-02,\n","          -2.8102e-02,  8.4776e-03, -2.1887e-03, -1.4361e-02, -2.5633e-02,\n","           2.1604e-03,  1.2843e-02,  9.6412e-03, -1.6360e-02, -2.8046e-02,\n","           1.5865e-02,  2.3055e-02,  5.2845e-04,  1.1966e-02,  1.9433e-02,\n","          -2.8794e-02, -1.7516e-02, -6.1360e-03,  2.7544e-02,  3.0691e-02,\n","          -3.5250e-03,  2.1898e-02,  2.2690e-02, -1.7559e-02,  1.5952e-02,\n","           6.3097e-03, -3.3129e-02,  5.8927e-04, -3.1839e-02,  7.1325e-03,\n","           1.4546e-02,  2.9511e-02,  1.2374e-02, -3.7275e-03, -3.1583e-02,\n","           2.7692e-02, -5.5671e-03,  6.4247e-03,  3.2799e-02, -1.8087e-02,\n","          -1.8629e-02,  2.8339e-02,  2.6222e-02, -3.5840e-04, -1.6023e-02,\n","           2.6022e-02,  1.0458e-03,  3.1829e-02,  1.9135e-03,  2.4581e-02,\n","          -2.4153e-02, -1.2190e-02, -1.1957e-02, -1.7485e-02, -3.2824e-02,\n","           2.8675e-02,  1.7909e-03, -3.5251e-02,  6.5098e-03,  1.3407e-02,\n","          -5.9059e-03, -3.2718e-02, -1.5883e-02,  1.2175e-02, -1.4488e-02,\n","           4.6844e-04,  8.4443e-03,  2.5035e-02, -3.1982e-02, -2.2391e-02,\n","           3.5400e-02, -2.7542e-02, -4.5590e-03, -9.8598e-03, -2.8180e-02,\n","          -4.1751e-03,  3.2945e-02,  1.4797e-02, -1.2721e-02, -3.3437e-02,\n","           1.2094e-02, -1.3128e-02,  3.3091e-03,  2.6223e-02, -8.0503e-03,\n","          -6.5795e-03,  6.5999e-03, -1.6834e-02,  3.6019e-02,  5.3499e-04,\n","           2.7222e-02, -1.6258e-02,  2.3612e-03, -3.5811e-02,  1.9545e-02,\n","          -5.8111e-04,  4.4201e-03,  4.2873e-03, -3.7700e-03, -6.5503e-03,\n","           3.5225e-03, -3.6228e-03, -2.4381e-02, -3.2984e-02, -2.4605e-02,\n","           3.1677e-04,  2.1706e-02, -3.0232e-02, -1.1783e-03,  5.9512e-03,\n","          -2.2468e-02,  2.2397e-02, -2.0463e-02,  4.3183e-03,  3.0770e-02,\n","          -2.3446e-02, -6.1035e-03, -3.2825e-02,  2.8629e-02, -3.4032e-02,\n","           1.0603e-02,  5.1347e-04, -1.1964e-02,  1.0119e-02, -4.7460e-03,\n","          -2.7914e-02,  9.4473e-03, -3.4523e-03,  1.0197e-02, -2.9785e-02,\n","          -3.3448e-02,  4.6281e-03, -9.8175e-03,  2.6166e-03,  3.0435e-02,\n","          -3.4586e-02, -2.6261e-02, -5.1335e-03, -1.9149e-02,  2.5652e-02,\n","           3.5568e-02,  2.5232e-02,  1.9493e-03,  1.2530e-02,  2.0096e-02,\n","           2.9676e-02, -4.1658e-04,  2.3907e-02, -3.3005e-02, -2.9888e-02,\n","           3.5416e-02,  1.9133e-02,  1.4410e-02,  8.2380e-03,  4.3302e-03,\n","          -1.1875e-02, -1.0074e-02,  2.1284e-02, -1.8286e-02,  3.1384e-02,\n","           4.5948e-03, -2.3433e-02,  1.3715e-02,  3.0976e-02, -8.1110e-03,\n","          -4.3066e-03,  2.5296e-02, -6.6208e-03, -2.7132e-02, -2.3425e-04,\n","          -1.6887e-02, -2.7003e-02, -1.1395e-02,  7.4412e-03, -2.6565e-02,\n","           3.2770e-02, -2.3477e-02,  8.6977e-03, -3.0002e-02, -1.6475e-02,\n","          -2.0695e-02, -2.5032e-02, -1.3348e-02,  2.2826e-02, -1.5569e-02,\n","           9.8352e-03,  1.2400e-02, -9.9403e-03,  8.3881e-03,  3.5699e-02,\n","          -7.2791e-03,  2.4389e-02,  1.0963e-02,  3.0489e-02, -1.3712e-03,\n","           2.3939e-02,  1.6409e-02, -9.6309e-03,  2.1918e-02, -6.3895e-03,\n","           8.7155e-03,  2.0114e-02, -2.3478e-02, -1.8804e-02,  9.2262e-03,\n","           1.7511e-02,  1.9958e-02, -8.7230e-03,  3.1104e-02],\n","         grad_fn=<CloneBackward0>)),\n"," ('pemb.transform.weight',\n","  tensor([[-0.0147, -0.0320, -0.0248,  ...,  0.0176, -0.0153,  0.0415],\n","          [ 0.0449,  0.0457, -0.0085,  ...,  0.0096, -0.0465, -0.0144],\n","          [-0.0263,  0.0169,  0.0198,  ...,  0.0094,  0.0368, -0.0262],\n","          ...,\n","          [-0.0312, -0.0220,  0.0183,  ..., -0.0013, -0.0509, -0.0072],\n","          [ 0.0188,  0.0502,  0.0329,  ..., -0.0215, -0.0139,  0.0025],\n","          [-0.0327,  0.0256,  0.0494,  ..., -0.0218,  0.0257,  0.0285]],\n","         grad_fn=<CloneBackward0>)),\n"," ('pemb.transform.bias',\n","  tensor([-3.7838e-02, -2.6734e-02, -4.3361e-02, -4.5761e-03,  2.4372e-02,\n","          -3.5161e-03, -4.6353e-03, -3.2482e-02,  2.9539e-02,  4.0033e-02,\n","           1.8933e-02, -1.6220e-02, -9.2589e-03,  2.9307e-02, -7.2223e-03,\n","          -3.2916e-02, -3.9697e-02,  4.3907e-02,  3.5324e-03, -4.3403e-02,\n","           5.0949e-02,  2.8571e-02, -2.4810e-02,  3.0963e-02,  3.6464e-02,\n","           3.5756e-02,  3.5913e-02,  1.4308e-03,  5.6752e-03,  1.4960e-02,\n","          -2.4428e-02,  4.8196e-02, -3.6168e-02, -2.9051e-02, -2.9020e-02,\n","           4.9387e-02, -2.9085e-02,  4.5698e-02, -2.1033e-02, -2.5748e-02,\n","           1.5973e-02,  1.0679e-03, -3.0243e-02, -1.5397e-02,  3.8436e-02,\n","           1.1049e-02,  7.0515e-03,  4.5778e-02, -3.0930e-02, -2.9248e-02,\n","          -1.3812e-02, -1.1710e-02,  2.3237e-02,  2.8300e-02, -3.3736e-02,\n","           1.5924e-02, -4.8863e-02,  3.7879e-02, -2.5347e-02,  5.0159e-03,\n","          -1.6790e-03,  6.3996e-03,  3.4124e-02,  2.5899e-02, -1.2184e-02,\n","           4.6445e-03,  4.0063e-02,  3.1749e-03, -1.9140e-02,  3.3600e-02,\n","          -1.3528e-02,  1.7306e-02,  2.1078e-02, -3.5605e-02, -3.0934e-02,\n","           4.7832e-03,  4.4417e-02,  1.5826e-03, -2.8907e-02, -4.1057e-02,\n","          -1.4908e-02, -3.1549e-02, -4.6525e-03,  7.2873e-03,  1.5438e-02,\n","          -4.5716e-02,  3.7292e-02,  9.7593e-03,  3.4166e-02, -4.1701e-02,\n","          -3.1760e-02, -1.5359e-02,  1.2758e-02, -1.5681e-02,  5.0443e-02,\n","          -3.1893e-02, -1.7781e-02, -1.2218e-02, -4.1178e-02, -3.1597e-02,\n","          -2.3225e-02,  4.4716e-02,  2.6013e-02, -1.8959e-02, -4.4198e-02,\n","           7.7230e-03, -2.4264e-02,  1.6146e-02,  1.2971e-02,  2.0674e-02,\n","           1.8654e-02, -3.5995e-02,  2.8019e-02,  2.5435e-03,  1.6080e-02,\n","           4.0602e-02, -1.5390e-02, -2.8338e-02,  1.4218e-02, -4.1044e-02,\n","           2.1085e-02, -3.2568e-02, -4.4763e-02,  4.1457e-02,  5.0053e-02,\n","          -3.6418e-02,  6.6425e-03, -3.7704e-02,  3.0698e-02, -6.5763e-03,\n","           3.1486e-02,  4.7624e-02, -4.6849e-02,  1.9708e-02,  4.6573e-02,\n","          -1.9738e-02,  4.3782e-02, -2.8340e-02, -6.9263e-03, -2.3981e-02,\n","           1.5985e-02,  2.3566e-02, -3.4431e-02, -7.6945e-04,  2.4921e-02,\n","           2.8845e-02,  1.3534e-02, -3.7189e-02,  1.0299e-03,  1.3253e-02,\n","          -1.9823e-02,  1.0741e-02, -3.3121e-02,  2.8880e-02,  1.3763e-02,\n","           3.6123e-02, -2.4143e-02, -2.4031e-02, -2.8671e-02,  4.1028e-02,\n","          -2.1624e-02,  6.3572e-03, -2.5924e-02, -4.3253e-04, -5.2533e-03,\n","          -1.0076e-02,  4.6769e-02,  3.0598e-02, -1.7269e-02,  3.5158e-02,\n","           5.4433e-03, -1.2255e-02, -1.2719e-02,  3.7198e-02, -2.5879e-02,\n","          -5.0345e-02, -4.3055e-02,  4.7366e-02, -3.8909e-02, -2.9246e-02,\n","          -4.2607e-02,  2.2820e-02,  1.4845e-02, -4.5159e-02,  3.5293e-02,\n","          -4.0545e-02, -3.9794e-02,  1.9998e-02, -3.4029e-02,  4.4966e-02,\n","           3.0796e-02, -4.9206e-02,  3.9200e-02, -2.4509e-02, -2.6780e-02,\n","           4.4902e-02, -1.1292e-02,  3.2161e-03, -5.0432e-02,  1.1689e-02,\n","           2.1578e-02,  2.3594e-02,  2.2572e-03, -3.4168e-02, -3.3459e-02,\n","          -1.8301e-02,  2.6109e-02, -4.2044e-02,  2.0416e-02, -1.6824e-02,\n","          -1.6936e-02,  4.0836e-02,  3.7610e-02, -9.3149e-03, -4.3397e-02,\n","           1.8713e-02, -3.6635e-02, -2.1558e-02,  3.7437e-02, -3.7701e-02,\n","          -2.9518e-03, -9.2358e-03, -2.2906e-02, -5.1794e-03, -3.4113e-02,\n","           1.5405e-02, -3.0982e-02, -4.8315e-02,  2.4512e-02,  4.7269e-02,\n","           1.2129e-02, -3.1155e-02,  3.4740e-02, -3.4787e-02,  2.0921e-02,\n","          -3.0042e-02,  5.0598e-02, -4.7718e-02,  2.9993e-02,  4.8271e-02,\n","           3.8708e-03,  4.1066e-03, -1.4905e-02, -3.8583e-02, -3.8276e-02,\n","          -2.1506e-02,  2.5047e-02,  1.8495e-02, -1.7718e-03,  4.7631e-02,\n","           2.0205e-02, -8.5304e-03,  3.5412e-02,  7.7650e-03, -3.6471e-02,\n","          -2.3963e-02,  3.9442e-02,  2.0573e-02,  4.3859e-02,  2.8618e-02,\n","           2.5440e-02, -1.2139e-02, -3.1394e-02, -4.5480e-02, -2.5673e-02,\n","          -4.4677e-02,  3.1678e-02,  2.2240e-02,  4.1957e-02,  2.6327e-02,\n","          -3.5503e-02, -2.1456e-02,  3.8554e-02,  3.5597e-02, -1.6475e-02,\n","          -2.8060e-02, -3.8332e-02,  1.5063e-02,  1.9569e-02,  1.0301e-02,\n","           3.3885e-02, -4.9523e-02,  2.8169e-02,  4.5867e-02, -3.0237e-03,\n","           4.1166e-02, -4.3233e-02, -4.5782e-02, -2.7049e-02, -4.3960e-02,\n","           1.7649e-03, -1.6882e-02, -4.1253e-03, -2.3213e-02, -3.3745e-02,\n","           1.2766e-02,  2.7063e-02,  2.4611e-02,  4.8142e-02, -6.9928e-04,\n","           2.7113e-02,  1.5223e-03, -4.8507e-02, -3.3846e-02, -4.5868e-02,\n","           8.4918e-05, -4.7140e-02, -4.2807e-02, -4.7530e-02, -4.4978e-02,\n","          -2.2216e-03,  1.3799e-03,  4.2266e-02, -1.5893e-02, -9.6176e-03,\n","          -3.9465e-02,  3.3506e-02,  2.4431e-02, -4.7948e-02,  3.4348e-02,\n","           4.5186e-02, -2.5449e-02, -8.5254e-03,  4.9751e-02, -4.7512e-02,\n","          -1.0239e-02, -2.3903e-02, -2.2129e-02, -2.1726e-02, -1.6833e-02,\n","           2.8601e-02, -2.5267e-02, -3.6975e-02,  5.0944e-02, -3.3394e-02,\n","           1.3187e-02, -2.6037e-02, -3.1890e-02,  1.9586e-02,  1.7725e-02,\n","           3.3291e-02,  5.9371e-03,  3.4526e-02, -2.0438e-02,  4.1379e-02,\n","           2.4979e-02, -2.4759e-02,  8.1600e-03, -3.3228e-02,  9.9733e-03,\n","          -7.2837e-03, -3.5262e-02,  4.7960e-02, -2.0798e-02,  3.1715e-02,\n","          -2.4102e-03,  3.9445e-02, -3.7014e-02,  1.2425e-02,  2.7648e-02,\n","          -3.9410e-02,  1.7279e-02,  1.0239e-02, -1.6674e-02, -4.5393e-02,\n","          -4.9759e-02, -2.6384e-02,  2.1058e-02,  6.2272e-03, -2.5833e-02,\n","          -2.6430e-02, -1.8880e-02,  1.5411e-02,  3.6460e-02, -4.9110e-02,\n","           4.2861e-02, -4.7204e-02,  2.2671e-02,  1.9528e-02, -7.7754e-03,\n","           2.4315e-02, -8.5345e-03,  2.9085e-02, -2.5577e-02],\n","         grad_fn=<CloneBackward0>)),\n"," ('icnn.weight', tensor([[[[ 0.0356, -0.0858,  0.2018],\n","            [ 0.3278,  0.0957,  0.1243],\n","            [ 0.0780, -0.0642, -0.2691]]],\n","  \n","  \n","          [[[-0.2756,  0.2583, -0.2350],\n","            [-0.1715, -0.2810, -0.0578],\n","            [-0.2272, -0.0091,  0.1580]]],\n","  \n","  \n","          [[[ 0.3033,  0.0369,  0.0857],\n","            [ 0.0191,  0.2534,  0.1525],\n","            [-0.2666, -0.2873,  0.3236]]]], grad_fn=<CloneBackward0>)),\n"," ('icnn.bias', tensor([-0.2507, -0.1639, -0.2719], grad_fn=<CloneBackward0>)),\n"," ('decoder.0.weight',\n","  tensor([[-0.0014, -0.0036,  0.0023,  ...,  0.0007, -0.0052,  0.0055],\n","          [-0.0058,  0.0030,  0.0014,  ...,  0.0060, -0.0058, -0.0002],\n","          [ 0.0053,  0.0007,  0.0027,  ..., -0.0040, -0.0018,  0.0028],\n","          ...,\n","          [ 0.0037, -0.0002, -0.0013,  ..., -0.0026, -0.0048,  0.0045],\n","          [-0.0062, -0.0037, -0.0009,  ..., -0.0045,  0.0011, -0.0017],\n","          [ 0.0008,  0.0013,  0.0008,  ...,  0.0059,  0.0003,  0.0046]],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.0.bias',\n","  tensor([-1.1956e-03, -2.4188e-03,  2.2170e-03, -3.8840e-03, -5.7071e-04,\n","           2.6838e-03, -4.8057e-03, -1.3150e-03,  1.5247e-03, -4.4275e-03,\n","           5.6030e-03,  1.2796e-03, -2.3675e-03,  2.3383e-03,  5.7270e-03,\n","           5.5932e-03,  8.4249e-04,  5.9510e-03, -3.8625e-04,  8.0824e-04,\n","          -6.1205e-03, -4.4753e-03, -8.3658e-04,  2.8480e-03,  3.6011e-03,\n","           9.6995e-04, -1.1797e-03, -4.5796e-03,  3.3469e-03,  5.9861e-03,\n","           3.0579e-03, -1.9635e-03,  2.6450e-03,  3.2874e-03,  2.3495e-03,\n","          -7.5351e-04, -2.4072e-03,  2.0689e-03,  2.9676e-03, -1.8471e-04,\n","          -3.1856e-03,  5.3974e-03, -4.8636e-03,  5.2950e-03, -4.8738e-03,\n","          -6.0356e-03,  2.4245e-03,  1.2888e-04, -2.4718e-03,  2.9815e-03,\n","          -5.2524e-04, -5.3737e-04,  1.7014e-03, -1.9874e-03, -4.1417e-03,\n","           2.4828e-04, -1.5100e-03,  1.0767e-04, -2.0268e-03, -4.6262e-03,\n","          -4.2786e-03,  6.0714e-03, -2.9616e-04, -2.2523e-03, -3.0326e-03,\n","           1.7836e-03,  7.9461e-05, -3.2728e-04,  4.5689e-03, -1.1891e-03,\n","           6.5138e-04, -7.0988e-04, -4.0852e-03,  8.3155e-04, -4.2011e-04,\n","           3.7786e-03, -1.4475e-03, -1.5798e-03, -7.1380e-04, -2.5935e-03,\n","          -1.2273e-03,  3.9651e-03, -2.5879e-03, -3.3388e-03, -3.0774e-03,\n","           3.2479e-03, -4.3421e-04, -1.1238e-03, -1.3049e-03, -5.6870e-03,\n","           1.3242e-03, -5.4670e-03,  4.4133e-03,  6.1911e-03,  5.9001e-03,\n","           3.2503e-03,  5.7913e-03, -2.5327e-03,  3.5006e-03, -1.4439e-03,\n","           3.3295e-03, -2.5374e-03, -3.8470e-03,  5.6674e-03,  5.8820e-04,\n","           3.1765e-03, -2.4419e-03,  4.6532e-03,  6.6874e-04, -5.9030e-03,\n","           9.4779e-04, -2.8184e-03, -4.8476e-03,  4.4083e-03,  8.8319e-04,\n","          -5.0406e-03,  5.3699e-03,  5.5571e-03, -8.4854e-04,  2.5274e-03,\n","           5.9435e-03,  4.4845e-03, -4.4668e-03, -2.4337e-03, -2.2513e-03,\n","          -2.1971e-03,  2.9338e-04, -1.0209e-03,  9.8231e-04,  1.6523e-03,\n","           2.0652e-03, -4.2956e-03,  4.5429e-03, -1.1652e-03, -4.6696e-03,\n","          -5.4231e-03,  9.8441e-04,  2.6797e-03, -2.1735e-03,  3.0017e-03,\n","           5.6354e-03, -5.4616e-03,  2.2743e-03,  6.1593e-03, -6.1141e-03,\n","          -6.7700e-04,  2.8167e-03, -5.6800e-03, -6.0175e-03, -3.1233e-03,\n","          -2.3674e-03, -1.1261e-04, -5.2294e-03,  5.2523e-03, -2.4914e-03,\n","           2.8789e-04, -5.0055e-03, -4.3960e-03, -3.7929e-03, -5.9402e-03,\n","           9.8440e-04, -9.4920e-04, -9.2724e-04, -5.3980e-03, -4.0199e-03,\n","           3.8444e-03,  5.6327e-03,  1.4920e-03,  2.2583e-03,  4.1279e-03,\n","          -2.5830e-03,  2.2510e-03, -3.0373e-03, -1.7600e-03, -5.3390e-03,\n","          -3.5482e-03, -3.1278e-03,  7.8108e-04,  5.0763e-03,  4.1286e-03,\n","           4.4976e-03, -3.4305e-03, -5.9315e-03,  2.0599e-03,  3.6150e-03,\n","           1.0284e-04, -3.7419e-05, -5.8768e-03, -5.5119e-03, -3.5160e-03,\n","           3.9655e-04, -4.3093e-03, -2.5891e-03,  4.0780e-03,  5.5511e-03,\n","          -5.7002e-03,  4.6002e-03,  1.1321e-03, -3.0356e-03, -2.0146e-03,\n","           1.9526e-03, -5.3812e-03, -2.1141e-03, -4.8983e-03,  5.6391e-03,\n","          -3.9870e-03,  4.4910e-03, -5.1208e-03, -9.4252e-04,  3.3652e-03,\n","          -4.8598e-03, -2.5762e-03,  2.9889e-03, -2.6077e-03,  3.3425e-03,\n","          -1.0511e-03,  5.0144e-03, -3.4105e-03, -2.9124e-03, -2.2335e-03,\n","           5.0014e-03,  4.3308e-03,  1.8508e-03,  4.7439e-03, -4.3800e-04,\n","          -1.1669e-03, -5.0621e-03,  2.6525e-03, -3.7409e-03,  2.0205e-03,\n","           2.1350e-03,  3.2367e-03, -3.5666e-03,  6.0153e-03, -4.2923e-03,\n","           4.8692e-03, -1.3391e-03,  2.7839e-03, -4.4284e-03, -6.0622e-03,\n","           3.1987e-03,  4.1454e-03, -3.8715e-03,  2.9941e-03, -5.2656e-03,\n","          -6.3033e-04,  5.6137e-03, -5.9175e-03,  9.7031e-04,  2.5913e-03,\n","           2.2535e-03,  1.1241e-03, -3.2904e-04,  2.5227e-03, -2.2157e-03,\n","           6.1470e-04, -5.6546e-03, -4.2862e-03, -1.3165e-03,  4.6199e-03,\n","           4.7745e-03, -2.6363e-03, -1.2396e-03,  1.0753e-03,  5.3144e-03,\n","           2.2468e-03, -1.2798e-03,  4.9219e-03, -1.7202e-03, -2.4829e-03,\n","           5.7850e-03,  4.3458e-03,  5.6531e-03, -5.4557e-03,  5.0858e-03,\n","           3.9676e-03,  1.1066e-03, -3.6121e-03,  2.2072e-03, -3.1561e-03,\n","          -6.1350e-03, -1.1525e-03, -4.8841e-03, -4.8326e-03, -3.3637e-04,\n","           6.4994e-04,  5.9431e-03,  6.0437e-03, -3.5636e-03,  3.2313e-03,\n","           5.6470e-04,  5.4125e-03,  3.7490e-03,  9.7275e-04, -3.4342e-03,\n","           9.6450e-04, -2.6583e-04, -2.7681e-03, -1.1338e-03, -2.2169e-04,\n","           5.4630e-03, -3.3726e-03, -4.7302e-03,  5.0101e-03, -2.7263e-03,\n","           4.7611e-03,  2.7026e-03,  4.8286e-04,  2.9914e-04, -2.9895e-03,\n","          -6.1013e-03, -3.1547e-03, -1.9561e-03, -3.6946e-03,  6.1301e-03,\n","          -4.3610e-03, -3.2345e-03, -1.0336e-03,  3.0308e-03, -2.3405e-03,\n","          -1.4268e-03, -5.8539e-03,  5.2150e-03, -5.3102e-03,  5.3806e-04,\n","          -5.5420e-04, -2.4335e-03,  5.7581e-03,  4.8992e-03, -3.9538e-03,\n","           2.9087e-03, -7.6169e-04,  4.8485e-03,  4.5614e-03, -5.0102e-04,\n","          -1.3182e-03,  2.1632e-03, -2.1943e-03, -3.3667e-03, -1.5253e-03,\n","           4.5465e-03,  4.1998e-03,  5.3182e-03, -4.8745e-03, -3.0024e-03,\n","          -1.8805e-03, -2.9233e-03,  4.1460e-03, -2.9009e-04, -3.4503e-03,\n","          -4.2104e-03, -1.1814e-03,  1.8079e-03,  1.6299e-03, -2.1646e-03,\n","          -2.4759e-03,  3.4503e-03,  5.3183e-03,  2.9992e-03, -4.5102e-03,\n","           2.1122e-03, -2.7009e-03,  6.0866e-03, -6.0131e-03, -2.1371e-03,\n","          -4.6827e-03,  5.3028e-03,  1.8525e-03,  2.9280e-03,  6.0002e-03,\n","           3.6321e-03, -3.5776e-04,  3.9749e-03, -3.4635e-03,  5.2880e-03,\n","          -7.7948e-04,  5.0546e-04, -3.0940e-03, -2.0771e-03,  2.7636e-03,\n","           2.5261e-03,  5.3806e-03,  4.4961e-03,  3.7765e-03,  2.3512e-03,\n","          -5.4638e-03,  4.4411e-04,  2.2013e-03, -2.4094e-04,  4.0205e-04,\n","          -2.9228e-03,  2.4280e-03,  8.1109e-04, -2.1159e-03,  3.4876e-03,\n","          -2.7210e-03,  3.3983e-03, -2.5899e-03, -5.1534e-03,  1.9198e-03,\n","           8.2431e-04,  2.2803e-03, -4.9994e-03,  5.7868e-03,  1.6794e-03,\n","          -3.1475e-03,  5.4921e-03,  7.9067e-04,  5.9862e-03, -3.5852e-03,\n","           3.3018e-03, -9.6118e-04,  5.0133e-03, -4.7140e-03, -4.2145e-03,\n","          -4.7765e-03, -2.5386e-03,  5.4504e-03,  5.0257e-03, -2.7695e-03,\n","           1.1262e-03,  6.1338e-03,  1.6441e-03, -3.0755e-03, -3.0461e-04,\n","          -5.1621e-03, -3.3386e-03,  2.6606e-03,  1.5738e-03, -3.6849e-03,\n","          -4.2977e-03,  2.0422e-03, -2.1256e-04, -2.1985e-03,  1.2224e-03,\n","          -2.1426e-03, -5.0659e-03, -5.5956e-03,  5.6091e-03,  4.5618e-03,\n","           1.1888e-03, -5.0314e-03, -6.4241e-04,  2.2199e-03,  2.5699e-03,\n","           5.1452e-03,  4.8702e-03, -2.2610e-03, -5.6867e-03, -9.1049e-04,\n","          -5.6515e-03, -2.6174e-05, -4.5328e-04, -1.3803e-03,  4.6025e-03,\n","          -4.0413e-03,  2.7344e-03, -5.4210e-03,  1.7251e-03, -2.7767e-03,\n","          -5.4506e-04, -2.8765e-03, -6.1428e-03,  2.6759e-03,  4.4216e-03,\n","          -5.2134e-05,  3.3121e-03, -6.7140e-04, -4.4646e-03, -2.6581e-03,\n","           2.2886e-03,  5.8421e-03,  7.5802e-04, -5.5714e-03, -2.9727e-03,\n","          -4.7489e-04, -5.0850e-03,  2.7150e-03, -1.3084e-03, -5.5455e-03,\n","           2.7605e-03, -5.2034e-03,  2.8072e-03, -2.4347e-03,  4.4555e-03,\n","           1.4131e-03, -9.3756e-04, -3.7718e-03,  3.2199e-03, -3.9172e-03,\n","           3.8505e-03,  2.1528e-03, -2.3108e-03, -3.0345e-03,  3.4256e-03,\n","          -3.6528e-03, -2.6820e-03,  5.4749e-03, -2.7200e-03, -1.2581e-03,\n","           4.1995e-03, -2.3295e-03,  3.9096e-03,  3.1702e-03, -2.8057e-03,\n","          -7.0933e-04, -1.3640e-03,  1.5277e-03, -1.2795e-03, -3.5350e-04,\n","          -5.6418e-03,  1.7452e-03], grad_fn=<CloneBackward0>)),\n"," ('decoder.2.weight',\n","  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<CloneBackward0>)),\n"," ('decoder.2.bias',\n","  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<CloneBackward0>)),\n"," ('decoder.3.weight',\n","  tensor([[-0.0025,  0.0374, -0.0423,  ..., -0.0434,  0.0362,  0.0190],\n","          [-0.0005,  0.0343,  0.0115,  ...,  0.0080, -0.0383,  0.0375],\n","          [-0.0010, -0.0345, -0.0169,  ..., -0.0034,  0.0243,  0.0152],\n","          ...,\n","          [-0.0311, -0.0003,  0.0283,  ...,  0.0428, -0.0224, -0.0006],\n","          [-0.0089,  0.0168,  0.0088,  ..., -0.0272,  0.0208, -0.0343],\n","          [ 0.0155, -0.0406, -0.0312,  ...,  0.0343, -0.0284,  0.0247]],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.3.bias',\n","  tensor([-0.0286,  0.0314,  0.0310, -0.0263,  0.0427, -0.0273,  0.0194, -0.0086,\n","          -0.0045, -0.0011, -0.0309, -0.0396, -0.0336, -0.0087,  0.0098,  0.0352,\n","          -0.0279, -0.0052, -0.0322,  0.0214, -0.0127, -0.0148,  0.0442, -0.0151,\n","           0.0038, -0.0306,  0.0293, -0.0306,  0.0034, -0.0152, -0.0429, -0.0025,\n","          -0.0200, -0.0221,  0.0080, -0.0314,  0.0177, -0.0043,  0.0310, -0.0164,\n","          -0.0079, -0.0349, -0.0205, -0.0426,  0.0370, -0.0116,  0.0370, -0.0019,\n","          -0.0267,  0.0318,  0.0248,  0.0342,  0.0212,  0.0348,  0.0014, -0.0056,\n","          -0.0274,  0.0220,  0.0390,  0.0157,  0.0098, -0.0341, -0.0424, -0.0155],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.5.weight',\n","  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<CloneBackward0>)),\n"," ('decoder.5.bias',\n","  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.6.weight',\n","  tensor([[-0.0541, -0.0448, -0.0347,  ..., -0.0313, -0.0299,  0.1230],\n","          [-0.0978,  0.0056,  0.0225,  ...,  0.1033, -0.0961, -0.0624],\n","          [-0.0508, -0.1106,  0.0345,  ...,  0.1206, -0.0242, -0.0521],\n","          ...,\n","          [-0.0675, -0.0278, -0.0339,  ..., -0.1010,  0.0663, -0.1216],\n","          [-0.1178,  0.1188,  0.1026,  ..., -0.0593, -0.0942, -0.0718],\n","          [ 0.1124, -0.0691,  0.1163,  ..., -0.1101, -0.0032, -0.0158]],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.6.bias',\n","  tensor([-0.0190, -0.0121,  0.0160, -0.0408, -0.0484, -0.0732,  0.0495,  0.0150,\n","           0.0861, -0.0319,  0.0992, -0.0616, -0.1172, -0.1083, -0.1221,  0.0863,\n","          -0.0169,  0.1193,  0.0959,  0.0883,  0.0104, -0.0705,  0.0523, -0.0231,\n","           0.0781, -0.1047, -0.0624,  0.0006,  0.1021,  0.0123, -0.0587,  0.0112],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.8.weight',\n","  tensor([[-0.0789,  0.1323,  0.0183,  0.1139,  0.0385, -0.0231,  0.0678,  0.0860,\n","           -0.0731, -0.0821, -0.0058,  0.0866,  0.0316, -0.0952, -0.1110, -0.0312,\n","           -0.1264, -0.1187, -0.1622, -0.0484, -0.0358,  0.1375,  0.0867,  0.0794,\n","           -0.1233,  0.1746, -0.1514, -0.0337, -0.0817, -0.1451, -0.0424, -0.0892]],\n","         grad_fn=<CloneBackward0>)),\n"," ('decoder.8.bias', tensor([0.0049], grad_fn=<CloneBackward0>))]"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":[""],"metadata":{"id":"8fFXWwLEKsIw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a10aee04-20e3-44de-8e32-01a6e8bb7552"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["yes\n","10\n","yes\n","20\n","yes\n","30\n","yes\n","40\n","yes\n","50\n","yes\n","60\n","yes\n","70\n","yes\n","80\n","yes\n","90\n","yes\n","100\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"NmoPoqwuCfhp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"train.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}